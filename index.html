<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Hexo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hexo</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-about"></i>About</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/11/01/paper-reading-The-CacheLib-Caching-Engine-Design-and-Experiences-at-Scale/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/11/01/paper-reading-The-CacheLib-Caching-Engine-Design-and-Experiences-at-Scale/" class="post-title-link" itemprop="url">paper reading: The CacheLib Caching Engine: Design and Experiences at Scale</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-11-01 23:21:57" itemprop="dateCreated datePublished" datetime="2023-11-01T23:21:57+08:00">2023-11-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-11-05 16:28:38" itemprop="dateModified" datetime="2023-11-05T16:28:38+08:00">2023-11-05</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>在过去每个团队都可能维护一套自己的特化的cache. 这样的方式无视了不同cache系统共有的问题, 极大增加了部署，维护以及扩容的成本.<br>本文主要介绍CacheLib——Facebook内部已经广泛应用在CDN，存储和应用数据cache上. 坐着阐述了各个生产环节workload的特质以及FB内部的应用场景如何影响着决策. 描述了FB内部cache如何演化的, 也讨论了对未来的cache研究和设计能带来哪些暗示.</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>FB内部架构里大量的系统都使用了cache,包括CDB caches, key-value application caches, social-graph caches, storage cache, database cache, media caches等. 这些cache系统最初都是单独设计实现并维护的. 最初的思路是单独设计针对不同场景优化以此满足复杂的一致性协议，更好地利用定制化数据结构，并且对特定的硬件平台优化.</p>
<p>尽管各种cache有一些不同点，但他们也有很多相同的点: 都需要百万级的qps, cache set大到需要flash和DRAM都使用, 同时必须容忍系统更新引起的频繁重启(FB在Fail at Scale里提过他们更新部署是很频繁的). 随着FB的发展，这些cache系统也越来越多, 维护这么多系统的代价也是很高的. 很多重复的问题在不同的系统上被重复地解决多次. 同时这样多系统的维护也让很多系统上的系统调优知识无法有效共享. 因此FB在考虑了泛用性和特化的tradeoff之后选择了泛用性. 虽然这会在某些特殊的系统上丢失一部分特殊领域的优化，但是减轻了代码开发的负担也增加了系统协调性.</p>
<p>最后FB开启了CacheLib的开发. CacheLib作为一个C++库提供了cache功能所必需的核心功能, 包括: 高效的cache索引实现, 驱逐策略, 为DRAM和flash caches的稳定优化. 同时提供给用户简单，线程安全的接口.</p>
<h3 id="Lessons-Learned-from-CacheLib"><a href="#Lessons-Learned-from-CacheLib" class="headerlink" title="Lessons Learned from CacheLib"></a>Lessons Learned from CacheLib</h3><p>**特化的cache系统可以同时也应该构建于通用的cache系统之上.**一方面一套统一的代码更利于维护和开发，另一个方面业务部门可以通过在core系统外围开启不同功能选择不同配置以定制化需求. 同时统一的系统的运维经验，调优经验，方便整理的文档也利于开发者分享(搞不好还利于减轻oncall的人的压力).</p>
<p><strong>生产场景的workload需要大规模饿环境</strong>.以往的benchmark采用的是参数为.9的Zipf popularity model. 基于这个模型会认为DRAM-based缓存已经可以应对大多数场景. FB的场景里面cache系统需要能够应对massive request. 所以采用了flash.</p>
<h2 id="Motivation-Caching-Use-Cases"><a href="#Motivation-Caching-Use-Cases" class="headerlink" title="Motivation: Caching Use Cases"></a>Motivation: Caching Use Cases</h2><p>这一章以6个FB内部的生产系统为例介绍不同的业务对cache的需求是什么</p>
<h3 id="Hierarchical-and-geo-distributed-caches"><a href="#Hierarchical-and-geo-distributed-caches" class="headerlink" title="Hierarchical and geo-distributed caches"></a>Hierarchical and geo-distributed caches</h3><p>FB的CDN服务专注于为请求静态资源的HTTP请求服务. 使用CDN的目标之一是减少因为cache miss引起的跨区域网络传输(比如在亚洲要是需要请求到北美的服务器那延迟肯定很低). 在FB内部每台CDN都是使用local cache，同时包含flash和DRAM.</p>
<h3 id="Application-look-aside-caches"><a href="#Application-look-aside-caches" class="headerlink" title="Application look-aside caches"></a>Application look-aside caches</h3><p>web应用的cache需求非常广泛. 可能是某条db的查询结果(比如查询库存), 查询用户数据等. 这种需求一般是应用通过RPC访问一系列的共享cache服务. 每一个cache服务都由一个庞大的分布式cache系统组成(其实就很类似互联网应用中各种各样的cache, 不过一般可能都是使用的redis的服务, 可以看下FB关于memcached的论文).</p>
<h3 id="in-process-caches"><a href="#in-process-caches" class="headerlink" title="in-process caches"></a>in-process caches</h3><p>也有很多应用无法忍受remote cache的网络开销. 这个时候cachelib也可以发挥类似caffeine的作用，以进程内cache的方式发挥作用.</p>
<h3 id="Machine-learning-model"><a href="#Machine-learning-model" class="headerlink" title="Machine learning-model"></a>Machine learning-model</h3><p>面向用户的ml应用经常基于用户和推荐内容的互动来作为训练的输入. 用户和内容的互动会先cache住以方便ml程序快速做出预测(类似于将用户的行为记录counter缓存在cache中，用户的counter的更新也能通过write through cache的方式更新，之后训练程序直接读取cache肯定比去storage  service里load更快). 另外相同的输入往往输出也相同，所以可以将相同输入对应的预测结果缓存在cache中.</p>
<h3 id="Storage-backend-cache"><a href="#Storage-backend-cache" class="headerlink" title="Storage-backend cache"></a>Storage-backend cache</h3><p>持久化数据会按照blocks的方式存储在FB内部的集群中的spinning disks上. 即使在block storage server前使用了多层存储还是存在部分热点block的请求次数超过目标磁盘的IOPS的情况. Storage server会使用flash来缓存热点block. 为了支持byte-range请求和append操作，这些flash cache会和storage system stack紧密整合.</p>
<h3 id="Database-page-buffer"><a href="#Database-page-buffer" class="headerlink" title="Database page buffer"></a>Database page buffer</h3><p>数据结构和小对象被存储在各种各样的数据库系统中. DB会利用page cache来提升吞吐并降低延迟, 为了保证一致性和事务性, page cache会和数据库logic紧密整合.</p>
<p>目前除了database page buffer以外上诉其他场景cachelib都在fb内部使用了.</p>
<h2 id="Shared-Challenges-Across-Caching-Systems-at-Facebook"><a href="#Shared-Challenges-Across-Caching-Systems-at-Facebook" class="headerlink" title="Shared Challenges Across Caching Systems at Facebook"></a>Shared Challenges Across Caching Systems at Facebook</h2><p>这一章介绍构建cache系统时普遍面临的问题.</p>
<h3 id="Massive-Working-Sets"><a href="#Massive-Working-Sets" class="headerlink" title="Massive Working Sets"></a>Massive Working Sets</h3><p>working set的定义是在一个workload中能够从caching里面收益的对象的集合. 如果要达到相同的hit ratio, working set越大则需要越大的cache. 为了测量working sets, 必须同时考虑随着时间变化被看到的popular data(Popularity)和随着时间变化数据的欢迎度改变的程度(Churn).</p>
<h4 id="Popularity"><a href="#Popularity" class="headerlink" title="Popularity"></a>Popularity</h4><p>表示每一个key在一定时间内在系统内所有objects间的相对受欢迎度. </p>
<p>TODO: 这里贴图</p>
<p>不恰当地说, 在Zipf分布里最受欢迎的20%的object接受了80%的请求. 但Zipf 分布的公式里第i受欢迎的object的相对频率是通过一个参数可以计算出来的. 相对的这个参数越低意味着更多的请求会发给popularity 分布的尾部，这也就需要更大的working set. (Lookaside系统的参数接近1， SocialGraph是0.55 CDN是0.7)</p>
<h4 id="Churn"><a href="#Churn" class="headerlink" title="Churn"></a>Churn</h4><p>Churn表示随着新key的进入，working set的变化以及已经存在的key的popularity变化. churn会影响caching policy的设计。 高churn就增加了temporal locality的重要性. 也让caching police’s更难通过过去的access patten估计object的popularity.</p>
<p>这些发现也限制了设计一套通用cache系统时的设计空间. 许多现有的系统一个cacheline最多存储一个单独的object(64B). 对于SocialGraph系统(一般是10B到20B)这就会很浪费. 另一个挑战是经常用于作为flash里面系统的in-memory index. 每一个object在索引上的负担在现有系统上也是不同的(8B-100B都有。如LookAside系统, 这意味着需要80GB-1TB的DRAM来索引1TB的flash上的数据).</p>
<h3 id="Size大小多变"><a href="#Size大小多变" class="headerlink" title="Size大小多变"></a>Size大小多变</h3><p>Storage 和 CDN需求里常见的是64KB和128Kb的chunk，所以会把大的object拆分成chunk. 而Lookaside和SocialGraph里大小变化超过7个数量级.</p>
<h3 id="Bursty-Traffic"><a href="#Bursty-Traffic" class="headerlink" title="Bursty Traffic"></a>Bursty Traffic</h3><p>用户的请求数量存在激增的情况. 通常在system领域会采用Poisson分布来描述请求, 但FB内部的采集数据显示和实际上请求到达的速率还是有很大的区别的. Lookaside场景相对Poisson分布波动较小. SocialGraph和Storage场景会有20%到30%做有的波动, CDN场景则存在很尖锐的波动. 请求到达速率的多变性让cache系统在高压导入场景很难有效提供资源给cache服务.</p>
<h3 id="Resource-Management"><a href="#Resource-Management" class="headerlink" title="Resource Management"></a>Resource Management</h3><p>cache系统需要注意不能将系统可用资源全部消耗,尤其是DRAM-based的cache系统. 以in-process场景的cache为例, 因为需要cache的对象的size也是多变的，所以cache的内存消耗也是很难预测的. 如果消耗了太多内存很容易导致系统OOM程序直接退出.</p>
<h3 id="Computationally-Costly-Query-for-Empty-Results"><a href="#Computationally-Costly-Query-for-Empty-Results" class="headerlink" title="Computationally Costly Query for Empty Results"></a>Computationally Costly Query for Empty Results</h3><p>在追踪用户关系的数据库查询中经常会出现query返回了空的情况. 这种查询很浪费数据库资源. 在SocialGraph场景中FB发现有55.6%的查询都是这种空结果查询. 剩余的44.4%的请求都是有效的对象，对应的cache命中率是86.5%. 如果不能cache住空结果, 对应的cache命中率会显著降低.</p>
<h3 id="Updating-Cached-Data-Structures"><a href="#Updating-Cached-Data-Structures" class="headerlink" title="Updating Cached Data Structures"></a>Updating Cached Data Structures</h3><p>Cache应该能够有效支持结构化数据. 特别是对in-process场景. 应用程序经常会希望能够在不反序列化整个cached数据的情况下更新其中的特定fields.</p>
<h3 id="Frequent-Restarts"><a href="#Frequent-Restarts" class="headerlink" title="Frequent Restarts"></a>Frequent Restarts</h3><p>最后，生产环境中的cache系统应该能过在频繁重启(可能是bug修复或者软件更新)的情况下稳定工作. 75%的Lookaside场景和95%的CDN场景的更新时间都小于7天. 即使是Storage和SocialGraph场景也会因为每月的维护需要重启cache进程. 大部分的cache系统是透明无感的，也就是说重启后就丢失了cache中的数据. 这对于大型的cache系统是很不友好的，可能需要很长的时间cache系统的命中率才能恢复到正常状态. 有的系统会采取warmup来缓解.</p>
<p>笔者吐槽: 其实cachelib在程序非正常退出的情况下 cache也全部会丢失… 只有优雅退出的场景能保留cache内容.</p>
<h2 id="Design-and-Implementation"><a href="#Design-and-Implementation" class="headerlink" title="Design and Implementation"></a>Design and Implementation</h2><p>FB认为要解决前两章的问题则cache系统应该有如下的feature:</p>
<ul>
<li>Thread-safe cache primitives: 以此简化应对bursty traffic的场景. 同时也简化了一致性和cache invalidation协议的实现.</li>
<li>Transparent hybrid caching: 为了能够满足large working sets的需求，cachelib支持混合使用DRAM和flash。 Hybrid cache能够在每台节点提供TB级的cache能力. cachelib提供给programmer的统一的byte-address的抽象，让programmer无需担心底层的存储介质.</li>
<li>Low resource overhead: Cachelib能够在占用低CPU和memory的情况下提供强劲的吞吐. 这使得其能够在和application混布的场景发挥作用(cache和application共享资源). 也让其在small objects很多的场景也能够顺利工作(不会出现前文中需要很大的资源才能维护cache index之类的情况).</li>
<li>Structured items: Cachelib提供了原生的array和hashmap的实现. 可以在不发起serialization的情况下高效cache和修改.</li>
<li>Dynamic resource monitoring, allocation, and OOM protection: cachelib会监控整个系统的内存使用.</li>
<li>Warm restarts: 在重启程序时依旧保留cache的状态.</li>
</ul>
<h3 id="API设计"><a href="#API设计" class="headerlink" title="API设计"></a>API设计</h3><p>所有的api设计都围绕着一个叫Item的概念, 用来表示被cache的对象的抽象. Item能够用byte-address的方式访问cache中的object, 无需关心是cache在DRAM还是在flash中. ItemHandle是Item的使用接口，每产生一个handle就会对Item的引用计数+1，销毁时则-1. 除非Item的引用为0，否则不会被evict. 如果某个引用计数不为0的item被删除或者超时expires了，现存的他的itemhandle还是有效的，但是不会有新的itemhandle产生了.</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">ItemHandle <span class="title">allocate</span><span class="params">(PoolId id, Key key, <span class="type">uint32_t</span> size, <span class="type">uint32_t</span> ttlSecs = <span class="number">0</span>)</span></span>;</span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">insertOrReplace</span><span class="params">(<span class="type">const</span> Itemhandle&amp; handle)</span></span>;</span><br><span class="line"><span class="function">ItemHandle <span class="title">find</span><span class="params">(Key key)</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span>* <span class="title">Item::getMemory</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span>* <span class="title">Item::markNvmUnclean</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">remove</span><span class="params">(Key key)</span></span>;</span><br></pre></td></tr></table></figure>

<p>调用allocate时如果没有空间会先根据eviction policy来驱逐一个引用计数为0的Item. 新插入的Item可以设置TTL. 同时根据PoolId可以可以选择内存池以提供隔离性配置. 任何一个新的Item会在对对应的ItemHandle完成insertOrReplcae操作后才可见.</p>
<p>要访问Item需要通过find方法根据Key拿到ItemHandle. 之后可以通过getMemory方法以非同步地方式零拷贝访问Item相关的内存. 如果需要原子性地更新一个Item, 可以先使用allocate分配对应的ItemHandle，然后通过调用insertOrReplace让更新可见。 CacheLib会忠实地执行用户的markNvmUnclean方法指示任何的修改. 最后，remove会删除key指定的object，也会invalidation cache或者删除对应的底层的object.</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">MyType</span> &#123;</span><br><span class="line">    <span class="type">int</span> foo;</span><br><span class="line">    <span class="type">char</span> bar[<span class="number">10</span>];</span><br><span class="line">&#125;</span><br><span class="line">TypedHandleImpl&lt;Item, MyType&gt; typedHandle&#123;cache-&gt;<span class="built_in">find</span>(..)&#125;;</span><br></pre></td></tr></table></figure>

<p>用户也可以如上面的代码一样自定义类型并使用CacheLib将他们cache起来. 也支持变长类型比如hashmap等.</p>
<h3 id="Architecture-Overview"><a href="#Architecture-Overview" class="headerlink" title="Architecture Overview"></a>Architecture Overview</h3><p>CacheLib的设计目标是能够有足够的拓展性以及能够应对各种长度的size的object. 为了实现较低的per-object负载, 一个单独的CacheLib cache由多个子系统组成，每一个都对应一个特别的storage介质和object的size. CacheLib由一个DRAM cache和一个flash cache组成. Flash cache由LargeObjectCache(LOC, 为Item大于等于2KB的object服务)和SmallObjectSize(SOC, 为小于2KB的object服务).</p>
<p>allocate函数的作用是从DRAM空间分配内存，对应的就可能会被DRAM中的存在的Item驱逐到flash或者直接丢弃. find函数则会先找DRAM然后LOC然后SOC. 如果是在DRAM中找到则返回的ItemHandle立刻就能使用，如果是在flash中找到则需要异步拉取，对应的Cachehandle会在Item被加载进DRAM会变得可用. 当发生cache miss时会返回一个空的ItemHandle.</p>
<p><strong>DRAM cache</strong>. CacheLib在DRAM cache中使用链式hash表进行查找, DRAM cache可以被切分成带有不同eviction policy的pool(在allocate的时候通过PoolId指定).</p>
<p>为了性能考虑cache 内存是通过伙伴系统来分配的. CacheLib使用4MB的slabs并且实现了自己的slab分配器. 每一个slab需要7B(3B给内部元数据，4B用来标识object大小). 对于不同业务来讲每一个slab ckass的大小是可以采用不同配置的(对于小于64B和大于4MB的情况在4.3节讨论对应的优化).</p>
<p>对于不同的Slab系统也可以配置不同的eviction policy(CacheLib也能自定义开发新的policy). CacheLib会在Item上额外使用31B来支持这些对应的policy的配置.</p>
<table>
<thead>
<tr>
<th>Item metadata</th>
<th>DRAM overhead</th>
<th>Data type</th>
</tr>
</thead>
<tbody><tr>
<td>Eviction policy state</td>
<td>12B</td>
<td>1<em>4B timestamp, 2</em>4B pointers</td>
</tr>
<tr>
<td>Item creation timestamp</td>
<td>4B</td>
<td>4B timestamp</td>
</tr>
<tr>
<td>Expiration time(for TTLs)</td>
<td>4B</td>
<td>4B timestamp</td>
</tr>
<tr>
<td>Key size + object size</td>
<td>4B</td>
<td>4B size_t</td>
</tr>
<tr>
<td>Reference counting</td>
<td>2B</td>
<td>13b public ref count, 3b internal count</td>
</tr>
<tr>
<td>hash table chaining</td>
<td>4B</td>
<td>4B pointer</td>
</tr>
<tr>
<td>Flags</td>
<td>1B</td>
<td>8 binary flags</td>
</tr>
</tbody></table>
<p>为了保证metadata操作的原子性, Cachelib使用了细粒度Lock, 用户空间mutexes, C++院子操作等优化. 比如在LRU场景中，传统的方式里一个object被访问后会被放到most-recently-used的位置(在FB的场景中也很容易发生). CacheLib里每个Item在一段时间T内同一个Item不会被移动到MRU位置. 只要T比object在LRU list里走到尾端(也就是成为最不常用的那个)的时间短，这个方式都能有效的减少移动操作带来的contention. 另外FB也采用了比如flat combining的方式优化.</p>
<p><strong>Flash cache</strong>. 从DRAM中淘汰后除了直接删除也可能会写入flash. CacheLib还必须处理flash cell的有限的写寿命.</p>
<p>为了尽量减少写flash的速率，CacheLib会选择性地将object写回flash. 如果一个存在于flash的object在DRAM中没被修改过那么就不会写回flash. 否则CacheLib通过一个admission policy来决定是否写回flash. 默认配置是通过一个概率p来决定是否写回flash. 这个p可以通过对flash的写入速率进行控制.</p>
<p>另一个考虑的因素是写放大(比如在写falsh时除了object的内容还有元数据). 不只是应用层的写放大还有设备层的. </p>
<p>LOC存储的object大小都大于等于2KB，这个大小决定了在LOC中的独特的object的数量大概在百万级，所以可以通过一个内存中的B+树来进行索引. LOC使用分段B+树来存储flash中Item的位置. Items在LOC中的flash page里是4KB对齐的, 所以B+树中的flash location是一个4B的4KB对齐的地址. 也就是说LOC中最多能索引16TB的数据.</p>
<p>LOC使用cache也进一步限制了DRAM index的size. Keys被hash成8B. 前4B表示B+树的segment, 后4B用来在对应segment里查找. LOG 在flash中也会存储整个key的内容，用来在load进DRAM后与进行hash的key进行比较以确定是否找到了对应的Item. 而不同size的object在flash上被存储在不同的partition，所以可以根据flash location直接判断object的size，这样就不需要在元数据里存储object的size了. 为了减少DRAM里存储的address的size，每一个4KB的flash page最多存储一个单独的object和对应的元数据. 因为LOC只存储超过2KB的object，这个策略是很space-efficient的. 因为LOC的read和write都是page粒度的，任何application级别的碎片化都会导致写放大.</p>
<p>LOC的remove是按照region级别进行的。也就是说一下子可以删除一个region上的多个Item(顺序删除，提供删除的性能，也摊平flash erasure的开销). 默认情况下region是按照FIFO的方式进行严格顺序的erase的. 当然也可以采用类似LRU的方式进行region管理.</p>
<p><strong>SOC</strong>. 因为SOC都是小于2KB的object，如果还是使用LOC那样的精确查找的方式会消耗非常多的内存，所以SOC采用的是近似索引. SOC将Key映射到不同的set. 每个set表示一个4KB的flash page. 一个flash page能存储多个objects. set中的objects是按照FIFO的顺序进行驱逐的. 为了加快查找效率，cachelib会给每个set在内存中维护一个8B的bloom filter.</p>
<p>在SOC中控制写放大时很有挑战性的. 因为写一条object在flash上就是下刷4KB. 所以SOC需要有先进的admit policy来控制对SOC的写入.</p>
<h3 id="Implementation-of-Advanced-Feature"><a href="#Implementation-of-Advanced-Feature" class="headerlink" title="Implementation of Advanced Feature"></a>Implementation of Advanced Feature</h3><h4 id="structured-items"><a href="#structured-items" class="headerlink" title="structured items"></a>structured items</h4><p>CacheLib原生支持arrays和map类型. 同时因为能提供raw access访问cached memory, 平坦的数据结构可以直接用cachelib api访问.</p>
<h4 id="caching-large-and-small-objects"><a href="#caching-large-and-small-objects" class="headerlink" title="caching large and small objects"></a>caching large and small objects</h4><p>大于4MB的object会通过链表的方式将多个Item链到一起组成一个逻辑上的大item(每个item会使用4B的next pointer).</p>
<p>针对小对象还有compact cache的功能用来存储小于cacheline的对象(一般64B或者128B). 相同key size，相同object size的objects会被存储在一个cache line之中. compact cache中每一个cacheline都是通过key hash索引的. cacheline之中会进行LRU. compact cache可以用来处理negative caching(后段查询返回空值的情况).</p>
<h4 id="resource-monitoring"><a href="#resource-monitoring" class="headerlink" title="resource monitoring"></a>resource monitoring</h4><p>Cachelib会监控系统内存使用，系统free内存不足时释放自己的内存.</p>
<h4 id="warm-restarts"><a href="#warm-restarts" class="headerlink" title="warm restarts"></a>warm restarts</h4><p>Cachelib使用POSIX shared memory来满足warmup需要.</p>
<h2 id="Experience-and-Discussion"><a href="#Experience-and-Discussion" class="headerlink" title="Experience and Discussion"></a>Experience and Discussion</h2><h3 id="New-features-are-adopted-by-many-system"><a href="#New-features-are-adopted-by-many-system" class="headerlink" title="New features are adopted by many system"></a>New features are adopted by many system</h3><p>之前为别的cache系统开发的功能越来越多地被移植到cachelib上</p>
<h3 id="Performance-improvements-help-many-systems"><a href="#Performance-improvements-help-many-systems" class="headerlink" title="Performance improvements help many systems"></a>Performance improvements help many systems</h3><p>因为是一套general的系统，在cachelib上的一点点改进在部署方都可能带来很大的收益.</p>
<h3 id="Improved-stability"><a href="#Improved-stability" class="headerlink" title="Improved stability"></a>Improved stability</h3><p>Cachelib作为一个通用系统也避免了以前各种不同实现带来的不稳定性.</p>
<h3 id="No-single-caching-system-dominates"><a href="#No-single-caching-system-dominates" class="headerlink" title="No single caching system dominates"></a>No single caching system dominates</h3><h3 id="Flash-caching-signals-a-paradigm-shift"><a href="#Flash-caching-signals-a-paradigm-shift" class="headerlink" title="Flash caching signals a paradigm shift"></a>Flash caching signals a paradigm shift</h3><p>有的人可能觉得cache的命中率够高时通过flash增加cache的容量收益不会很大. flash cache和dram cache的混合部署能降低纯DRAM的成本. </p>
<p>另外传统的思路里认为cache只是用来节省磁盘访问时间的，但是考虑到现在的服务结构模式，除了磁盘访问延时以外还有更高的比如网络耗时，后端数据库执行耗时等, 使用flash缓存只要能避免这些耗时操作也是很有价值的.</p>
<h3 id="CacheLib-dose-not-always-lead-to-performance-gains"><a href="#CacheLib-dose-not-always-lead-to-performance-gains" class="headerlink" title="CacheLib dose not always lead to performance gains"></a>CacheLib dose not always lead to performance gains</h3><p>毕竟作为一个通用系统，在面对很多corner case的时候还是很难比经过专门设计和调优的专有系统强的. 但是专有系统的功能可以在之后被添加到cachelib中(.</p>
<h3 id="CacheLib-does-not-work-for-every-use-case"><a href="#CacheLib-does-not-work-for-every-use-case" class="headerlink" title="CacheLib does not work for every use case"></a>CacheLib does not work for every use case</h3><p>一些广告服务依赖于nested 数据结构，这是cachelib不能支持的.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/22/Doris-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0vertical-compaction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/10/22/Doris-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0vertical-compaction/" class="post-title-link" itemprop="url">Doris 如何实现vertical compaction</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-10-22 22:31:32" itemprop="dateCreated datePublished" datetime="2023-10-22T22:31:32+08:00">2023-10-22</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-10-28 18:02:53" itemprop="dateModified" datetime="2023-10-28T18:02:53+08:00">2023-10-28</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Apache Doris原先的compaction策略是horizontal compaction, 也就是说在读取不同版本数据做merge的这一步是把整行数据全部读到内存中进行聚合后再写入到compaction output之中的, 这样的方式面对大宽表场景会很容易把内存打满导致失败. Doris在最近的版本中引入了vertical compaction, 从整行一起compaction变成了按照列组的方式对不同的组进行compaction, 大大降低了compaction的内存消耗. 本文主要是根据代码解析到底是如何做到的. 本文不会涉及rowset的选择策略, 也不会涉及merge时读取数据聚合的过程，主要关注的是如何写不同的segment.</p>
<h2 id="调用路径"><a href="#调用路径" class="headerlink" title="调用路径"></a>调用路径</h2><p>compaction的触发方式有两种, 手动http触发, bg线程轮询触发. 本文主要介绍后者,前者比较简单,直接从<code>compaction_action.cpp</code>入手即可.</p>
<p>首先compaction任务是由_compaction_tasks_producer_thread周期性扫描磁盘上的tablets的情况后调用<code>StorageEngine::_submit_compaction_task</code>产生的. 对于每一个被挑选的tablet,会调用<code>Tablet::prepare_compaction_and_calculate_permits</code>计算其所需要的permits. 这一步具体的逻辑是各个compaction子类的<code>prepare_compacte</code>.</p>
<p><code>prepare_compacte</code>主要的逻辑是从这个tablet下属的所有rowsets中挑选最合适的连续的一连串rowset(根据不同的compaction类型会有不同的策略)进行compaction. 刚刚提到的compaction需要的permits则是所有被挑选出来的rowsets的compaction score之和.</p>
<p>在顺利执行完上面的步骤后即可向不同的compaction线程池提交对应的任务, 任务主要的逻辑是调用对应tablet实例的<code>execute_compaction</code>方法. 而这个方法的本质是调用<code>execute_compact</code>方法进而调用不同compaction子类实现<code>execute_compaction_impl()</code>.</p>
<p>这些<code>execute_compaction_impl()</code>方法之中都是先上锁然后计算compaction需要的permits然后调用<code>Compaction::do_compaction(int64_t permits)</code>方法. 其实这个方法的逻辑则是调用<code>do_compaction_impl(int64_t permits)</code>(如果开启了checksum配置则还会在调用前后执行检查checksum).</p>
<h3 id="do-compaction-impl-int64-t-permits"><a href="#do-compaction-impl-int64-t-permits" class="headerlink" title="do_compaction_impl(int64_t permits)"></a>do_compaction_impl(int64_t permits)</h3><p>这个函数的逻辑很长, 一点一点来解析他干了什么</p>
<figure class="highlight cpp"><figcaption><span>linenums</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">Compaction::do_compaction_impl</span><span class="params">(<span class="type">int64_t</span> permits)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">handle_ordered_data_compaction</span>()) &#123;</span><br><span class="line">        <span class="comment">// 检查segment间是否无重叠</span></span><br><span class="line">        Compaction::<span class="built_in">do_compact_ordered_rowsets</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果被选取的rowset之中的数据彼此间是顺序的(比如读取segment里面的zonemap发现min max区间是无重复的)并且segment文件大小合适, 那就可以很方便地compaction起来甚至不需要读取每个segment的数据聚合起来重新写到一个新的大的segment文件中. 可以简单的将input rowset下的segment文件硬链接到output rowset下使用新的segment id即可.</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">Compaction::do_compact_ordered_rowsets</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">construct_output_rowset_writer</span>();</span><br><span class="line">    <span class="keyword">auto</span> seg_id = <span class="number">0</span>; <span class="comment">// 新的目录下seg文件的新名字</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; rowset: _input_rowsets) &#123;</span><br><span class="line">        rowset-&gt;<span class="built_in">link_files_to</span>(_tablet-&gt;<span class="built_in">tablet_path</span>(), _output_rs_writer-&gt;<span class="built_in">rowset_id</span>(), seg_id);</span><br><span class="line">        seg_id += rowset-&gt;<span class="built_in">num_segments</span>();</span><br><span class="line">        <span class="comment">// 记录rowset的key bounds</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 向output rowset的meta信息里写数据</span></span><br><span class="line">    <span class="comment">// 包括刚刚记录的key bounds</span></span><br><span class="line">    <span class="comment">// 数据大小等</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight cpp"><figcaption><span>linenums</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">Compaction::do_compaction_impl</span><span class="params">(<span class="type">int64_t</span> permits)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 处理ordered compaction</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">construct_input_rowset_reader</span>(); <span class="comment">// 从所有input rowset上构建reader, 之后需要读所有rs的数据聚合才是output的数据</span></span><br><span class="line">    <span class="built_in">construct_output_rowset_writer</span>();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (vertical_compaction) &#123;</span><br><span class="line">        Merger::<span class="built_in">vertical_merge_rowsets</span>(_tablet, <span class="built_in">compaction_type</span>(), _cur_tablet_schema,</span><br><span class="line">                                        _input_rs_readers, _output_rs_writer.<span class="built_in">get</span>(),</span><br><span class="line">                                        <span class="built_in">get_avg_segment_rows</span>(), &amp;stats);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 非vertical compaction的逻辑就不梳理了, 比较直观(当然代码不一定直观==)</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>接下来是vertical compaction的逻辑到底是怎么走的</p>
<h3 id="vertical-merge-rowsets"><a href="#vertical-merge-rowsets" class="headerlink" title="vertical_merge_rowsets"></a>vertical_merge_rowsets</h3><p>第一步先看整个逻辑的入口也就是<code>vertical_merge_rowsets</code>这个函数, 先分析下他的入参</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">Merger::vertical_merge_rowsets</span><span class="params">(TabletSharedPtr tablet, ReaderType reader_type,</span></span></span><br><span class="line"><span class="params"><span class="function">                                      TabletSchemaSPtr tablet_schema,</span></span></span><br><span class="line"><span class="params"><span class="function">                                      <span class="type">const</span> std::vector&lt;RowsetReaderSharedPtr&gt;&amp; src_rowset_readers,</span></span></span><br><span class="line"><span class="params"><span class="function">                                      RowsetWriter* dst_rowset_writer, <span class="type">int64_t</span> max_rows_per_segment,</span></span></span><br><span class="line"><span class="params"><span class="function">                                      Statistics* stats_output)</span></span></span><br></pre></td></tr></table></figure>

<p>第一个tablet表示是哪个tablet被选出来做compaction, 因为会涉及到修改元数据所以需要拿到tablet并获取其中的锁. 第二个reader_type中记录的是不同的compaction的类型, tablet_schema记录表的schema属性(比如key类型, 列的数量)之后切分列组时也会用到. src_rowset_readers里记录的是之前prepare_compaction中选出的所有参与compaction的rowset, 这些rowset对应不同版本的数据. dst_rowset_writer是用来构造compaction的结果rowset的其表示的范围是src_rowset_reader中的最小值到最大值的区间, max_rows_per_segment是最后生成的output rowset下的每个segment文件之中最多有多少行数据, stats_output里面记录的是compaction的stats包括merge了多少列,结果是多少列等.</p>
<p>接下来的逻辑中第一步是划分列, 我们考虑下为什么需要划分. 在建表的时候用户可以指定dup key, uniq key, agg key等key列, 每一行数据在逻辑上都是通过key列来辨识的, key列不同的时候就一定不是同一行. 在进行compaction的时候为了保证数据不重不漏, 需要先将key列组进行compaction, 这样整行的数据都是按照key列在遍历就不会有遗漏. 而key列的顺序也表示了最终数据的顺序. 在拆分出key列之后僧下的value列按照<code>config::vertical_compaction_num_columns_per_group</code>的大小为一组分成多个组.</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// tablet_schema中拿到表的key列和列数等属性, column_groups中记录的是不同列组的下标集合</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Merger::vertical_split_columns</span><span class="params">(TabletSchemaSPtr tablet_schema,</span></span></span><br><span class="line"><span class="params"><span class="function">                                    std::vector&lt;std::vector&lt;<span class="type">uint32_t</span>&gt;&gt;* column_groups)</span> </span>&#123;</span><br><span class="line">    <span class="type">uint32_t</span> num_key_cols = tablet_schema-&gt;<span class="built_in">num_key_columns</span>();</span><br><span class="line">    <span class="type">uint32_t</span> total_cols = tablet_schema-&gt;<span class="built_in">num_columns</span>();</span><br><span class="line">    std::vector&lt;<span class="type">uint32_t</span>&gt; key_columns;</span><br><span class="line">    <span class="comment">// 前面几列都是key</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> i = <span class="number">0</span>; i &lt; num_key_cols; ++i) &#123;</span><br><span class="line">        key_columns.<span class="built_in">emplace_back</span>(i);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 根据不同key类型进行不同的处理</span></span><br><span class="line"></span><br><span class="line">    std::vector&lt;<span class="type">uint32_t</span>&gt; value_columns;</span><br><span class="line">    <span class="comment">// 按照个数拆分个多个group</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> i = num_key_cols; i &lt; total_cols; ++i) &#123;</span><br><span class="line">        <span class="keyword">if</span> ((i - num_key_cols) % config::vertical_compaction_num_columns_per_group == <span class="number">0</span>) &#123;</span><br><span class="line">            column_groups-&gt;<span class="built_in">emplace_back</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        column_groups-&gt;<span class="built_in">back</span>().<span class="built_in">emplace_back</span>(i);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>接下来的一行代码<code>vectorized::RowSourcesBuffer row_sources_buf(tablet-&gt;tablet_id(), tablet-&gt;tablet_path(),reader_type);</code>的作用目前还不明显, 我们可以暂时简单地理解为他是用来记录行的. 而这个类的实现可以概括如下</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RowSourcesBuffer</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">RowSourcesBuffer</span>(<span class="type">int64_t</span> tablet_id, <span class="type">const</span> std::string&amp; tablet_path, ReaderType reader_type)</span><br><span class="line">            : _tablet_id(tablet_id),</span><br><span class="line">              _tablet_path(tablet_path),</span><br><span class="line">              _reader_type(reader_type),</span><br><span class="line">              _buffer(ColumnUInt16::<span class="built_in">create</span>()) &#123;&#125;</span><br><span class="line"></span><br><span class="line">    ~<span class="built_in">RowSourcesBuffer</span>() &#123;</span><br><span class="line">        _reset_buffer();</span><br><span class="line">        <span class="keyword">if</span> (_fd &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            ::<span class="built_in">close</span>(_fd);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// write batch row source</span></span><br><span class="line">    <span class="function">Status <span class="title">append</span><span class="params">(<span class="type">const</span> std::vector&lt;RowSource&gt;&amp; row_sources)</span></span>;</span><br><span class="line">    <span class="function">Status <span class="title">flush</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function">RowSource <span class="title">current</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="built_in">DCHECK</span>(_buf_idx &lt; _buffer-&gt;<span class="built_in">size</span>());</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">RowSource</span>(_buffer-&gt;<span class="built_in">get_element</span>(_buf_idx));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">advance</span><span class="params">(<span class="type">int32_t</span> step = <span class="number">1</span>)</span> </span>&#123;</span><br><span class="line">        <span class="built_in">DCHECK</span>(_buf_idx + step &lt;= _buffer-&gt;<span class="built_in">size</span>());</span><br><span class="line">        _buf_idx += step;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    Status _create_buffer_file();</span><br><span class="line">    Status _serialize();</span><br><span class="line">    Status _deserialize();</span><br><span class="line">    <span class="type">void</span> _reset_buffer() &#123;</span><br><span class="line">        _buffer-&gt;<span class="built_in">clear</span>();</span><br><span class="line">        _buf_idx = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">int64_t</span> _tablet_id;</span><br><span class="line">    std::string _tablet_path;</span><br><span class="line">    ReaderType _reader_type = ReaderType::UNKNOWN;</span><br><span class="line">    <span class="type">uint64_t</span> _buf_idx = <span class="number">0</span>;</span><br><span class="line">    <span class="type">int</span> _fd = <span class="number">-1</span>;</span><br><span class="line">    ColumnUInt16::MutablePtr _buffer;</span><br><span class="line">    <span class="type">uint64_t</span> _total_size = <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>里面存储的是多个RowSource, 每个rowsource之中是一块连续内存(顾名思义保存row的), 每次调用append将多个RowSource写到<code>MutablePtr _buffer</code>之中. 如果超过了_buffer的大小则会先序列化到磁盘并从_buffer头部开始继续写入.</p>
<p>接下来的逻辑是对于每一个column group进行一次merge, 也就是按照多列一起来merge. 这里也是和horizontal compaction的最大区别, 按照列组来进行merge显而易见的好处是内存压力会小很多, 假设列大小是均匀分布的, 平均每一行的内存消耗几乎只有最大列组数大小&#x2F;列数(当然实际情况里肯定是非常不均的).</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> i = <span class="number">0</span>; i &lt; column_groups.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">    <span class="type">bool</span> is_key = (i == <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">RETURN_IF_ERROR</span>(<span class="built_in">vertical_compact_one_group</span>(</span><br><span class="line">            tablet, reader_type, tablet_schema, is_key, column_groups[i], &amp;row_sources_buf,</span><br><span class="line">            src_rowset_readers, dst_rowset_writer, max_rows_per_segment, stats_output));</span><br><span class="line">    <span class="keyword">if</span> (is_key) &#123;</span><br><span class="line">        <span class="built_in">RETURN_IF_ERROR</span>(row_sources_buf.<span class="built_in">flush</span>());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">RETURN_IF_ERROR</span>(row_sources_buf.<span class="built_in">seek_to_begin</span>());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>深入到<code>vertical_compact_one_group</code>之中, 传递进来的参数主要关注<code>tablet_schema</code>, <code>src_rowset_reader</code>, <code>dst_rowset_writer</code>的使用.<br><code>row_source_buf</code>作为将数据读到内存时的内存缓冲传递给VerticalBlockReader的构造函数之中, 之后VerticalBlockReader读取input_rowset并聚合出数据后按照堆排序排序存入<code>row_source_buf</code>之中, 下面按照<code>VerticalHeapMergeIterator::next_batch</code>的部分代码为例说明</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">VerticalHeapMergeIterator::next_batch</span><span class="params">(Block* block)</span> </span>&#123;</span><br><span class="line">    <span class="type">size_t</span> row_idx = <span class="number">0</span>;</span><br><span class="line">    VerticalMergeIteratorContext* pre_ctx = <span class="literal">nullptr</span>;</span><br><span class="line">    std::vector&lt;RowSource&gt; tmp_row_sources; <span class="comment">// 读取的每一行数据</span></span><br><span class="line">    <span class="comment">// 下面是按照堆排序读取row</span></span><br><span class="line">    <span class="keyword">while</span> (_get_size(block) &lt; _block_row_max) &#123;</span><br><span class="line">        <span class="keyword">auto</span> ctx = _merge_heap.<span class="built_in">top</span>();</span><br><span class="line">        _merge_heap.<span class="built_in">pop</span>();</span><br><span class="line">        <span class="comment">// 先收集多个row</span></span><br><span class="line">        <span class="keyword">if</span> (ctx-&gt;<span class="built_in">is_same</span>() &amp;&amp;</span><br><span class="line">            (_keys_type == KeysType::UNIQUE_KEYS || _keys_type == KeysType::AGG_KEYS)) &#123;</span><br><span class="line">            <span class="comment">// skip cur row, copy pre ctx</span></span><br><span class="line">            ++_merged_rows;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            ctx-&gt;<span class="built_in">add_cur_batch</span>();</span><br><span class="line">            <span class="keyword">if</span> (pre_ctx != ctx) &#123;</span><br><span class="line">                <span class="keyword">if</span> (pre_ctx) &#123;</span><br><span class="line">                    <span class="built_in">RETURN_IF_ERROR</span>(pre_ctx-&gt;<span class="built_in">copy_rows</span>(block));</span><br><span class="line">                &#125;</span><br><span class="line">                pre_ctx = ctx;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (ctx-&gt;<span class="built_in">is_cur_block_finished</span>() || row_idx &gt;= _block_row_max) &#123;</span><br><span class="line">                <span class="comment">// current block finished, ctx not advance</span></span><br><span class="line">                <span class="comment">// so copy start_idx = (_index_in_block - _cur_batch_num + 1)</span></span><br><span class="line">                <span class="built_in">RETURN_IF_ERROR</span>(ctx-&gt;<span class="built_in">copy_rows</span>(block, <span class="literal">false</span>));</span><br><span class="line">                pre_ctx = <span class="literal">nullptr</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">RETURN_IF_ERROR</span>(ctx-&gt;<span class="built_in">advance</span>());</span><br><span class="line">        <span class="keyword">if</span> (ctx-&gt;<span class="built_in">valid</span>()) &#123;</span><br><span class="line">            _merge_heap.<span class="built_in">push</span>(ctx);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// push next iterator in same rowset into heap</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 这里就是将读取出来的row都放进`RowSourceBuf`之中</span></span><br><span class="line">    <span class="built_in">RETURN_IF_ERROR</span>(_row_sources_buf-&gt;<span class="built_in">append</span>(tmp_row_sources));</span><br><span class="line">    <span class="keyword">if</span> (!_merge_heap.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">        <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">EndOfFile</span>(<span class="string">&quot;no more data in segment&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>现在我们回到<code>vertical_compact_one_group</code>之中, 刚刚说了row_source_buf的用处，现在来说一下这个VerticalBlockReader, 这个reader实际上是用来读取从input rowset之中数据的，读取出来的数据都放到了刚刚提到的row_source_buf之中, 既然要读取数据这里就涉及到数据的schema的问题. 比如考虑这样的情况, 一开始有<code>colA</code>, <code>colB</code>然后插入数据(1,2), 之后<code>delete where colB = 2</code>, 然后drop掉columnB, 现在add column columnB. 新的column B和之前的column B是不同的.</p>
<p>在往下有一行<code>reader_params.return_columns = column_group;</code>, 因为vertical compaction的逻辑是按照列组进行compaction的也就是说读取数据的时候只需要读取某几列即可，具体读取哪些列的数据就是靠<code>reader_params.return_columns</code>决定.</p>
<p>接下来是读取聚合后的数据并且写入output rowset的逻辑.</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">size_t</span> output_rows = <span class="number">0</span>;</span><br><span class="line"><span class="type">bool</span> eof = <span class="literal">false</span>;</span><br><span class="line"><span class="keyword">while</span> (!eof &amp;&amp; !StorageEngine::<span class="built_in">instance</span>()-&gt;<span class="built_in">stopped</span>()) &#123;</span><br><span class="line">    <span class="comment">// Read one block from block reader</span></span><br><span class="line">    <span class="comment">// reader通过reader_params.set_read_source拿到了所有input rowset</span></span><br><span class="line">    <span class="comment">// 然后根据不同的key类型选择不同的聚合方式, 每次读取一个block的数据</span></span><br><span class="line">    <span class="built_in">RETURN_NOT_OK_STATUS_WITH_WARN</span>(reader.<span class="built_in">next_block_with_aggregation</span>(&amp;block, &amp;eof),</span><br><span class="line">                                    <span class="string">&quot;failed to read next block when merging rowsets of tablet &quot;</span> +</span><br><span class="line">                                            std::<span class="built_in">to_string</span>(tablet-&gt;<span class="built_in">tablet_id</span>()));</span><br><span class="line">    <span class="comment">// 这个函数名字叫add_columns, 但其实可能叫add_columns_block_data更直观一点</span></span><br><span class="line">    <span class="comment">// 主要作用是将这个block写入segment文件中</span></span><br><span class="line">    <span class="built_in">RETURN_NOT_OK_STATUS_WITH_WARN</span>(</span><br><span class="line">            dst_rowset_writer-&gt;<span class="built_in">add_columns</span>(&amp;block, column_group, is_key, max_rows_per_segment),</span><br><span class="line">            <span class="string">&quot;failed to write block when merging rowsets of tablet &quot;</span> +</span><br><span class="line">                    std::<span class="built_in">to_string</span>(tablet-&gt;<span class="built_in">tablet_id</span>()));</span><br><span class="line"></span><br><span class="line">    output_rows += block.<span class="built_in">rows</span>();</span><br><span class="line">    block.<span class="built_in">clear_column_data</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>从刚刚的代码逻辑里可以看到这个while循环会将input rowset里对应column_group的所有数据全部读出来然后写进output rowset之中. 这里要注意下<strong>只读取了对应column_group并写入</strong>. 这里也是为什么vertical compaction消耗的内存会低很多. 感兴趣的读者可以看一下<code>Merger::vmerge_rowsets</code>的实现，基本的逻辑几乎一模一样，最大的区别是一个读取的数据是row的部分，一个是整个row全部会读取.</p>
<p>到目前为止我们从merger的角度大概梳理了代码的流程，接下来我们看一下vertical_beta_rowset_writer的实现来理解vertical compaction的segment文件的数据写入.</p>
<h3 id="vertical-beta-rowset-writer"><a href="#vertical-beta-rowset-writer" class="headerlink" title="vertical_beta_rowset_writer"></a>vertical_beta_rowset_writer</h3><h4 id="vertical-beta-rowset-writer-add-columns"><a href="#vertical-beta-rowset-writer-add-columns" class="headerlink" title="vertical_beta_rowset_writer::add_columns"></a>vertical_beta_rowset_writer::add_columns</h4><p>在vertical compaction中写入数据其实就是调用了这个add_columns接口, 我们从这个函数开始分析具体实现.<br>add_columns需要判断是否某一个column group写满了一个segment的对应区域, 如果写满了需要创建一个新的segment或者切换到下一个segment，但是又因为一个segment里面需要写多个column group, 所以得把segment都保留着，在最后一个 column group写完后才全部下刷持久化产生可用的文件.<br>先写key column group, 同时也只有key column group可能会创建新的segment.</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">VerticalBetaRowsetWriter::add_columns</span><span class="params">(<span class="type">const</span> vectorized::Block* block,</span></span></span><br><span class="line"><span class="params"><span class="function">                                             <span class="type">const</span> std::vector&lt;<span class="type">uint32_t</span>&gt;&amp; col_ids, <span class="type">bool</span> is_key,</span></span></span><br><span class="line"><span class="params"><span class="function">                                             <span class="type">uint32_t</span> max_rows_per_segment)</span> </span>&#123;</span><br><span class="line"><span class="comment">// 检查rows数以及更新每个segment最多有多少rows</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (_segment_writers.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">        <span class="comment">// 如果一个segment 都没有就创建一个新的segment并写入数据</span></span><br><span class="line">        <span class="built_in">RETURN_IF_ERROR</span>(_create_segment_writer(col_ids, is_key, &amp;writer));</span><br><span class="line">        _cur_writer_idx = <span class="number">0</span>;</span><br><span class="line">        <span class="built_in">RETURN_IF_ERROR</span>(_segment_writers[_cur_writer_idx]-&gt;<span class="built_in">append_block</span>(block, <span class="number">0</span>, num_rows));</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (is_key) &#123;</span><br><span class="line">        <span class="comment">// 如果当前的segment写过的行数已经满了</span></span><br><span class="line">        <span class="keyword">if</span> (_segment_writers[_cur_writer_idx]-&gt;<span class="built_in">num_rows_written</span>() &gt; max_rows_per_segment) &#123;</span><br><span class="line">            <span class="comment">// segment is full, need flush columns and create new segment writer</span></span><br><span class="line">            <span class="built_in">RETURN_IF_ERROR</span>(_flush_columns(&amp;_segment_writers[_cur_writer_idx], <span class="literal">true</span>));</span><br><span class="line">            <span class="comment">// 创建一个新的segment并跳到对应的新segment</span></span><br><span class="line">            <span class="built_in">RETURN_IF_ERROR</span>(_create_segment_writer(col_ids, is_key, &amp;writer));</span><br><span class="line">            ++_cur_writer_idx;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">RETURN_IF_ERROR</span>(_segment_writers[_cur_writer_idx]-&gt;<span class="built_in">append_block</span>(block, <span class="number">0</span>, num_rows));</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (_cur_writer_idx == <span class="number">0</span> &amp;&amp; num_rows_written == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="comment">// init的作用是更新segment中对应的column id(其实就是上一轮column group写完了需要换到下一个column group了)</span></span><br><span class="line">            <span class="built_in">RETURN_IF_ERROR</span>(_segment_writers[_cur_writer_idx]-&gt;<span class="built_in">init</span>(col_ids, is_key));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 如果会将当前segment写满(也就是rows超过限制),那为了防止溢出智只会写一部分数据</span></span><br><span class="line">        <span class="comment">// 并且写完后切换到下一个segment继续写</span></span><br><span class="line">        <span class="keyword">if</span> (num_rows_written + num_rows &gt;= num_rows_key_group &amp;&amp;</span><br><span class="line">            _cur_writer_idx &lt; _segment_writers.<span class="built_in">size</span>() - <span class="number">1</span>) &#123;</span><br><span class="line">            <span class="built_in">RETURN_IF_ERROR</span>(_segment_writers[_cur_writer_idx]-&gt;<span class="built_in">append_block</span>(</span><br><span class="line">                    block, <span class="number">0</span>, num_rows_key_group - num_rows_written));</span><br><span class="line">            <span class="comment">// 切换前需要flush写将当前segment的写flush了来</span></span><br><span class="line">            <span class="built_in">RETURN_IF_ERROR</span>(_flush_columns(&amp;_segment_writers[_cur_writer_idx]));</span><br><span class="line">            start_offset = num_rows_key_group - num_rows_written;</span><br><span class="line">            limit = num_rows - start_offset;</span><br><span class="line">            ++_cur_writer_idx;</span><br><span class="line">            <span class="comment">// switch to next writer</span></span><br><span class="line">            <span class="built_in">RETURN_IF_ERROR</span>(_segment_writers[_cur_writer_idx]-&gt;<span class="built_in">init</span>(col_ids, is_key));</span><br><span class="line">            num_rows_written = <span class="number">0</span>;</span><br><span class="line">            num_rows_key_group = _segment_writers[_cur_writer_idx]-&gt;<span class="built_in">row_count</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 这里既可能是刚切换完segment也可能是这次写入不会写满segment</span></span><br><span class="line">        <span class="keyword">if</span> (limit &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="built_in">RETURN_IF_ERROR</span>(</span><br><span class="line">                    _segment_writers[_cur_writer_idx]-&gt;<span class="built_in">append_block</span>(block, start_offset, limit));</span><br><span class="line">            <span class="built_in">DCHECK</span>(_segment_writers[_cur_writer_idx]-&gt;<span class="built_in">num_rows_written</span>() &lt;=</span><br><span class="line">                   _segment_writers[_cur_writer_idx]-&gt;<span class="built_in">row_count</span>());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>接下来简单说一下创建segment writer的逻辑, Doris中数据文件实际上是通过segment在表示的，一个segment上的数据是按照列存形式管理的，所以创建segment实际上需要创建一个对应的file以及file writer. 另外在vertical compaction中由于每次写segment是按照列组在写的，所以对于一个segment其每次写入表示的column的id也是有所不同的，所以存在多次init的情况. 其实不同的列对应的就是不同的column writer，每一次init根据传递进去的column id都会构造新的column writer.</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Status VerticalBetaRowsetWriter::_create_segment_writer(</span><br><span class="line">        <span class="type">const</span> std::vector&lt;<span class="type">uint32_t</span>&gt;&amp; column_ids, <span class="type">bool</span> is_key,</span><br><span class="line">        std::unique_ptr&lt;segment_v2::SegmentWriter&gt;* writer) &#123;</span><br><span class="line">    <span class="comment">// segment 文件的路径</span></span><br><span class="line">    <span class="keyword">auto</span> path =</span><br><span class="line">            BetaRowset::<span class="built_in">segment_file_path</span>(_context.rowset_dir, _context.rowset_id, _num_segment++);</span><br><span class="line">    <span class="keyword">auto</span> fs = _rowset_meta-&gt;<span class="built_in">fs</span>();</span><br><span class="line">    io::FileWriterPtr file_writer;</span><br><span class="line">    fs-&gt;<span class="built_in">create_file</span>(path, &amp;file_writer);</span><br><span class="line">    writer-&gt;<span class="built_in">reset</span>(<span class="keyword">new</span> segment_v2::<span class="built_in">SegmentWriter</span>(</span><br><span class="line">            file_writer.<span class="built_in">get</span>(), _num_segment, _context.tablet_schema, _context.tablet,</span><br><span class="line">            _context.data_dir, _context.max_rows_per_segment, writer_options, <span class="literal">nullptr</span>));</span><br><span class="line">    <span class="comment">// 因为一个rowset可能有多个segment, 所以都通过_file_writer管理</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="function">std::lock_guard&lt;SpinLock&gt; <span class="title">l</span><span class="params">(_lock)</span></span>;</span><br><span class="line">        _file_writers.<span class="built_in">push_back</span>(std::<span class="built_in">move</span>(file_writer));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> s = (*writer)-&gt;<span class="built_in">init</span>(column_ids, is_key);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="vertical-beta-rowset-writer-flush-columns"><a href="#vertical-beta-rowset-writer-flush-columns" class="headerlink" title="vertical_beta_rowset_writer::flush_columns"></a>vertical_beta_rowset_writer::flush_columns</h4><p>上文有说到，vertical compaction是按照column group在进行数据的读取和写入的，但是考虑到Doris的数据表示是通过segment进行的，一个segment上就应该有同一行的所有数据，自然而然会想到一个问题，假设segment数量有多个，那么按照column group行读取部分列的方式进行写一定会出现一个segment交替的过程. 比如说一共1000行数据，有2个column group(key group和value group), 分成2个segment. 那么先按照key group写segment1写了500行数据，之后写segment2写了500行数据，之后切换到value group从segment1开始写，这里一定有一个segment遍历的过程. 查看vertical_beta_rowset_writer的实现会发现一个<code>std::vector&lt;std::unique_ptr&lt;segment_v2::SegmentWriter&gt;&gt; _segment_writers;</code>和<code>size_t _cur_writer_idx = 0;</code>后者便是用来迭代遍历segment的下标.</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">VerticalBetaRowsetWriter::flush_columns</span><span class="params">(<span class="type">bool</span> is_key)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">RETURN_IF_ERROR</span>(_flush_columns(&amp;_segment_writers[_cur_writer_idx], is_key));</span><br><span class="line">    <span class="comment">// 下一次从第一个segment开始写入</span></span><br><span class="line">    _cur_writer_idx = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br><span class="line">Status VerticalBetaRowsetWriter::_flush_columns(</span><br><span class="line">        std::unique_ptr&lt;segment_v2::SegmentWriter&gt;* segment_writer, <span class="type">bool</span> is_key) &#123;</span><br><span class="line">    <span class="type">uint64_t</span> index_size = <span class="number">0</span>;</span><br><span class="line">    <span class="built_in">RETURN_IF_ERROR</span>((*segment_writer)-&gt;<span class="built_in">finalize_columns_data</span>());</span><br><span class="line">    <span class="built_in">RETURN_IF_ERROR</span>((*segment_writer)-&gt;<span class="built_in">finalize_columns_index</span>(&amp;index_size));</span><br><span class="line">    <span class="keyword">if</span> (is_key) &#123;</span><br><span class="line">        _total_key_group_rows += (*segment_writer)-&gt;<span class="built_in">row_count</span>();</span><br><span class="line">        <span class="comment">// record segment key bound, 计算zonemap的值</span></span><br><span class="line">        KeyBoundsPB key_bounds;</span><br><span class="line">        Slice min_key = (*segment_writer)-&gt;<span class="built_in">min_encoded_key</span>();</span><br><span class="line">        Slice max_key = (*segment_writer)-&gt;<span class="built_in">max_encoded_key</span>();</span><br><span class="line">        key_bounds.<span class="built_in">set_min_key</span>(min_key.<span class="built_in">to_string</span>());</span><br><span class="line">        key_bounds.<span class="built_in">set_max_key</span>(max_key.<span class="built_in">to_string</span>());</span><br><span class="line">        _segments_encoded_key_bounds.<span class="built_in">emplace_back</span>(key_bounds);</span><br><span class="line">    &#125;</span><br><span class="line">    _total_index_size +=</span><br><span class="line">            <span class="built_in">static_cast</span>&lt;<span class="type">int64_t</span>&gt;(index_size) + (*segment_writer)-&gt;<span class="built_in">get_inverted_index_file_size</span>();</span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>现在回头看一下vertical compaction的代码，可以发现在<code>Merger::vertical_compact_one_group</code>中最后一行调用了<code>VerticalBetaRowsetWriter::_flush_columns</code>方法，也就是在每一个column group结束时将segment从0开始. 用一个伪代码表示则是</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Merger::<span class="built_in">vertical_merge_rowsets</span>() &#123;</span><br><span class="line">    <span class="keyword">for</span> (column_group: column_groups) &#123;</span><br><span class="line">        <span class="keyword">while</span> (!eof) &#123;</span><br><span class="line">            reader.<span class="built_in">next_block_with_aggregation</span>();</span><br><span class="line">            dst_rowset_writer-&gt;<span class="built_in">add_columns</span>(column_group);</span><br><span class="line">        &#125;</span><br><span class="line">        dst_rowset_writer-&gt;<span class="built_in">flush_columns</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    dst_rowset_writer-&gt;<span class="built_in">final_flush</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// final_flush中对每个segment调用finalize footer写入每个column的元数据信息, 在rowset_writer-&gt;build()时</span></span><br><span class="line"><span class="comment">// 持久所有数据</span></span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/15/Self-Tuning-Query-Scheduling-for-Analytical-Workloads/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/10/15/Self-Tuning-Query-Scheduling-for-Analytical-Workloads/" class="post-title-link" itemprop="url">Self-Tuning Query Scheduling for Analytical Workloads</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-10-15 13:18:42" itemprop="dateCreated datePublished" datetime="2023-10-15T13:18:42+08:00">2023-10-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-10-22 22:27:58" itemprop="dateModified" datetime="2023-10-22T22:27:58+08:00">2023-10-22</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>大部分数据库都将调度策略委托给了操作系统本身,这个策略虽然能够简化数据库的设计但是也会带来一些问题. 比如在面对并发查询的时候自适应的资源分配就便得很难做，除此以外要在数据库中做一些调度调优也变得很困难(因为实际上更多的还是靠os自己在进行调度). 所以很多现代的现代都通过将一整条query的执行拆分成多个小的独立的任务以此来实现task-based并行. 基于task就使得数据库系统自己就能进行调度.</p>
<p>这篇论文主要是展示如何在task-based的设计上进行一些优化，论文作者提出了一种针对分析型workload的创新的无锁，自调优调度器. 通过动态地调整任务的优先级以及任务对应的粒度提供了很高的调度弹性. 即使在大压力导入下依旧能为短查询提供接近最低的延迟.</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>分析型数据库面临的workload特别复杂，在高压导入时可能还有并行抵达的各种查询. 很多系统很难在这种压力下保持良好的查询性能. </p>
<p>下图作者以他们的系统和PG的进行了一个对比，在高频导入下的查询延迟的变化. Workload包括3&#x2F;4的短查询和1&#x2F;4的长查询. 同时系统的导入压力为其最大压力的95%并持续了25分钟.<br><img src="/Self-Tuning-Query-Scheduling-for-Analytical-Workloads/QueyType.png" alt="Query Type"></p>
<p>处于这种状态的系统对于用户来讲响应度变得更低，查询性能也变得难以预测在不同的时间跑相同的查询可能会收获不同的性能. 对于用户来说，在高压场景性能降级的影响应该尽量低. 类似PG的系统将执行的调度责任转交给了操作系统. 这类系统对每一次新的连接和查询都可能创建新的线程或者进程(当然更好的方式是池化), 在执行的过程中可能也会创建更多的线程进程来进行query内的并行. 为了避免线程数超过OS线程一般也会尽量控制线程的数量.</p>
<p>现代化的系统一般会做更细粒度的调度，会实现基于task-based的调度系统，一条query会被拆分成多个独立的任务，这些任务都可以在任何一个OS线程上执行，同时任务的调度也由数据库系统接手而非被动等待OS调度。数据库系统也可以很方便的基于任务数派发给不同的线程以动态调整query的并行度. 一些系统比如SAP HANA的调度策略是和OS 调度器共生的.</p>
<p>其他的比如HyPer和Umbra则是几乎不依赖OS的调度. 在启动时他们便启动同CPU核数相同数量的线程. 之后使用morsel-driven的方式进行调度. 一个morsel表示一个tuples的固定集合，morsel时query执行时的最小单元. 因为同一条queried的不同morsel可以并行执行所以这种方式可以实现query内并行和query间并行. </p>
<p>类似intel tbb的通用调度器更关注的是吞吐, 数据库系统更关注的是公平性和查询的响应度. DB系统调度器为了在高压导入时依旧能保证低延时会更倾向于执行short running query. 除此以外, 新开启任务的粒度也可以在执行时自适应调整.</p>
<p>本篇论文主要提出了一种创新的无锁自调优调度器. 接下来的内容主要是 Section2 调度器设计. Section 3 关注于morsel-driven数据库系统. 如何通过morsel数据结构让调度变得更鲁棒更可预测. Section 4, 在调度器上加上自适应调优.</p>
<h2 id="Scalable-Task-Scheduling"><a href="#Scalable-Task-Scheduling" class="headerlink" title="Scalable Task Scheduling"></a>Scalable Task Scheduling</h2><p>在task-based的系统中挑选任务的步骤是在用户态进行的，所以调度策略需要尽可能地可拓展并且利用好硬件资源. </p>
<h3 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h3><p>假设$t_i$表示第i个任务,$p_i$表示任务的优先级. 每一个task被赋值stride $S_i&#x3D;(p_i)^{-1}$. 假设所有任务在同一时间到达那么调度策略就变得很简单. 每一个task被映射到一个$P_i$, 这个值一开始设置为0. 之后的处理方式是： 拥有最小pass的任务被选出来执行一段时间片. 执行完后将pass更新为$P_i + S_i$. 任务$t_i$拥有的执行资源比例是$p_i &#x2F; \sum_{k&#x3D;1}^{n} p_k$. Stride调度策略在所有任务都拥有相同优先级的情况下时公平的.</p>
<p>但是如果要适配动态变化的任务则需要有一些修改. 如果一个任务在任意时刻加入则其需要一个初始值. 本文的scheduler会维护一个全局的stride $S_G$ &#x3D; $\left(\sum_{k&#x3D;1}^{n} p_k\right)^{-1}$ 以及一个全局的pass $P_G$. 每过一个调度时间片这个全局的pass都要增加一次全局的stride. 现在这个全局的pass可以用来给一个新到的任务计算初始的initial pass值. 只觉上可以认为这个全局的pass值表示scheduler的时间. 如果任务的pass值比全局pass值$P_G$小那么这个任务还没拿到他应该拥有的资源，反之比全局pass大则是已经使用了太多资源.</p>
<p>Stride调度可以很简单地被拓展到非抢占式设置. 如果一个任务$t_i$消耗了其分配的时间片的$f$那么他的pass就被更新为$P_i$+$fS_i$.同样的全局pass也变成$P_G$+$fS_G$. $f$在这里可能大于1.</p>
<h3 id="Scheduling-in-Umbra"><a href="#Scheduling-in-Umbra" class="headerlink" title="Scheduling in Umbra"></a>Scheduling in Umbra</h3><p><img src="/Self-Tuning-Query-Scheduling-for-Analytical-Workloads/TaskStructureOfUmbra.png" alt="TaskStructureOfUmbra"></p>
<p>每一条pipeline被映射成一个task set. 每一个task set中包含数个task，每个task由数个morsel组成. 同一条query可以有多个task set，这些task set都属于同一个resource group. 如上图中task set 1和2都属于rg1，因为rg1有两条pipeline. 而rg2只有一个所以只有一个task set. 每一个task可以有多个morsel，而morsel有3种状态, finished, running, pending. Worker thread每次pick一个task执行.</p>
<p>同一个task set的task可以被不同的worker thread并行执行以此来提供query的并行度.  query的不同pipeline间可能有顺序依赖所以task set间也是存在顺序依赖的. 例如上图中左边的查询里的pipeline A部分必须在右边的pipeline B开始前完成. 因为hash join的build side必须比probe side先物化. Umbra通过将两条pipeline映射成顺序的task set来保证，在同一个resource group之中的task set必须等待其旗面的task set全部结束后才能开始执行. 这也方便我们在query的粒度追踪资源消耗.</p>
<p>类似Hyper的系统中task和morsel是一比一的关系也就是说一个task只有一个morsel. 但是umbra中一个task可以有任意个morsel. 在umbra中task并不是一开始就被静态创建好了的. 而是在运行时根据运行时的观测性动态调整的.</p>
<h3 id="Thread-local-scheduling"><a href="#Thread-local-scheduling" class="headerlink" title="Thread local scheduling"></a>Thread local scheduling</h3><p>Stride scheduling虽然能提供很强的确定性调度粒度但是他对现代多核硬件并不友好，因为会需要很多同步操作. 本章主要是提出了一种创新的task-based stride 调度实现. 可以在thread-local的底座上执行所有调度决策. Worker线程只会在活跃的task sets发生变化被notify.</p>
<p>当然，和传统的stride scheduling相比也增加了一些限制, 同时存在的resource group(也就是query的数量)是有上限的(但其实这样挺合理的,不做点反压系统搞不好直接被打爆了). 当数量特别多的时候会有一定的性能降级，新的resource group会在任务队列中等待.</p>
<p>本文的设计比较巧妙，虽然是针对stride scheduling algorithm的，但也可以通过仅修改thread-local scheduling的逻辑不需要修改别的部分从而切换到别的调度算法. 作者仅通过修改不了不到100行C++代码就实现了非确定性的lottery调度.</p>
<h4 id="Thread-local-Decisions"><a href="#Thread-local-Decisions" class="headerlink" title="Thread local Decisions"></a>Thread local Decisions</h4><p>全局scope内会维护一个数组，其中每一个slot是一个指针，指向某一个活跃的resource group中的task set. 当某一个RG的task set执行完毕后，会从RG中选一个新的task set放到同一个slot上. 这样的好处是调度时的优先级是绑定到了RG上而不是task set上从而简化了调度. 如果同一个RG的task sets可以被放到不同的slot会增加记账的逻辑.</p>
<p>除此以外所有的调度都是thread-local里发生的. 其中包括一个bitmask，它的作用是记录全局RG数组中的活跃项. 同时也负责优先级和pass value的映射记录. 除此以外每个worker thread也会存储其自己的global pass value. 就如下图所示.</p>
<p><img src="/Self-Tuning-Query-Scheduling-for-Analytical-Workloads/SchedulingStructrue.png" alt="SchedulingStructrue"></p>
<p>如果全局的slot和worker thread的local activity mask是同步的那么调度就很简单, 直接挑选pass value最小的slot，然后在这个slot上进行一个atomic read以获取指向对应task set的指针. 之后便是执行，记录执行时间后更新本地对应的local pass value. 这种处理模式非常轻量, worker在pick 任务的时候不需要别的线程是否pick了相同的task set. 同时全局array中的slot只有在有新的task set的时候才会被写入新数据. 这类写操作发生的频率是比较低的，就不会带来大量的cache无效化同步开销.</p>
<h4 id="修改active-task-sets"><a href="#修改active-task-sets" class="headerlink" title="修改active task sets"></a>修改active task sets</h4><p><img src="/Self-Tuning-Query-Scheduling-for-Analytical-Workloads/ChangeBitmask.png" alt="Figure4"></p>
<p>大部分情况下会尽力最低化同步开销，但是有些全局的信息还是无法避免同步. Worker线程在以下3种事件时需要能过检测到</p>
<ol>
<li>某一个全局array的slot里的task set执行完毕了. Worker必须把本地slot也disable掉(因为这个slot可能之后没有task set了 也就是这个query可能执行完了)</li>
<li>一个新的RG被赋值给一个slot时的初始化task set. worker需要pick这个RG对应的初始pass value和优先级. 并且更新local activity bitmask对应位置</li>
<li>全局slot对应位置的active RG中插入一条新的task set时(比如之前的task set执行完了就切换到下一个task set). worker需要更新本地的active slot并且设置初始pass value(在1中被disable掉了)</li>
</ol>
<p>第一种事件可以只标记对应的pointer而无需通知worker. worker线程拿到slot时读取pointer就能发现已经是disable的状态并更新自己的local 数组</p>
<p>第二种和第三种事件需要引入新的组件. 在每一个worker中会维护两个原子的bitmask. 当worker在全局的slot中插入新的task set时, 所有worker的bitmask都会对应的更新. 两个bitmask分别称为change mask和return mask. 事件2更新change mask事件3更新return mask. 之后用update mask统称两个mask.</p>
<p>更新update bitmask的方式很简单，假如现在全局数组中的第k个slot接收到了一个新的RG的初始task set, 则只要更新每个worker的change mask的第k位为1. 通过原子的fetch or操作即可轻量级更新每一个worker. 类似地，worker线程首先通过原子的exchange操作将update mask都设为0并拿到刚刚被设置的值，并通过刚刚的值来获取全局的slot的状态以此决定是否更新调度策略. 如果根据bitmask获取的值没有特别大的变化则可以避免cache无效化(其实主要是是否更新worker对应的active task set, 如果不需要更新则可以继续pick对应的任务)。 例如在上图中, 第二幅图里全局slot中插入了两个新的task set. 所有worker的update mask也进行了对应的更新. 这里用了return mask来表示TS2是从一个已知的RG中来的，用change mask表示TS3是从一个全新的RG中来的. 此时所有的worker都还在执行TS3的task 他们在第二张image的时候还不会去拉取bitmask的更新到本地的调度状态里.在第三幅图片时第一个worker会将update mask中的信息同步更新, worker 2还在执行TS3的任务不会去更新. 这张figure说明了两个workers不需要同步各自的active task sets.</p>
<h4 id="Task-Set-Finalization"><a href="#Task-Set-Finalization" class="headerlink" title="Task Set Finalization"></a>Task Set Finalization</h4><p>如果RG中的task set A结束了那么需要激活他的下一个task set B(如果存在的话). 只有在task set b的所有前置task set都执行完后才会发生这一步. 当然为了灵活度考虑也允许task sets执行额外的finalization steps. 比如在sort时执行partitions的shuffling或者在grouping时merge部分的聚合结果.</p>
<p>worker会在试图从没有剩余的task的task set获取任务时被notified. 咋一想我们或许可以在这种事件发生时立即开启finalization. 但是别的worker可能还在执行刚刚从这个task set里拿到的task, 如果立马去finalization是很不对的，因为我们必须要在task set的所有任务都结束后才执行finalization, 这种情况也不应该一直等待别的task 完成. 为了解决这个情况Umbra的scheduler引入了一种轻量级的finalization phase.</p>
<p>当一个worker 挑选了一个slot进行执行时它会在全局的state数组上更新自己的决策(发生在原子read全局slot数组前). 之后第一个发现task set耗光了的worker会作为finalization phase的coordinator.</p>
<p>coordinator需要保证最后一个结束对应task的线程能够调用finalization逻辑. coordinator首先在全局slot 数组上将对应的slot里的pointer标记为无效, 这样之后pick这个slot的worker也会将其对应的local slot设置为无。 之后coordinator遍历全局state数组查找有哪些worker还在执行这个task set的task. 对于每一个满足条件的slot信息加上一个专用的finalization marker. 所有被mark的worker thread在结束他们当前的task之后必须显式注销这个task set. 只需要对每一个task set设置一个原子的counter即可做到. coordinator会在遍历完后将counter设置为其成功设置marker的worker数量(不能是设置一个marker就+1一次,一个是这样其实不高效另一个是这样不好确认到底是不是全部执行完了). 对应的worker thread在每次执行完一个task后检查全局state数组是否包含finalization marker，如果有则对counter减1(注意，这个counter可能变成负数, 因为有个worker可能在coordinator遍历完以前就执行完并减1了). 将counter置为0的worker可以保证是最后一个(因为这个counter只能一次性增加，就避免了刚+1就-1的情况), 他可以执行最终的finalization逻辑-&gt; 在当前RG中查找是否有剩下的task set，如果有就设置如果没有就去全局wait queue中获取新的 RG.</p>
<p>这个finalization phase的开销几乎只是对全局state 数组的更新. 只要别的worker不在coordinator更新对应的slot的时候试图去pick task set则不会发生竞争. 并且只有pin了相同RG的worker才可能被影响. 所有会被影响到的线程理论上并不多(特别是在query比较多的场景，只要不是所有的worker都在处理同一个RG其实很难有特别多竞争).</p>
<h2 id="Robust-Morsel-Scheduling"><a href="#Robust-Morsel-Scheduling" class="headerlink" title="Robust Morsel Scheduling"></a>Robust Morsel Scheduling</h2><p>上一章介绍了lock-free的stride scheduler. 这一章介绍在此基础上利用morsel-based task进行的优化.</p>
<p>首先介绍如何将morsel-driven parallelism变得robust. 传统方式task:morsel的比例导致task粒度有方差从而导致不理想的调度失真. 调度的开销变得很难预测而且会有worker长时间被阻塞. 本文作者通过标准化task的执行时间来保证了调度开销可预测以及强响应度.</p>
<p>第二步是利用数据库的领域知识来优化混合分析负载中的查询延时. 通过优先级策略，本文的stride scheduler提供了细粒度的资源消耗控制. 而这是通过自适应的优先级调整策略做到的.</p>
<h3 id="Adaptive-Morsel-Execution"><a href="#Adaptive-Morsel-Execution" class="headerlink" title="Adaptive Morsel Execution"></a>Adaptive Morsel Execution</h3><p>类似Hyper的系统中morsel:task是1比1，但其实不同的morsel的执行耗时很很不同的(因为不同的pipeline执行的逻辑本身也不同,复杂度也不同)<br>. 比如假设一个pipeline中时简单的selectiton然后插入到hashtable, 那么在相同的morsel大小的情况下他的执行时间肯定是比一条包括复杂的字符串匹配和一系列hash table probe的pipeline要短的. 这意味着对于scheduler来说不同任务的粒度是差别很大的. 如果继续采用这种1:1映射那么在选择morsel大小时就需要考虑不同的tradeoff. 如果太小那么会产生更多次的schedule相应的schedule开销也更大, 如果太长, 那么有的morsel在有的pipeline中执行时间太长会影响整个系统的响应度.</p>
<p>传统的模式在两个维度是静态的:1. 依赖于固定的morsel大小 2. 依赖于静态的morsel和task的映射.</p>
<p>本文提出了一个创新的渐进式框架. 调度器定义一个目标时间$t_max$. 在挑选任务的时候调度器尽量调度能够准确满足这个目标的morsels. 也就是说这个框架能够1.使用动态的不定size morsel大小 2. 执行不同数量的morsels. 另外调度器对task的结构是无感的，这也让整个调度压力变得可预测了. Umbra将这个值设置为2ms. 作者认为这个大小兼顾了调度的负担以及响应度. 另外据作者的观测调度策略一般只需要不到1ms就能决定，也就是说负载大概也就0.05%</p>
<p>通过将pipeline转换为状态机以不同的执行阶段采取不同的策略来达到目标时间. 不同的状态暗示了需要pick多少个morsel. 因为morsel是在运行时从tuples的集合中算出来的，所以动态地通过不同的morsel size填充task size是可行的.</p>
<h4 id="Default-state"><a href="#Default-state" class="headerlink" title="Default state"></a>Default state</h4><p>默认状态时会试着挑取一个能够满足$t_max$的morsel. 这需要系统能够提供一个准确的吞吐估算值$T$, 表示每秒多少tuple. 这样一个morsel则是T*$t_max$的tuples. 而当这个morsel执行完后便能拿到实际的执行时间$t$. 对刚刚的吞吐估算值进行一个修正$\hat{T}&#x3D;(T\cdot t_{\max})&#x2F;t$. 根据旧的吞吐量T和系数$\alpha \in [0, 1]$, 那么新的则是$T^{\prime}&#x3D;\alpha\hat{T}+(1-\alpha).T$.</p>
<h4 id="Startup-State"><a href="#Startup-State" class="headerlink" title="Startup State"></a>Startup State</h4><p>这个state用来提供一个初始的吞吐估算. 这个state会按照指数关系不停pick不同size的morsel指到达到$t_max$</p>
<h4 id="Optimizations"><a href="#Optimizations" class="headerlink" title="Optimizations"></a>Optimizations</h4><p>还引入了两个优化. 一个是除了上述两种state还有一个shutdown state. 通过当前的吞吐估算值以及剩余的tuples数量可以大概计算出剩余所需的pipeline执行时间. 假设我们有M个worker, 一旦可预测的剩余的总时间低于$W\cdot t_{max}$就会进入shutdown state. 假设预期剩余总时间为t，morsel的最短执行时间为$t_min$, 我们将morsels调度为$\max(\frac{t}{W},t_{\min})$. 另一个优化是为了应对不支持自适应morsel size的tasks. 这类必须高效处理因为有些任务不具有高度的自适应. 如果运行时发现有的任务消耗的只是target duration的一部分可以允许这类任务继续消费直到达到$t_max$</p>
<h4 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h4><p><img src="/Self-Tuning-Query-Scheduling-for-Analytical-Workloads/MorselSizeComparison.png" alt="MorselSizeComparison"></p>
<p>这个图能看出来不同阶段的效果, 特别是startup阶段的两倍指数</p>
<h3 id="Adaptive-Query-Priorities"><a href="#Adaptive-Query-Priorities" class="headerlink" title="Adaptive Query Priorities"></a>Adaptive Query Priorities</h3><p>不同的任务可以有不同的优先级. 数据库不应该让用户处理workload管理中的繁琐细节. Umbra利用自适应查询优先级来透明化地按照短作业优先的方式处理. 不需要用户输入而是在运行时根据query的性质赋予优先级. 首先定义”desirable”延迟. 假设所有的query都是一样重要的. 在这个假设下提出两个基础原则.</p>
<ol>
<li>查询延迟在load时也得保持可预测性.</li>
</ol>
<p>如果系统同时接受两条query, 短一些query需要先结束.</p>
<ol start="2">
<li>查询延迟需要尽量低.</li>
</ol>
<p>如果数据库遵守这两条那么是可以做到可预测和高性能的. 不过公平调度只能保证1不能保证2. 因为短作业一般不会特别影响到长作业的延迟. 比如我们有9成的短作业他们耗时10ms，只有一成的长作业，他们耗时1s. 即使使用短作业优先的方式，对于长作业也只有10%的影响.</p>
<p>本文提出的自适应优先级策略就是为了透明地给短作业赋予优先级. 处理起来和多级反馈队列很像，一个查询的优先级取决于他到目前为止消耗的CPU资源. 因为作者将query包装成了一个RG, 所以查询的优先级其实也就是query的优先级. 可以按照如下公式处理:</p>
<p>$P_{i+1}&#x3D;\begin{cases}P_{i},i&lt;d_{start}\\max(P_{min},\lambda P_{i}),i\geq d_{start}\end{cases}$</p>
<p>有3个参数, $d_start$表示RG的优先级开始衰退的时间, 衰退的速度控制在$\lambda\in[0,1]$. 优先级最低到$p_min$.</p>
<p>和公平调度相比，这种调度策略能提供更大的相对性能差异. 但是为了实现短作业任务的高性能也是必须的. 尽管如此还是保证了原则(1). 同时到达的两条query的优先级退化速度是一致的也就是说短的一个会在同样的资源分配下先结束.</p>
<h3 id="自定义优先级"><a href="#自定义优先级" class="headerlink" title="自定义优先级"></a>自定义优先级</h3><p>当然也可以让用户自己定义优先级. 有两种简单的方式实现</p>
<ol>
<li>特别重要的query可以允许用户设置一个不同的静态初始优先级并且这个优先级是静态的不会衰退</li>
<li>也可以将优化级和用户绑定. 这样用户优先级可以影响他的所有query的衰退速度.</li>
</ol>
<h2 id="Self-tuning-Scheduling"><a href="#Self-tuning-Scheduling" class="headerlink" title="Self-tuning Scheduling"></a>Self-tuning Scheduling</h2><p>TODO</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/06/24/%E6%B5%85%E8%B0%88%E5%8D%8F%E7%A8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/06/24/%E6%B5%85%E8%B0%88%E5%8D%8F%E7%A8%8B/" class="post-title-link" itemprop="url">浅谈协程</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-06-24 22:14:29" itemprop="dateCreated datePublished" datetime="2023-06-24T22:14:29+08:00">2023-06-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-10-15 13:09:45" itemprop="dateModified" datetime="2023-10-15T13:09:45+08:00">2023-10-15</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>这篇博文主要是结合笔者以前在字节跳动实习时在内部做的一次分享以及近年来的一些新的感悟来谈一下协程的部分内容，这篇博文不会过多讨论协程如何进行调度以及如何进行任务的组合等部分，主要是围绕为何会有协程,协程的分类以及不同的实现，另外也简单聊一下使用协程的心得.</p>
<h3 id="为什么我们想要协程"><a href="#为什么我们想要协程" class="headerlink" title="为什么我们想要协程"></a>为什么我们想要协程</h3><p>亦可参考Google于13年的一次<a target="_blank" rel="noopener" href="https://dokumen.tips/documents/paul-turner-pjt-with-threads-turner-pjt-google-confidential-and-proprietary.html?page=17">分享</a></p>
<p>首先为什么会想要使用协程呢？先从网络编程中几种模式说起，这里我们基于asio的代码来讨论，先用最传统的阻塞式的网络编程模式实现echo server就如同如下代码</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">try</span></span><br><span class="line">  &#123;</span><br><span class="line">    boost::asio::io_context io_context;</span><br><span class="line">    <span class="function">tcp::acceptor <span class="title">acceptor</span><span class="params">(io_context, tcp::endpoint(tcp::v4(), <span class="number">8000</span>))</span></span>;</span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>)</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="function">tcp::socket <span class="title">socket</span><span class="params">(io_context)</span></span>;</span><br><span class="line">      acceptor.<span class="built_in">accept</span>(socket);</span><br><span class="line">      boost::system::error_code error;</span><br><span class="line">      <span class="keyword">while</span> (<span class="literal">true</span>)</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="type">char</span> data[<span class="number">1024</span>];</span><br><span class="line">        <span class="type">size_t</span> length = socket.<span class="built_in">read_some</span>(boost::asio::<span class="built_in">buffer</span>(data), error);</span><br><span class="line">        <span class="keyword">if</span> (error == boost::asio::error::eof)</span><br><span class="line">          <span class="keyword">break</span>; <span class="comment">// Connection closed cleanly by peer.</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (error)</span><br><span class="line">          <span class="keyword">throw</span> boost::system::<span class="built_in">system_error</span>(error); <span class="comment">// Some other error.</span></span><br><span class="line">        boost::asio::<span class="built_in">write</span>(socket, boost::asio::<span class="built_in">buffer</span>(data, length));</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">catch</span> (std::exception&amp; e)</span><br><span class="line">  &#123;</span><br><span class="line">    std::cerr &lt;&lt; <span class="string">&quot;Exception: &quot;</span> &lt;&lt; e.<span class="built_in">what</span>() &lt;&lt; std::endl;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>因为使用的是阻塞的模式，这段代码的吞吐量特别慢，因为每次只能处理一个连接的请求，并且一次连接的请求没能处理完完全不会去处理下一段。</p>
<p>有的人会想或许我们可以采取每一条连接都开启一个新线程进行处理的方式</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thread&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;asio.hpp&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> asio::ip;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">do_echo</span><span class="params">(tcp::socket socket)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">try</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">char</span> data[<span class="number">1024</span>];</span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            std::<span class="type">size_t</span> length = socket.<span class="built_in">read_some</span>(asio::<span class="built_in">buffer</span>(data));</span><br><span class="line">            asio::<span class="built_in">write</span>(socket, asio::<span class="built_in">buffer</span>(data, length));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">catch</span> (std::exception&amp; e)</span><br><span class="line">    &#123;</span><br><span class="line">        std::cerr &lt;&lt; <span class="string">&quot;Exception in thread: &quot;</span> &lt;&lt; e.<span class="built_in">what</span>() &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">do_accept</span><span class="params">(asio::ip::tcp::acceptor&amp; acceptor, asio::io_service&amp; io_service)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    acceptor.<span class="built_in">async_accept</span>(io_service,</span><br><span class="line">        [&amp;acceptor, &amp;io_service](std::error_code ec, tcp::socket socket)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (!ec)</span><br><span class="line">            &#123;</span><br><span class="line">                std::<span class="built_in">thread</span>(do_echo, std::<span class="built_in">move</span>(socket)).<span class="built_in">detach</span>();</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="built_in">do_accept</span>(acceptor, io_service);</span><br><span class="line">        &#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span>* argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">try</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (argc != <span class="number">2</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            std::cerr &lt;&lt; <span class="string">&quot;Usage: echo_server &lt;port&gt;\n&quot;</span>;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        asio::io_service io_service;</span><br><span class="line">        <span class="function">tcp::acceptor <span class="title">acceptor</span><span class="params">(io_service, tcp::endpoint(tcp::v4(), std::atoi(argv[<span class="number">1</span>])))</span></span>;</span><br><span class="line">        <span class="built_in">do_accept</span>(acceptor, io_service);</span><br><span class="line">        io_service.<span class="built_in">run</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">catch</span> (std::exception&amp; e)</span><br><span class="line">    &#123;</span><br><span class="line">        std::cerr &lt;&lt; <span class="string">&quot;Exception: &quot;</span> &lt;&lt; e.<span class="built_in">what</span>() &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上面这种形式在连接数较少时也是能work的，但是当连接数量达到几十万条甚至更多的时候呢？假设有10w个连接，Linux下每个线程的栈默认大小为8M，那么一下子就会消费80G的内存,再算上线程切换的开销，可以想象服务的负载会有多么大，这似乎并不是一条很靠谱的解决方案.<br>接下来我们试着用最简单的回调的方式进行异步化改造</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;boost/asio.hpp&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> boost::asio::ip::tcp;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">session</span><span class="params">(tcp::socket socket)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  std::array&lt;<span class="type">char</span>, 1024&gt; buffer;</span><br><span class="line">  boost::system::error_code error;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 异步读取来自客户端的数据</span></span><br><span class="line">  socket.<span class="built_in">async_read_some</span>(boost::asio::<span class="built_in">buffer</span>(buffer), [&amp;](boost::system::error_code ec, std::<span class="type">size_t</span> length)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">if</span> (!ec)</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="comment">// 将数据回显回客户端</span></span><br><span class="line">      boost::asio::<span class="built_in">async_write</span>(socket, boost::asio::<span class="built_in">buffer</span>(buffer, length),</span><br><span class="line">        [&amp;](boost::system::error_code ec, std::<span class="type">size_t</span> <span class="comment">/*length*/</span>)</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="keyword">if</span> (!ec)</span><br><span class="line">          &#123;</span><br><span class="line">            <span class="comment">// 继续异步读取来自客户端的数据</span></span><br><span class="line">            <span class="built_in">session</span>(std::<span class="built_in">move</span>(socket));</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">try</span></span><br><span class="line">  &#123;</span><br><span class="line">    boost::asio::io_context io_context;</span><br><span class="line">    <span class="function">tcp::acceptor <span class="title">acceptor</span><span class="params">(io_context, tcp::endpoint(tcp::v4(), <span class="number">8000</span>))</span></span>;</span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>)</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="function">tcp::socket <span class="title">socket</span><span class="params">(io_context)</span></span>;</span><br><span class="line">      acceptor.<span class="built_in">accept</span>(socket);</span><br><span class="line">      <span class="comment">// 启动异步会话</span></span><br><span class="line">      <span class="built_in">session</span>(std::<span class="built_in">move</span>(socket));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">catch</span> (std::exception&amp; e)</span><br><span class="line">  &#123;</span><br><span class="line">    std::cerr &lt;&lt; <span class="string">&quot;Exception: &quot;</span> &lt;&lt; e.<span class="built_in">what</span>() &lt;&lt; std::endl;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上面这段代码中所有的io操作都是异步的,即使只有一个线程的情况下也能提供很强的吞吐(参考nodejs)，因为其中所有的IO操作都是非阻塞的，加上使用了IO多路复用技术可以保证一个线程中处理多个request时不会出现某个request的io卡住导致所有request全部饿死的情况。但是可以看到这种方式的代码中无可避免的会使用回调(echo server这种比较简单的情况只有2层回调，但是如果我们是http服务器呢？读到数据后先进行encode&#x2F;decode,然后路由到对应的处理函数)，当回调层数越深的时候丢失的代码上下文就越多，在debug的时候就更费劲.<br>另外异步+回调更容易让程序员迷失在对象的生命周期之中，一种很常见的问题是，对象A在线程1里析构了，但是被线程2访问了，这就会导致heap-use-after-free的问题。有的人会argue到使用shared_ptr来解决问题，但是如果shared_ptr引用的原子变量的开销在很多时候也不可小觑，更不用提enable_shared_from被滥用的话带来的问题。</p>
<p>下面我们用asio的协程来编写刚刚的功能.</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">report_error</span><span class="params">(std::string_view component, sys::error_code ec)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  std::cerr &lt;&lt; component &lt;&lt; <span class="string">&quot; failure: &quot;</span></span><br><span class="line">            &lt;&lt; ec &lt;&lt; <span class="string">&quot; ()&quot;</span> &lt;&lt; ec.<span class="built_in">message</span>() &lt;&lt; <span class="string">&quot;)\n&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function">asio::awaitable&lt;<span class="type">void</span>&gt; <span class="title">session</span><span class="params">(tcp::socket socket)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">try</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="type">char</span> data[<span class="number">1024</span>];</span><br><span class="line">    <span class="keyword">for</span> (;;)</span><br><span class="line">    &#123;</span><br><span class="line">      std::<span class="type">size_t</span> n = <span class="keyword">co_await</span> socket.<span class="built_in">async_read_some</span>(asio::<span class="built_in">buffer</span>(data), asio::use_awaitable);</span><br><span class="line">      <span class="function"><span class="keyword">co_await</span> <span class="title">async_write</span><span class="params">(socket, asio::buffer(data, n), asio::use_awaitable)</span></span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">catch</span> (sys::system_error <span class="type">const</span>&amp; e)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">if</span> (e.<span class="built_in">code</span>() == asio::error::eof)</span><br><span class="line">      std::cerr &lt;&lt; <span class="string">&quot;Session done \n&quot;</span>;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">      <span class="built_in">report_error</span>(<span class="string">&quot;Session&quot;</span>, e.<span class="built_in">code</span>());</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function">asio::awaitable&lt;<span class="type">void</span>&gt; <span class="title">listener</span><span class="params">(asio::io_context&amp; context, <span class="type">unsigned</span> <span class="type">short</span> port)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="function">tcp::acceptor <span class="title">acceptor</span><span class="params">(context, &#123;tcp::v4(), port&#125;)</span></span>;</span><br><span class="line"> </span><br><span class="line">  <span class="keyword">try</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">for</span> (;;)</span><br><span class="line">    &#123;</span><br><span class="line">      tcp::socket socket = <span class="keyword">co_await</span> acceptor.<span class="built_in">async_accept</span>(asio::use_awaitable);</span><br><span class="line">      asio::<span class="built_in">co_spawn</span>(context, <span class="built_in">session</span>(std::<span class="built_in">move</span>(socket)), asio::detached);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">catch</span> (sys::system_error <span class="type">const</span>&amp; e)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="built_in">report_error</span>(<span class="string">&quot;Listener&quot;</span>, e.<span class="built_in">code</span>());</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">try</span></span><br><span class="line">  &#123;</span><br><span class="line">    asio::io_context context;</span><br><span class="line"> </span><br><span class="line">    <span class="function">asio::signal_set <span class="title">signals</span><span class="params">(context, SIGINT, SIGTERM)</span></span>;</span><br><span class="line">    signals.<span class="built_in">async_wait</span>([&amp;](<span class="keyword">auto</span>, <span class="keyword">auto</span>)&#123; context.<span class="built_in">stop</span>(); &#125;);</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">auto</span> listen = <span class="built_in">listener</span>(context, <span class="number">55555</span>);</span><br><span class="line">    asio::<span class="built_in">co_spawn</span>(context, std::<span class="built_in">move</span>(listen), asio::detached);</span><br><span class="line"> </span><br><span class="line">    context.<span class="built_in">run</span>();</span><br><span class="line">    std::cerr &lt;&lt; <span class="string">&quot;Server done \n&quot;</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">catch</span> (std::exception&amp; e)</span><br><span class="line">  &#123;</span><br><span class="line">    std::cerr &lt;&lt; <span class="string">&quot;Server failure: &quot;</span> &lt;&lt; e.<span class="built_in">what</span>() &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到在协程版本的代码中我们并不需要像异步版本的代码一样写很多的回调函数，更多的是<code>co_await expression</code>这样类似函数调用的写法，我们的代码不需要再非常的割裂，可以和同步编程时的代码似乎没有太大的差别，同时这样的代码也不会出现同步阻塞代码中处理一条请求时无法处理新来的请求的情况，程序的吞吐也能很可观。同时也不会出现per-thread-per-connection版本中的线程消耗问题.</p>
<p>下文中我们简单描述一下不同的协程的实现原理</p>
<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><h3 id="按照是否保存调用栈区分"><a href="#按照是否保存调用栈区分" class="headerlink" title="按照是否保存调用栈区分"></a>按照是否保存调用栈区分</h3><p>首先有栈无栈协程在执行的时候都是要使用到程序内存空间当中的栈的，而他们的名字之中的有栈无栈指的是是否保存自己的调用栈，有栈协程会将从协程起始点开始到挂起点为止的所有栈上的变量都保存到自己的栈之中,当发生协程切换的时候会替换挂起协程和恢复协程的栈,这样就可以在另一个协程的挂起点上恢复。这里我们先卖个关子不谈这有什么差异</p>
<p>现在我们设想一个场景，在某个协程C的上下文中调用函数F，这个协程能在什么地方挂起？<br>在有栈协程中，假设C调用到F的时候调用栈如下:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">|      Stack Frame f     |   &lt;- 在这里的任意时刻挂起</span><br><span class="line">+----------------------+</span><br><span class="line">|  Local Variables f    |</span><br><span class="line">|                      |</span><br><span class="line">|                      |</span><br><span class="line">|                      |</span><br><span class="line">|                      |</span><br><span class="line">+----------------------+</span><br><span class="line">|  Return Address f    |</span><br><span class="line">+----------------------+</span><br><span class="line">|       Ctx Of C       |</span><br><span class="line">+----------------------+</span><br></pre></td></tr></table></figure>

<p>有栈协程能够将C中jmp F到F执行的任意时刻的堆栈给保存下来，之后也可以切换回来. 这里用Linux kernel中的process&#x2F;thread调度做一个简单的类比，Linux中不管是process还是thread都是用task_struct保存其对应的属性的，内核在进行调度的时候也是将当前的process&#x2F;thread对应的task_struct切出并替换成另一个task_struct，这样就完成了切换。所以我们甚至可以说如果有syscall api能够让用户自己指定将当前process&#x2F;thread切换到pid所对应的process&#x2F;thread，那么内核其实也提供了手动实现的有栈协程的手段.(实际上Google还真想<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=KXuZi9aeGTw">这么</a>干)</p>
<p>接下来我们讨论无栈协程的实现。无栈协程并不会单独保存协程的整个stack frame,类比上面有栈协程的图来对比的话就是无栈协程只能在<strong>被标注可以挂起的地方</strong>挂起. 假设我们有这样一段代码</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Task&lt;<span class="type">int</span>&gt; <span class="title">coro</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> i = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">co_yield</span> i;</span><br><span class="line">  i++;</span><br><span class="line">  <span class="keyword">co_yield</span> i;</span><br><span class="line">  i++;</span><br><span class="line">  <span class="keyword">co_return</span> i;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这段代码中只有3个co_xxx的地方可以挂起，这段代码可能会被编译器修改成这样</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">CoroutineState</span> &#123;</span><br><span class="line">  <span class="type">int</span> i;</span><br><span class="line">  <span class="type">int</span> state;</span><br><span class="line">  <span class="built_in">CoroutineState</span>() : <span class="built_in">i</span>(<span class="number">0</span>), <span class="built_in">state</span>(<span class="number">0</span>) &#123;&#125;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">coro</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">switch</span> (state) &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="number">0</span>:</span><br><span class="line">        state = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">return</span> i;</span><br><span class="line">      <span class="keyword">case</span> <span class="number">1</span>:</span><br><span class="line">        i++;</span><br><span class="line">        state = <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">return</span> i;</span><br><span class="line">      <span class="keyword">case</span> <span class="number">2</span>:</span><br><span class="line">        i++;</span><br><span class="line">        <span class="keyword">return</span> i;</span><br><span class="line">      <span class="keyword">default</span>:</span><br><span class="line">        <span class="comment">// shoule never come here</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>可以看到整个函数被转换成了一个状态机类，在函数内部的局部变量会被捕获到这个类中作为成员变量，而不同的挂起点对应不同的状态。可以认为无栈协程会被状态成状态机代码来执行(熟悉Js的小伙伴会不会想到Promise呢).敏锐的小伙伴肯定也意识到了，编译器帮我们将无栈协程转换成了对应的状态机或者结构体(在rust中的future,JS中的promise)，那只要拿到这个对应的handler就能自己决定在哪儿resume(这也给众多的库作者提供了自己手写runtime scheduler的方式).</p>
<p>但是说了这么多无栈和有栈的区别能如何更具体的体现呢？我们按照一段伪代码来分析在无栈和有栈时的不同情况</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">function <span class="title">foo</span><span class="params">()</span>:</span></span><br><span class="line"><span class="function">    ...</span></span><br><span class="line"><span class="function">    return <span class="number">42</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">function coroFun():</span></span><br><span class="line"><span class="function">    yield <span class="number">100</span></span></span><br><span class="line"><span class="function">    i =</span> <span class="built_in">foo</span>()</span><br><span class="line">    yield <span class="number">101</span></span><br></pre></td></tr></table></figure>

<p>无栈协程无法在<code>foo()</code>上挂起,因为foo中没有挂起点,这意味着没有告诉编译器怎么将<code>foo()</code>转变成一个结构体保存其对应的堆栈上下文也不知道在什么地方挂起和回复. 但是有栈协程因为从协程起始点开始保存了所有的栈信息所以即使到了<code>foo()</code>函数中也能一并保存，可以随时挂起.这就是为什么无栈协程only the top-level coroutine may be suspended.</p>
<h3 id="协程的使用"><a href="#协程的使用" class="headerlink" title="协程的使用"></a>协程的使用</h3><ol>
<li><p>首先第一个问题，协程是适合IO密集型任务还是计算密集任务？答案是IO密集型任务，协程最直观的好处在于他的切换代价非常低，所以对于IO密集型任务可以在IO发生阻塞时(所以一般需要结合非阻塞IO使用，当返回EWOULDBLOCK的时候就可以出让本协程了)切换到另一个协程，这样代价相比线程IO切换会低上很多。</p>
</li>
<li><p>那如果有了协程我的并行度会有提升吗？并行度的上限理论上还是和CPU core数量有关，同一时间能并行执行的任务并不会因为协程数量更多切换代价更低而提升。协程的好处是在避免因为过多的回调引起程序的非结构化的基础上还能提供有效的异步编程手段以提升程序的吞吐(参考单线程的NodeJS).</p>
</li>
<li><p>协程使用中应该使用什么同步原语？如果还是使用pthread_xxx同步原语的话同步的粒度是thread级别的，不管是有栈协程还是无栈协程对于操作系统来说都是运行在用户态的函数，比如一旦使用pthread_lock上锁那整个线程都将阻塞自然而然也就没有了切换协程的能力。这也是为什么在不同的协程实现中都会带上一套自己的同步原语(比如bmutex之于bthread, tokio::sync::Mutex之于rust). 之后的博文也会介绍如何实现不同的协程如何实现自己的同步原语. 当然，在库级别的协程的同步原语在多个库混杂时也会造成一些问题，比如我在bthread里面如果使用了folly::fiber的同步原语会发生什么？</p>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/06/17/%E8%AF%91From-Eager-Futures-Promises-to-Lazy-Continuations/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/06/17/%E8%AF%91From-Eager-Futures-Promises-to-Lazy-Continuations/" class="post-title-link" itemprop="url">译From Eager  Futures/Promises  to Lazy Continuations</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-06-17 23:23:03" itemprop="dateCreated datePublished" datetime="2023-06-17T23:23:03+08:00">2023-06-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-06-18 14:31:28" itemprop="dateModified" datetime="2023-06-18T14:31:28+08:00">2023-06-18</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>译者一直对有关coroutine和execution的概念非常迷恋，近来希望将对这部分内容的学习心得简单分享一下提升下自己的理解，预计会有5 6篇博文产出，先以这篇CppCon的翻译起个头</p>
<p>下文会从pdf的第一章开始翻译</p>
<h2 id="motivating-futures-x2F-promises-actors"><a href="#motivating-futures-x2F-promises-actors" class="headerlink" title="motivating futures&#x2F;promises + actors"></a>motivating futures&#x2F;promises + actors</h2><p>当工程师试图打造一款高性能且正确的分布式系统时会遇到许多关键挑战。概括下来有两条</p>
<ol>
<li>在代码中不得不有等待的条件</li>
<li>在代码中有state</li>
</ol>
<h3 id="如何解决等待的问题"><a href="#如何解决等待的问题" class="headerlink" title="如何解决等待的问题"></a>如何解决等待的问题</h3><p>以下面的代码为例</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">std::string text=<span class="string">&quot;...&quot;</span>;</span><br><span class="line">text = <span class="built_in">SpellCehck</span>(text);</span><br><span class="line">text = <span class="built_in">GrammerCheck</span>(text);</span><br></pre></td></tr></table></figure>

<p>上面的代码可通过函数的组合修改成一行<code>GrammerCheck(SpellCehck(&quot;...&quot;))</code>. 不过接下来我们还是分开分析，先分析SpellCheck函数的实现</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">std::string <span class="title">SpellCheck</span><span class="params">(std::string text)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> body = http::<span class="built_in">UrlEncode</span>(&#123;<span class="string">&quot;text&quot;</span>, text&#125;);</span><br><span class="line">  <span class="keyword">auto</span> response = http::<span class="built_in">Post</span>(<span class="string">&quot;https://www.online-spellcheck.com&quot;</span>, body);</span><br><span class="line">  <span class="keyword">return</span> response.body;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>无论这段代码之中的<code>Http::Post</code>方法是阻塞的还是非阻塞都不会改变一件事实：你的代码不得不在这里等待<br>可能的解决方案如下：</p>
<ol>
<li>就死等. 这个方案肯定是不会采纳的</li>
<li>使用线程. 成本高昂同时对正确性无益</li>
<li>使用coroutine. 作者当时是09年 还没有好用的C++ coroutine</li>
<li>使用不同的语言比如erlang 或者 把erlang带进C++之中</li>
<li>使用回调函数，之后会讨论这个</li>
<li>使用future&#x2F;promise</li>
</ol>
<p>接下来我们讨论future&#x2F;promise。<br>future&#x2F;promise就像buffered channel一样</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Promise&lt;std::string&gt; promise;</span><br><span class="line">---------------thread x-------------</span><br><span class="line">Channel::Reader&lt;std::string&gt; reader = channel.<span class="built_in">Reader</span>();</span><br><span class="line">reader.<span class="built_in">Read</span>(); <span class="comment">// Blocks!</span></span><br><span class="line">---------------thread y-------------</span><br><span class="line">Channel::Writer&lt;std::string&gt; writer = channel.<span class="built_in">Writer</span>();</span><br><span class="line">writer.<span class="built_in">Write</span>(<span class="string">&quot;...&quot;</span>); <span class="comment">// Non-blocking!</span></span><br><span class="line">writer.<span class="built_in">Close</span>();</span><br></pre></td></tr></table></figure>

<p>改为future代码如下</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Promise&lt;std::string&gt; promise;</span><br><span class="line">---------------thread x-------------</span><br><span class="line">Future&lt;std::string&gt; future = promise.<span class="built_in">Future</span>();</span><br><span class="line">future.<span class="built_in">Get</span>(); <span class="comment">// Blocks!</span></span><br><span class="line">---------------thread y-------------</span><br><span class="line">promise.<span class="built_in">Set</span>(<span class="string">&quot;...&quot;</span>); <span class="comment">// Non-blocking!</span></span><br></pre></td></tr></table></figure>

<p>接下来我们用future来修改SpellCheck函数</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 这里我们异步地请求Post方法，并通过future拿到对应的返回值</span></span><br><span class="line"><span class="function">Future&lt;std::string&gt; <span class="title">SpellCheck</span><span class="params">(std::string text)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> body = http::<span class="built_in">UrlEncode</span>(&#123;<span class="string">&quot;text&quot;</span>, text&#125;);</span><br><span class="line">  Promise&lt;std::string&gt; promise;</span><br><span class="line">  <span class="keyword">auto</span> future = promise.<span class="built_in">Future</span>();</span><br><span class="line">  http::<span class="built_in">AsyncPost</span>(</span><br><span class="line">      <span class="string">&quot;https://www.online-spellcheck.com&quot;</span> ,</span><br><span class="line">      body,</span><br><span class="line">      [promise = std::<span class="built_in">move</span>(promise)]( <span class="keyword">auto</span>&amp;&amp; response) &#123;</span><br><span class="line">        <span class="keyword">if</span> (response.code != <span class="number">200</span>) promise.<span class="built_in">Fail</span>(response.code); </span><br><span class="line">        <span class="keyword">else</span> promise.<span class="built_in">Set</span>(response.body);</span><br><span class="line">      &#125;);</span><br><span class="line">  <span class="keyword">return</span> future;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>假如现在我们的SpellCheck和GrammarCheck两个函数都试用了future&#x2F;promise的方法改造，那么我们会碰到接下来的问题</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">std::string text = <span class="string">&quot;...&quot;</span>; </span><br><span class="line">text = <span class="built_in">SpellCheck</span>(text). <span class="built_in">Get</span>(); <span class="comment">// Blocks!</span></span><br><span class="line">text = <span class="built_in">GrammarCheck</span>(text). <span class="built_in">Get</span>(); <span class="comment">// Blocks!</span></span><br></pre></td></tr></table></figure>

<p>可以看到这两个方法的Get都会是阻塞的，那不相当于我们的代码又变成串行阻塞的了吗？这里的函数逻辑是在完成spellcheck后再调用grammarcheck，也就是说这里的Control Flow应该是<code>SpellCheck -&gt; GrammarCheck</code>那么这里如果可以让两个future拥有future a异步执行完了之后(then)执行b的语义似乎能避免对应的阻塞，假设C++的future能提供类似JavaScript的<code>.then</code>接口继续讨论这个问题.那么对应代码或许可以这样修改</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 这里将SpellCheck和GrammerCheck组合到一个函数SpellAndGrammarCheck之中</span></span><br><span class="line"><span class="function">Future&lt;std::string&gt; <span class="title">SpellAndGrammarCheck</span> <span class="params">(std::string text)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">SpellCheck</span>(text)</span><br><span class="line">      .<span class="built_in">Then</span>([](<span class="keyword">auto</span>&amp;&amp; text) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">GrammarCheck</span>(text);<span class="comment">// Can be a Future&lt;T&gt; or T.</span></span><br><span class="line">      &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>到这里我们似乎解决了等待的问题.</p>
<h3 id="如何解决状态的问题"><a href="#如何解决状态的问题" class="headerlink" title="如何解决状态的问题"></a>如何解决状态的问题</h3><p>使用future&#x2F;promises执行代码的一些性质</p>
<ul>
<li>因为代码中从不block所以可以只有一个线程便执行(类型JavaScript的模型，只有基于libuv提供的单线程event loop)</li>
<li>然后代码并不一定能原子地执行，因为当代码中出现必须等待别的代码时就出现了交互(在不得不等待时会有别的代码被执行就是问题的关键)</li>
<li>许多人称这种情况为”concurrency” vs parallelism因为这种模式给了你并发执行的错觉然而你并没有同时在执行</li>
<li>但是你依旧得忍受并发执行所带来的同步问题</li>
<li>也可以基于多线程执行代码</li>
</ul>
<p>可能的解决方案如下：</p>
<ul>
<li>1963年提出了mutexes和semaphore</li>
<li>1973年提出了actors</li>
<li>1974年提出了monitors</li>
<li>1978年提出了communicating sequential processes</li>
<li>1987年提出了statecharts</li>
</ul>
<p>其中mutexes，semaphores和monitors都是基于threads的解决方案<br>而actors，csp，statecharts是没有线程的解决方案</p>
<p>没有线程会是什么情况？<br>没有线程的抽象包含了执行模型&#x2F;语义和状态的同步<br>actors包括了执行，同步，状态</p>
<p>包括得更多 -&gt; 更高级的抽象能带来</p>
<ul>
<li>更容易理解</li>
<li>更容易在更多的硬件和平台运行</li>
<li>更容易优化</li>
</ul>
<p>actors的性质</p>
<ul>
<li>本地可修改状态</li>
<li>消息队列</li>
<li>一次接受并处理一条消息</li>
<li>actors之间发送消息是非阻塞的</li>
<li>不论是local还是distributed模式都是同样的编程模型</li>
</ul>
<p>下面我们看一段在C++中的actor模型的代码</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">MyActor</span> : <span class="keyword">public</span> Actor &#123;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Receive</span><span class="params">(ActorId sender, Message message, <span class="type">void</span>* arguments)</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">    <span class="keyword">switch</span> (message) &#123;</span><br><span class="line">      <span class="keyword">case</span> MESSAGE_FOO_REQUEST:</span><br><span class="line">        <span class="keyword">auto</span>* request = (FooRequest*) arguments;</span><br><span class="line">        ...</span><br><span class="line">        <span class="built_in">Send</span>(sender, MESSAGE_FOO_RESPONSE, response);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">case</span> MESSAGE_BAR_REQUEST:</span><br><span class="line">      ...</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>只需要实现不同的request，actor在接受到 message后就能派发到对应的actor上去。<br><img src="/%E8%AF%91From-Eager-Futures-Promises-to-Lazy-Continuations/actors%E4%BA%A4%E4%BA%92%E5%9B%BE.png" alt="actors (visualized)"></p>
<p>如果对所有的方法上锁（类似java的synchronized）能不能做到同样的效果呢？<br><img src="/%E8%AF%91From-Eager-Futures-Promises-to-Lazy-Continuations/threads%E4%BA%A4%E4%BA%92%E5%9B%BE.png" alt="threads (visualized)"></p>
<p>actor的性能如何？<br>对于数据经常需要被共享或者在执行资源间移动的并发程序没啥影响</p>
<p>但是对于分布式和网络程序，数据经常只在别的机器上被共享，并且在任意的core之间交换数据会带来性能下降</p>
<p>似乎通过actor我们解决了state的问题</p>
<h2 id="libprocess"><a href="#libprocess" class="headerlink" title="libprocess"></a>libprocess</h2><p>作者在2009年的时候</p>
<ul>
<li>在UCB 构建分布式系统Apache Mesos</li>
<li>使用了C++来避免如Java的gc语言会带来的运行时不确定性问题</li>
<li>希望使用actors</li>
</ul>
<p>于是在打造libprocess的时候他们想到了将futures&#x2F;promises和actors结合！</p>
<h3 id="为什么actor需要future-x2F-promises"><a href="#为什么actor需要future-x2F-promises" class="headerlink" title="为什么actor需要future&#x2F;promises"></a>为什么actor需要future&#x2F;promises</h3><p>回首上面的actor代码会发现很难描述清楚actor之间的执行流</p>
<ul>
<li>在actor 模型上收发信息就如同编写汇编语言一样（译者注：编写难度和体验）尽管他们确实解决了state的问题</li>
<li>message的处理就如同goto一样！而goto是非结构化的，是不被提倡的</li>
</ul>
<p>抛弃goto这个玩意，我们想要的是</p>
<ul>
<li>非阻塞的函数调用(返回future)</li>
<li>函数的可组合性(Then)</li>
</ul>
<p>就像如下的代码</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">MyActor actor;</span><br><span class="line"><span class="keyword">auto</span> future = actor.<span class="built_in">Foo</span>(...)</span><br><span class="line">  .<span class="built_in">Then</span>([](<span class="keyword">auto</span>&amp;&amp; response) &#123;</span><br><span class="line">    <span class="keyword">return</span> ...;</span><br><span class="line">  &#125;);</span><br></pre></td></tr></table></figure>

<p>libprocess actor的伪代码如下</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">MyActor</span> : <span class="keyword">public</span> Actor &#123;</span><br><span class="line">  <span class="function">Future&lt;FooResponse&gt; <span class="title">Foo</span><span class="params">(FooRequest request)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Execute the “message” on the actor ‘self()’.                                                                                                                </span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">On</span>(<span class="built_in">self</span>(), [<span class="keyword">this</span>, request]() &#123;</span><br><span class="line">      FooResponse response;</span><br><span class="line">      ...</span><br><span class="line">      <span class="keyword">return</span> response;</span><br><span class="line">    &#125;);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>注意这里On(self(), closure)的语义是在self()也就是这个actor实例本身这个执行资源上执行closure中的内容</p>
<p>自然的也可以在函数中通过then组合调用别的逻辑</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">MyActor</span> : <span class="keyword">public</span> Actor &#123;</span><br><span class="line">  <span class="function">Future&lt;FooResponse&gt; <span class="title">Foo</span><span class="params">(FooRequest request)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Execute the “message” on the actor ‘self()’.                                                                                                                </span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">On</span>(<span class="built_in">self</span>(), [<span class="keyword">this</span>, request]() &#123;</span><br><span class="line">      ...</span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">SomeOtherFunctionReturningAFuture</span>()</span><br><span class="line">        .<span class="built_in">Then</span>([](<span class="keyword">auto</span>&amp;&amp; value) &#123;</span><br><span class="line">           ...</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="why-futures-x2F-promises-need-actors"><a href="#why-futures-x2F-promises-need-actors" class="headerlink" title="why futures&#x2F;promises need actors"></a>why futures&#x2F;promises need actors</h3><p>观察一下下面这段代码</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">MyObject</span> &#123;</span><br><span class="line">  <span class="function">Future&lt;<span class="type">void</span>&gt; <span class="title">SomeMember</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">SomeFunction</span>()</span><br><span class="line">      .<span class="built_in">Then</span>([](<span class="keyword">auto</span>&amp;&amp; value) &#123;</span><br><span class="line">        <span class="comment">// Where should this lambda run?????                                                                                                                   </span></span><br><span class="line">        ...</span><br><span class="line">      &#125;);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p><code>Then</code>之中的函数逻辑应该运行在什么之上呢？一个简单的想法是直接使用<code>SomeFunction</code>返回的future所关联的promise所在的执行资源之上</p>
<p>完善一下上面的代码可能会是这样</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">MyObject</span> &#123;</span><br><span class="line">  <span class="function">Future&lt;<span class="type">void</span>&gt; <span class="title">SomeMember</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">SomeFunction</span>()</span><br><span class="line">      .<span class="built_in">Then</span>([<span class="keyword">this</span>](<span class="keyword">auto</span>&amp;&amp; value) &#123;</span><br><span class="line">        <span class="comment">// Where should this lambda run?????                                                                                                                    </span></span><br><span class="line">        std::unique_lock&lt;std::mutex&gt; <span class="built_in">lock</span>(mutex_);</span><br><span class="line">        i += value;</span><br><span class="line">      &#125;);</span><br><span class="line">  &#125;</span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="type">int</span> i_;</span><br><span class="line">  std::mutex mutex_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>这可能会带来一个问题：在SomeFunction对应的promise的执行逻辑在调用<code>promise.Set()</code>的时候可能是阻塞的(可以理解成执行promise的逻辑和执行Then的逻辑可能会并行，这里就有锁会带来的同步代价)<br>或许可以使用asyncmutex试图解决这个问题</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">MyObject</span> &#123;</span><br><span class="line">  <span class="function">Future&lt;<span class="type">void</span>&gt; <span class="title">SomeMember</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">SomeFunction</span>()</span><br><span class="line">      .<span class="built_in">Then</span>([<span class="keyword">this</span>](<span class="keyword">auto</span>&amp;&amp; value) &#123;</span><br><span class="line">        <span class="comment">// Where should this lambda run?????                                                                                                                    </span></span><br><span class="line">        <span class="keyword">return</span> mutex_.<span class="built_in">Acquire</span>()</span><br><span class="line">          .<span class="built_in">Then</span>([<span class="keyword">this</span>]() &#123;</span><br><span class="line">            i += value;</span><br><span class="line">            mutex_.<span class="built_in">Release</span>();</span><br><span class="line">          &#125;);</span><br><span class="line">      &#125;);</span><br><span class="line">  &#125;</span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="type">int</span> i_;</span><br><span class="line">  AsyncMutex mutex_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>这里调用<code>Release()</code>将要&#x2F;必须执行一个不会block的waiter，这也可能带来不确定的执行。</p>
<p>如果能够保证<code>Then</code>的内容严格在actor执行完<code>SomeFunction()</code>之后执行就能够避免上文中非确定性执行带来的同步问题</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">MyObject</span> : <span class="keyword">public</span> Actor &#123;</span><br><span class="line">  <span class="function">Future&lt;<span class="type">void</span>&gt; <span class="title">SomeMember</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">SomeFunction</span>()</span><br><span class="line">      .<span class="built_in">Then</span>(<span class="built_in">DeferOn</span>(<span class="built_in">self</span>(), [<span class="keyword">this</span>](<span class="keyword">auto</span>&amp;&amp; value) &#123;  <span class="comment">// Then之中的内容之后会在同一个actor的执行资源上执行</span></span><br><span class="line">        i_ += value;</span><br><span class="line">      &#125;));</span><br><span class="line">  &#125;</span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="type">int</span> i_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<ul>
<li>上面的方式中actor提供了执行<code>Then</code>(continuation)的executor资源</li>
<li>设置promise非常快是非阻塞的(DeferOn保证了在set之后才会执行Then之中的逻辑)</li>
<li>无需同步</li>
</ul>
<h2 id="revisiting-the-problem"><a href="#revisiting-the-problem" class="headerlink" title="revisiting the problem"></a>revisiting the problem</h2><p>重新看一下SpellAndGrammerCheck函数</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">std::string <span class="title">SpellAndGrammarCheck</span><span class="params">(std::string text)</span> </span>&#123; </span><br><span class="line">  text = <span class="built_in">SpellCheck</span>(text);</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">GrammarCheck</span>(text);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这段代码是顺序的，非并行的，即使并发执行也没有状态需要同步<br>修改成Future和Then的方式</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Future&lt;std::string&gt; <span class="title">SpellAndGrammarCheck</span><span class="params">(std::string text)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">SpellCheck</span>(text)</span><br><span class="line">      .<span class="built_in">Then</span>([](<span class="keyword">auto</span>&amp;&amp; text) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">GrammarCheck</span>(text);</span><br><span class="line">      &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这之中会申请锁并且需要动态分配内存</p>
<h3 id="是什么需要申请锁以及动态分配内存"><a href="#是什么需要申请锁以及动态分配内存" class="headerlink" title="是什么需要申请锁以及动态分配内存"></a>是什么需要申请锁以及动态分配内存</h3><p>我们先展开SpellCheck的逻辑</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Future&lt;std::string&gt; <span class="title">SpellAndGrammarCheck</span> <span class="params">(std::string text)</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">auto</span> future = promise.<span class="built_in">future</span>();</span><br><span class="line">  http::<span class="built_in">AsyncPost</span>( <span class="comment">// Non-blocking! Returns immediately!</span></span><br><span class="line">      ...,</span><br><span class="line">      [promise = std::<span class="built_in">move</span>(promise)]( <span class="keyword">auto</span>&amp;&amp; response) &#123;</span><br><span class="line">        promise.<span class="built_in">Set</span>(response.body);</span><br><span class="line">      &#125;);</span><br><span class="line">  <span class="keyword">return</span> future</span><br><span class="line">      .<span class="built_in">Then</span>([](<span class="keyword">auto</span>&amp;&amp; text) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">GrammarCheck</span>(text);</span><br><span class="line">      &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上面的代码中在<code>promise.Set(response.body)</code>与continuation通过<code>.Then()</code>组合之间存在race, 这两个动作可能在同时发生，于此我们需要锁来同步. 另外promise也可能在continuation被组合起来以前设置，所以需要动态内存分配.</p>
<p>有什么办法避免锁以及这一次动态内存分配吗？</p>
<h2 id="evolution-of-libprocess"><a href="#evolution-of-libprocess" class="headerlink" title="evolution of libprocess"></a>evolution of libprocess</h2><h3 id="避免锁开销"><a href="#避免锁开销" class="headerlink" title="避免锁开销"></a>避免锁开销</h3><p>上面的逻辑中SpellCheck的future的组装(将GrammarCheck的逻辑组合在一起)和promise的set操作之间是可能并行的，所以需要锁来同步，但如果将代码的逻辑做一下简单的修改，修改成SpellCheck中AsyncPost的逻辑执行完之后执行一个回调函数就可以避免锁的同步(也就是保证了GrammerCheck的逻辑一定在SpellCheck之后)</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// f的逻辑其实就是GrammerCheck</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">SpellCheck</span><span class="params">(std::string text, std::function&lt;<span class="type">void</span>(std::string)&gt; f)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> body = http::<span class="built_in">UrlEncode</span>(&#123;<span class="string">&quot;text&quot;</span>, text&#125;);</span><br><span class="line">  </span><br><span class="line">  http::<span class="built_in">AsyncPost</span>(</span><br><span class="line">      <span class="string">&quot;https://www.online-spellcheck.com&quot;</span> ,</span><br><span class="line">      body,</span><br><span class="line">      [f = std::<span class="built_in">move</span>(f)](<span class="keyword">auto</span>&amp;&amp; response) &#123;</span><br><span class="line">        <span class="built_in">f</span>(response.body); <span class="comment">// Invoke continuation without locks!</span></span><br><span class="line">      &#125;);</span><br><span class="line">  <span class="keyword">return</span> future;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>也可以修改成模板函数</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> K&gt;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">SpellCheck</span><span class="params">(std::string text, K k)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> body = http::<span class="built_in">UrlEncode</span>(&#123;<span class="string">&quot;text&quot;</span>, text&#125;);</span><br><span class="line">  http::<span class="built_in">AsyncPost</span>(</span><br><span class="line">      <span class="string">&quot;https://www.online-spellcheck.com&quot;</span> ,</span><br><span class="line">      body,</span><br><span class="line">      [k = std::<span class="built_in">move</span>(k)](<span class="keyword">auto</span>&amp;&amp; response) &#123;</span><br><span class="line">        <span class="keyword">if</span> (response.code != <span class="number">200</span>)  k.<span class="built_in">Fail</span>(response.code); </span><br><span class="line">        <span class="keyword">else</span> k.<span class="built_in">Success</span>(response.body);</span><br><span class="line">      &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>译者注：作者在演讲里表示在他读大学的时候他们都用K来表示continuation，所以这里模板里他也用的是K而不是C</p>
<h3 id="避免动态内存分配"><a href="#避免动态内存分配" class="headerlink" title="避免动态内存分配"></a>避免动态内存分配</h3><p>以上面的模板函数为例,到底是在什么地方分配了内存呢？这里需要进入Http::AsyncPost的实现之中</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">namespace</span> http &#123;</span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> K&gt;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Post</span><span class="params">(std::string url, std::string body, K k)</span> </span>&#123;</span><br><span class="line">  <span class="type">void</span>* data = <span class="keyword">new</span> <span class="built_in">K</span>(std::<span class="built_in">move</span>(k));</span><br><span class="line">  ...</span><br><span class="line">  <span class="built_in">http_post</span>(url, body, data, +[](<span class="type">long</span> code, <span class="type">const</span> <span class="type">char</span>* body, <span class="type">void</span>* data) &#123;</span><br><span class="line">    K* k = <span class="built_in">reinterpret_cast</span>&lt;K*&gt;(data);</span><br><span class="line">    k-&gt;<span class="built_in">Success</span>(http::Response&#123;code, body&#125;);</span><br><span class="line">    <span class="keyword">delete</span> k;</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="comment">// namespace http</span></span><br></pre></td></tr></table></figure>

<p>在Post方法中还是分配了内存.</p>
<p>💡 如果将continuation K作为函数返回的结果中的一部分是不是就避免了分配？</p>
<p>接受一个continuation作为参数并返回一个continuation作为结果(返回值中组合&#x2F;包括了作为参数传递的continuation)</p>
<p>修改一下上面的Post方法的实现，与其在函数的栈上分配一个堆上的void*，不如在函数中定义一个仅存在于该函数的struct并返回一个该struct的值</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> K&gt;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Post</span><span class="params">(std::string url, std::string body, K k)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">Continuation</span> &#123;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">Start</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="type">void</span>* data = &amp;k;</span><br><span class="line">      <span class="built_in">http_post</span>(url, body, data, +[]( <span class="type">long</span> code, <span class="type">const</span> <span class="type">char</span>* body, <span class="type">void</span>* data) </span><br><span class="line">      &#123;</span><br><span class="line">        K* k = <span class="built_in">reinterpret_cast</span>&lt;K*&gt;(data);</span><br><span class="line">        k-&gt;<span class="built_in">Success</span>( http::Response&#123;code, body&#125;);</span><br><span class="line">      &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">    std::string url, body;</span><br><span class="line">    K k;</span><br><span class="line">  &#125;;</span><br><span class="line">  <span class="keyword">return</span> Continuation&#123;std::<span class="built_in">move</span>(url), std::<span class="built_in">move</span>(body), std::<span class="built_in">move</span>(k)&#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到这段代码讲传递进入的url,body,k都传递进了struct Continuation之中，之后这三个值的生命周期将同返回的Continuation value绑定，在value析构时一同回收，同时这里的内存分配也只有一个栈上的值类型Continuation的内存分配.</p>
<h3 id="lazy-continuation"><a href="#lazy-continuation" class="headerlink" title="lazy continuation"></a>lazy continuation</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> k = http::<span class="built_in">Post</span>(url, body, <span class="comment">/* k&#x27; */</span>);</span><br><span class="line">k.<span class="built_in">Start</span>();</span><br></pre></td></tr></table></figure>

<ul>
<li>返回值类型是”computational graph”</li>
<li>这个graph是lazy的,当我们拿到这个graph时什么都不会发生(tradeoff for dynamic allocation) 并且如果我们想执行他的逻辑就必须显式调用start</li>
<li>graph可以分配在栈上或者堆上</li>
<li>在完成以前内存必须有效</li>
</ul>
<h2 id="eventuals"><a href="#eventuals" class="headerlink" title="eventuals"></a>eventuals</h2><p>作者将lazy continuation称为eventuals.</p>
<p>这一章的内容主要是介绍了eventuals并且通过eventuals将上文中传递continuation的代码风格进行了修正(传递continuation看着比较难看不符合人体工程学),译文会忽略这部分推导,感兴趣的读者可以访问<a target="_blank" rel="noopener" href="https://github.com/3rdparty/eventuals">eventuals</a>查看这个项目的信息.</p>
<h2 id="scheduling"><a href="#scheduling" class="headerlink" title="scheduling"></a>scheduling</h2><p>本章节主要是探讨continuation应该在什么地方运行？回望下面这段代码</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">auto</span> <span class="title">Post</span><span class="params">(std::string url, std::string body)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">Eventual</span>&lt;http::Response&gt;([url, body]( <span class="keyword">auto</span>&amp; k) &#123;</span><br><span class="line">      <span class="keyword">using</span> K = std::<span class="type">decay_t</span>&lt;<span class="keyword">decltype</span>(k)&gt;;</span><br><span class="line">      <span class="type">void</span>* data = &amp;k;</span><br><span class="line">      <span class="built_in">http_post</span>(url, body, data, +[]( <span class="type">long</span> code, <span class="type">const</span> <span class="type">char</span>* body, <span class="type">void</span>* data) </span><br><span class="line">      &#123;</span><br><span class="line">        K* k = <span class="built_in">reinterpret_cast</span>&lt;K*&gt;(data);</span><br><span class="line">        k-&gt;<span class="built_in">Success</span>(http::Response&#123;code, body&#125;);</span><br><span class="line">      &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;);</span><br></pre></td></tr></table></figure>

<p>如果continuation是在event loop中被调用的,我们不希望continuation继续在event loop中继续运行(会阻塞其他的IO任务,IO线程池不应该执行太复杂的continuation任务)<br>同理,如果continuation是在actor中被调用的我们也不希望继续在actor的执行资源上运行，因为这样会阻塞别的message的处理</p>
<p>回首看一下motivating exemple的代码</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">std::string <span class="title">SpellCheck</span><span class="params">(std::string text)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> body = http::<span class="built_in">UrlEncode</span>(&#123;<span class="string">&quot;text&quot;</span>, text&#125;);</span><br><span class="line">  <span class="keyword">auto</span> response = http::<span class="built_in">Post</span>(<span class="string">&quot;https://www.online-spellcheck.com&quot;</span>, body);</span><br><span class="line">  <span class="keyword">return</span> response.body;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>得益于函数的抽象，我们可以分开考虑函数的接口以及实现.在这里不需要考虑http::Post到底是如何实现的.</p>
<ul>
<li>我们不关心是否在多线程上实现</li>
<li>我们不关心是否在GPU上实现</li>
<li>我们不关心是否在FPGA上实现</li>
</ul>
<p>然而，如果执行完http::Post方法并将控制流返回时我们发现现在正在</p>
<ul>
<li>于我们开始执行时不同的线程上执行时，我们会很惊讶</li>
<li>一块GPU的执行逻辑上，而我们是在CPU上开始执行的，我们会很惊讶</li>
</ul>
<p>所以我们到底应该让continuation在什么地方执行呢？<br><strong>使用在你不得不等待以前正在使用的执行资源</strong></p>
<p>否则(译者注：这里作者意思大概就是否则我们每一次都应该检查接下来的函数调用的文档&#x2F;实现去查看对应的函数会不会在eventloop上执行，如果是的话就需要自己通过ThreadPool::Schedule等方法重新调度),需要将代码进行类似的修改.</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">auto</span> <span class="title">SpellAndGrammarCheck</span> <span class="params">(std::string text)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> ThreadPool::<span class="built_in">Schedule</span>([text]() &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">SpellCheck</span>(text)</span><br><span class="line">        <span class="comment">// Rescheduling on thread pool because we looked at  </span></span><br><span class="line">        <span class="comment">// documentation of &#x27;SpellCheck()&#x27; and it continues on the</span></span><br><span class="line">        <span class="comment">// event loop which we don&#x27;t want to be on.</span></span><br><span class="line">        | ThreadPool::<span class="built_in">Schedule</span>([text]() &#123;</span><br><span class="line">             <span class="keyword">return</span> <span class="built_in">Then</span>([](<span class="keyword">auto</span>&amp;&amp; text) &#123;</span><br><span class="line">               <span class="keyword">return</span> <span class="built_in">GrammarCheck</span>(text);</span><br><span class="line">             &#125;);</span><br><span class="line">           &#125;);</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>类似的内容可以查看std::execution的提案(译者后续的博文也会介绍这个提案).</p>
<p>另外也介绍了在PLDI也有类似的工作</p>
<p>“Composing Sorfware Efficiently with Lithe”(PLDI 2010)</p>
<ul>
<li>允许许多同时的scheduler负责计算图的子树</li>
<li>所有的计算都拥有一个调度context</li>
<li>对于冲洗提交任务给拥有context的接口提供了正式的接口</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/06/17/post-title-with-whitespace/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/06/17/post-title-with-whitespace/" class="post-title-link" itemprop="url">post title with whitespace</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-06-17 22:34:38" itemprop="dateCreated datePublished" datetime="2023-06-17T22:34:38+08:00">2023-06-17</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/06/17/hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/06/17/hello-world/" class="post-title-link" itemprop="url">Hello World</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-06-17 22:28:29" itemprop="dateCreated datePublished" datetime="2023-06-17T22:28:29+08:00">2023-06-17</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">John Doe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">7</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
