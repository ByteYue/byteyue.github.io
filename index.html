<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Hexo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hexo</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-about"></i>About</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/15/Self-Tuning-Query-Scheduling-for-Analytical-Workloads/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/10/15/Self-Tuning-Query-Scheduling-for-Analytical-Workloads/" class="post-title-link" itemprop="url">Self-Tuning Query Scheduling for Analytical Workloads</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-10-15 13:18:42" itemprop="dateCreated datePublished" datetime="2023-10-15T13:18:42+08:00">2023-10-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-10-22 22:27:58" itemprop="dateModified" datetime="2023-10-22T22:27:58+08:00">2023-10-22</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>大部分数据库都将调度策略委托给了操作系统本身,这个策略虽然能够简化数据库的设计但是也会带来一些问题. 比如在面对并发查询的时候自适应的资源分配就便得很难做，除此以外要在数据库中做一些调度调优也变得很困难(因为实际上更多的还是靠os自己在进行调度). 所以很多现代的现代都通过将一整条query的执行拆分成多个小的独立的任务以此来实现task-based并行. 基于task就使得数据库系统自己就能进行调度.</p>
<p>这篇论文主要是展示如何在task-based的设计上进行一些优化，论文作者提出了一种针对分析型workload的创新的无锁，自调优调度器. 通过动态地调整任务的优先级以及任务对应的粒度提供了很高的调度弹性. 即使在大压力导入下依旧能为短查询提供接近最低的延迟.</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>分析型数据库面临的workload特别复杂，在高压导入时可能还有并行抵达的各种查询. 很多系统很难在这种压力下保持良好的查询性能. </p>
<p>下图作者以他们的系统和PG的进行了一个对比，在高频导入下的查询延迟的变化. Workload包括3&#x2F;4的短查询和1&#x2F;4的长查询. 同时系统的导入压力为其最大压力的95%并持续了25分钟.<br><img src="/Self-Tuning-Query-Scheduling-for-Analytical-Workloads/QueyType.png" alt="Query Type"></p>
<p>处于这种状态的系统对于用户来讲响应度变得更低，查询性能也变得难以预测在不同的时间跑相同的查询可能会收获不同的性能. 对于用户来说，在高压场景性能降级的影响应该尽量低. 类似PG的系统将执行的调度责任转交给了操作系统. 这类系统对每一次新的连接和查询都可能创建新的线程或者进程(当然更好的方式是池化), 在执行的过程中可能也会创建更多的线程进程来进行query内的并行. 为了避免线程数超过OS线程一般也会尽量控制线程的数量.</p>
<p>现代化的系统一般会做更细粒度的调度，会实现基于task-based的调度系统，一条query会被拆分成多个独立的任务，这些任务都可以在任何一个OS线程上执行，同时任务的调度也由数据库系统接手而非被动等待OS调度。数据库系统也可以很方便的基于任务数派发给不同的线程以动态调整query的并行度. 一些系统比如SAP HANA的调度策略是和OS 调度器共生的.</p>
<p>其他的比如HyPer和Umbra则是几乎不依赖OS的调度. 在启动时他们便启动同CPU核数相同数量的线程. 之后使用morsel-driven的方式进行调度. 一个morsel表示一个tuples的固定集合，morsel时query执行时的最小单元. 因为同一条queried的不同morsel可以并行执行所以这种方式可以实现query内并行和query间并行. </p>
<p>类似intel tbb的通用调度器更关注的是吞吐, 数据库系统更关注的是公平性和查询的响应度. DB系统调度器为了在高压导入时依旧能保证低延时会更倾向于执行short running query. 除此以外, 新开启任务的粒度也可以在执行时自适应调整.</p>
<p>本篇论文主要提出了一种创新的无锁自调优调度器. 接下来的内容主要是 Section2 调度器设计. Section 3 关注于morsel-driven数据库系统. 如何通过morsel数据结构让调度变得更鲁棒更可预测. Section 4, 在调度器上加上自适应调优.</p>
<h2 id="Scalable-Task-Scheduling"><a href="#Scalable-Task-Scheduling" class="headerlink" title="Scalable Task Scheduling"></a>Scalable Task Scheduling</h2><p>在task-based的系统中挑选任务的步骤是在用户态进行的，所以调度策略需要尽可能地可拓展并且利用好硬件资源. </p>
<h3 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h3><p>假设$t_i$表示第i个任务,$p_i$表示任务的优先级. 每一个task被赋值stride $S_i&#x3D;(p_i)^{-1}$. 假设所有任务在同一时间到达那么调度策略就变得很简单. 每一个task被映射到一个$P_i$, 这个值一开始设置为0. 之后的处理方式是： 拥有最小pass的任务被选出来执行一段时间片. 执行完后将pass更新为$P_i + S_i$. 任务$t_i$拥有的执行资源比例是$p_i &#x2F; \sum_{k&#x3D;1}^{n} p_k$. Stride调度策略在所有任务都拥有相同优先级的情况下时公平的.</p>
<p>但是如果要适配动态变化的任务则需要有一些修改. 如果一个任务在任意时刻加入则其需要一个初始值. 本文的scheduler会维护一个全局的stride $S_G$ &#x3D; $\left(\sum_{k&#x3D;1}^{n} p_k\right)^{-1}$ 以及一个全局的pass $P_G$. 每过一个调度时间片这个全局的pass都要增加一次全局的stride. 现在这个全局的pass可以用来给一个新到的任务计算初始的initial pass值. 只觉上可以认为这个全局的pass值表示scheduler的时间. 如果任务的pass值比全局pass值$P_G$小那么这个任务还没拿到他应该拥有的资源，反之比全局pass大则是已经使用了太多资源.</p>
<p>Stride调度可以很简单地被拓展到非抢占式设置. 如果一个任务$t_i$消耗了其分配的时间片的$f$那么他的pass就被更新为$P_i$+$fS_i$.同样的全局pass也变成$P_G$+$fS_G$. $f$在这里可能大于1.</p>
<h3 id="Scheduling-in-Umbra"><a href="#Scheduling-in-Umbra" class="headerlink" title="Scheduling in Umbra"></a>Scheduling in Umbra</h3><p><img src="/Self-Tuning-Query-Scheduling-for-Analytical-Workloads/TaskStructureOfUmbra.png" alt="TaskStructureOfUmbra"></p>
<p>每一条pipeline被映射成一个task set. 每一个task set中包含数个task，每个task由数个morsel组成. 同一条query可以有多个task set，这些task set都属于同一个resource group. 如上图中task set 1和2都属于rg1，因为rg1有两条pipeline. 而rg2只有一个所以只有一个task set. 每一个task可以有多个morsel，而morsel有3种状态, finished, running, pending. Worker thread每次pick一个task执行.</p>
<p>同一个task set的task可以被不同的worker thread并行执行以此来提供query的并行度.  query的不同pipeline间可能有顺序依赖所以task set间也是存在顺序依赖的. 例如上图中左边的查询里的pipeline A部分必须在右边的pipeline B开始前完成. 因为hash join的build side必须比probe side先物化. Umbra通过将两条pipeline映射成顺序的task set来保证，在同一个resource group之中的task set必须等待其旗面的task set全部结束后才能开始执行. 这也方便我们在query的粒度追踪资源消耗.</p>
<p>类似Hyper的系统中task和morsel是一比一的关系也就是说一个task只有一个morsel. 但是umbra中一个task可以有任意个morsel. 在umbra中task并不是一开始就被静态创建好了的. 而是在运行时根据运行时的观测性动态调整的.</p>
<h3 id="Thread-local-scheduling"><a href="#Thread-local-scheduling" class="headerlink" title="Thread local scheduling"></a>Thread local scheduling</h3><p>Stride scheduling虽然能提供很强的确定性调度粒度但是他对现代多核硬件并不友好，因为会需要很多同步操作. 本章主要是提出了一种创新的task-based stride 调度实现. 可以在thread-local的底座上执行所有调度决策. Worker线程只会在活跃的task sets发生变化被notify.</p>
<p>当然，和传统的stride scheduling相比也增加了一些限制, 同时存在的resource group(也就是query的数量)是有上限的(但其实这样挺合理的,不做点反压系统搞不好直接被打爆了). 当数量特别多的时候会有一定的性能降级，新的resource group会在任务队列中等待.</p>
<p>本文的设计比较巧妙，虽然是针对stride scheduling algorithm的，但也可以通过仅修改thread-local scheduling的逻辑不需要修改别的部分从而切换到别的调度算法. 作者仅通过修改不了不到100行C++代码就实现了非确定性的lottery调度.</p>
<h4 id="Thread-local-Decisions"><a href="#Thread-local-Decisions" class="headerlink" title="Thread local Decisions"></a>Thread local Decisions</h4><p>全局scope内会维护一个数组，其中每一个slot是一个指针，指向某一个活跃的resource group中的task set. 当某一个RG的task set执行完毕后，会从RG中选一个新的task set放到同一个slot上. 这样的好处是调度时的优先级是绑定到了RG上而不是task set上从而简化了调度. 如果同一个RG的task sets可以被放到不同的slot会增加记账的逻辑.</p>
<p>除此以外所有的调度都是thread-local里发生的. 其中包括一个bitmask，它的作用是记录全局RG数组中的活跃项. 同时也负责优先级和pass value的映射记录. 除此以外每个worker thread也会存储其自己的global pass value. 就如下图所示.</p>
<p><img src="/Self-Tuning-Query-Scheduling-for-Analytical-Workloads/SchedulingStructrue.png" alt="SchedulingStructrue"></p>
<p>如果全局的slot和worker thread的local activity mask是同步的那么调度就很简单, 直接挑选pass value最小的slot，然后在这个slot上进行一个atomic read以获取指向对应task set的指针. 之后便是执行，记录执行时间后更新本地对应的local pass value. 这种处理模式非常轻量, worker在pick 任务的时候不需要别的线程是否pick了相同的task set. 同时全局array中的slot只有在有新的task set的时候才会被写入新数据. 这类写操作发生的频率是比较低的，就不会带来大量的cache无效化同步开销.</p>
<h4 id="修改active-task-sets"><a href="#修改active-task-sets" class="headerlink" title="修改active task sets"></a>修改active task sets</h4><p><img src="/Self-Tuning-Query-Scheduling-for-Analytical-Workloads/ChangeBitmask.png" alt="Figure4"></p>
<p>大部分情况下会尽力最低化同步开销，但是有些全局的信息还是无法避免同步. Worker线程在以下3种事件时需要能过检测到</p>
<ol>
<li>某一个全局array的slot里的task set执行完毕了. Worker必须把本地slot也disable掉(因为这个slot可能之后没有task set了 也就是这个query可能执行完了)</li>
<li>一个新的RG被赋值给一个slot时的初始化task set. worker需要pick这个RG对应的初始pass value和优先级. 并且更新local activity bitmask对应位置</li>
<li>全局slot对应位置的active RG中插入一条新的task set时(比如之前的task set执行完了就切换到下一个task set). worker需要更新本地的active slot并且设置初始pass value(在1中被disable掉了)</li>
</ol>
<p>第一种事件可以只标记对应的pointer而无需通知worker. worker线程拿到slot时读取pointer就能发现已经是disable的状态并更新自己的local 数组</p>
<p>第二种和第三种事件需要引入新的组件. 在每一个worker中会维护两个原子的bitmask. 当worker在全局的slot中插入新的task set时, 所有worker的bitmask都会对应的更新. 两个bitmask分别称为change mask和return mask. 事件2更新change mask事件3更新return mask. 之后用update mask统称两个mask.</p>
<p>更新update bitmask的方式很简单，假如现在全局数组中的第k个slot接收到了一个新的RG的初始task set, 则只要更新每个worker的change mask的第k位为1. 通过原子的fetch or操作即可轻量级更新每一个worker. 类似地，worker线程首先通过原子的exchange操作将update mask都设为0并拿到刚刚被设置的值，并通过刚刚的值来获取全局的slot的状态以此决定是否更新调度策略. 如果根据bitmask获取的值没有特别大的变化则可以避免cache无效化(其实主要是是否更新worker对应的active task set, 如果不需要更新则可以继续pick对应的任务)。 例如在上图中, 第二幅图里全局slot中插入了两个新的task set. 所有worker的update mask也进行了对应的更新. 这里用了return mask来表示TS2是从一个已知的RG中来的，用change mask表示TS3是从一个全新的RG中来的. 此时所有的worker都还在执行TS3的task 他们在第二张image的时候还不会去拉取bitmask的更新到本地的调度状态里.在第三幅图片时第一个worker会将update mask中的信息同步更新, worker 2还在执行TS3的任务不会去更新. 这张figure说明了两个workers不需要同步各自的active task sets.</p>
<h4 id="Task-Set-Finalization"><a href="#Task-Set-Finalization" class="headerlink" title="Task Set Finalization"></a>Task Set Finalization</h4><p>如果RG中的task set A结束了那么需要激活他的下一个task set B(如果存在的话). 只有在task set b的所有前置task set都执行完后才会发生这一步. 当然为了灵活度考虑也允许task sets执行额外的finalization steps. 比如在sort时执行partitions的shuffling或者在grouping时merge部分的聚合结果.</p>
<p>worker会在试图从没有剩余的task的task set获取任务时被notified. 咋一想我们或许可以在这种事件发生时立即开启finalization. 但是别的worker可能还在执行刚刚从这个task set里拿到的task, 如果立马去finalization是很不对的，因为我们必须要在task set的所有任务都结束后才执行finalization, 这种情况也不应该一直等待别的task 完成. 为了解决这个情况Umbra的scheduler引入了一种轻量级的finalization phase.</p>
<p>当一个worker 挑选了一个slot进行执行时它会在全局的state数组上更新自己的决策(发生在原子read全局slot数组前). 之后第一个发现task set耗光了的worker会作为finalization phase的coordinator.</p>
<p>coordinator需要保证最后一个结束对应task的线程能够调用finalization逻辑. coordinator首先在全局slot 数组上将对应的slot里的pointer标记为无效, 这样之后pick这个slot的worker也会将其对应的local slot设置为无。 之后coordinator遍历全局state数组查找有哪些worker还在执行这个task set的task. 对于每一个满足条件的slot信息加上一个专用的finalization marker. 所有被mark的worker thread在结束他们当前的task之后必须显式注销这个task set. 只需要对每一个task set设置一个原子的counter即可做到. coordinator会在遍历完后将counter设置为其成功设置marker的worker数量(不能是设置一个marker就+1一次,一个是这样其实不高效另一个是这样不好确认到底是不是全部执行完了). 对应的worker thread在每次执行完一个task后检查全局state数组是否包含finalization marker，如果有则对counter减1(注意，这个counter可能变成负数, 因为有个worker可能在coordinator遍历完以前就执行完并减1了). 将counter置为0的worker可以保证是最后一个(因为这个counter只能一次性增加，就避免了刚+1就-1的情况), 他可以执行最终的finalization逻辑-&gt; 在当前RG中查找是否有剩下的task set，如果有就设置如果没有就去全局wait queue中获取新的 RG.</p>
<p>这个finalization phase的开销几乎只是对全局state 数组的更新. 只要别的worker不在coordinator更新对应的slot的时候试图去pick task set则不会发生竞争. 并且只有pin了相同RG的worker才可能被影响. 所有会被影响到的线程理论上并不多(特别是在query比较多的场景，只要不是所有的worker都在处理同一个RG其实很难有特别多竞争).</p>
<h2 id="Robust-Morsel-Scheduling"><a href="#Robust-Morsel-Scheduling" class="headerlink" title="Robust Morsel Scheduling"></a>Robust Morsel Scheduling</h2><p>上一章介绍了lock-free的stride scheduler. 这一章介绍在此基础上利用morsel-based task进行的优化.</p>
<p>首先介绍如何将morsel-driven parallelism变得robust. 传统方式task:morsel的比例导致task粒度有方差从而导致不理想的调度失真. 调度的开销变得很难预测而且会有worker长时间被阻塞. 本文作者通过标准化task的执行时间来保证了调度开销可预测以及强响应度.</p>
<p>第二步是利用数据库的领域知识来优化混合分析负载中的查询延时. 通过优先级策略，本文的stride scheduler提供了细粒度的资源消耗控制. 而这是通过自适应的优先级调整策略做到的.</p>
<h3 id="Adaptive-Morsel-Execution"><a href="#Adaptive-Morsel-Execution" class="headerlink" title="Adaptive Morsel Execution"></a>Adaptive Morsel Execution</h3><p>类似Hyper的系统中morsel:task是1比1，但其实不同的morsel的执行耗时很很不同的(因为不同的pipeline执行的逻辑本身也不同,复杂度也不同)<br>. 比如假设一个pipeline中时简单的selectiton然后插入到hashtable, 那么在相同的morsel大小的情况下他的执行时间肯定是比一条包括复杂的字符串匹配和一系列hash table probe的pipeline要短的. 这意味着对于scheduler来说不同任务的粒度是差别很大的. 如果继续采用这种1:1映射那么在选择morsel大小时就需要考虑不同的tradeoff. 如果太小那么会产生更多次的schedule相应的schedule开销也更大, 如果太长, 那么有的morsel在有的pipeline中执行时间太长会影响整个系统的响应度.</p>
<p>传统的模式在两个维度是静态的:1. 依赖于固定的morsel大小 2. 依赖于静态的morsel和task的映射.</p>
<p>本文提出了一个创新的渐进式框架. 调度器定义一个目标时间$t_max$. 在挑选任务的时候调度器尽量调度能够准确满足这个目标的morsels. 也就是说这个框架能够1.使用动态的不定size morsel大小 2. 执行不同数量的morsels. 另外调度器对task的结构是无感的，这也让整个调度压力变得可预测了. Umbra将这个值设置为2ms. 作者认为这个大小兼顾了调度的负担以及响应度. 另外据作者的观测调度策略一般只需要不到1ms就能决定，也就是说负载大概也就0.05%</p>
<p>通过将pipeline转换为状态机以不同的执行阶段采取不同的策略来达到目标时间. 不同的状态暗示了需要pick多少个morsel. 因为morsel是在运行时从tuples的集合中算出来的，所以动态地通过不同的morsel size填充task size是可行的.</p>
<h4 id="Default-state"><a href="#Default-state" class="headerlink" title="Default state"></a>Default state</h4><p>默认状态时会试着挑取一个能够满足$t_max$的morsel. 这需要系统能够提供一个准确的吞吐估算值$T$, 表示每秒多少tuple. 这样一个morsel则是T*$t_max$的tuples. 而当这个morsel执行完后便能拿到实际的执行时间$t$. 对刚刚的吞吐估算值进行一个修正$\hat{T}&#x3D;(T\cdot t_{\max})&#x2F;t$. 根据旧的吞吐量T和系数$\alpha \in [0, 1]$, 那么新的则是$T^{\prime}&#x3D;\alpha\hat{T}+(1-\alpha).T$.</p>
<h4 id="Startup-State"><a href="#Startup-State" class="headerlink" title="Startup State"></a>Startup State</h4><p>这个state用来提供一个初始的吞吐估算. 这个state会按照指数关系不停pick不同size的morsel指到达到$t_max$</p>
<h4 id="Optimizations"><a href="#Optimizations" class="headerlink" title="Optimizations"></a>Optimizations</h4><p>还引入了两个优化. 一个是除了上述两种state还有一个shutdown state. 通过当前的吞吐估算值以及剩余的tuples数量可以大概计算出剩余所需的pipeline执行时间. 假设我们有M个worker, 一旦可预测的剩余的总时间低于$W\cdot t_{max}$就会进入shutdown state. 假设预期剩余总时间为t，morsel的最短执行时间为$t_min$, 我们将morsels调度为$\max(\frac{t}{W},t_{\min})$. 另一个优化是为了应对不支持自适应morsel size的tasks. 这类必须高效处理因为有些任务不具有高度的自适应. 如果运行时发现有的任务消耗的只是target duration的一部分可以允许这类任务继续消费直到达到$t_max$</p>
<h4 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h4><p><img src="/Self-Tuning-Query-Scheduling-for-Analytical-Workloads/MorselSizeComparison.png" alt="MorselSizeComparison"></p>
<p>这个图能看出来不同阶段的效果, 特别是startup阶段的两倍指数</p>
<h3 id="Adaptive-Query-Priorities"><a href="#Adaptive-Query-Priorities" class="headerlink" title="Adaptive Query Priorities"></a>Adaptive Query Priorities</h3><p>不同的任务可以有不同的优先级. 数据库不应该让用户处理workload管理中的繁琐细节. Umbra利用自适应查询优先级来透明化地按照短作业优先的方式处理. 不需要用户输入而是在运行时根据query的性质赋予优先级. 首先定义”desirable”延迟. 假设所有的query都是一样重要的. 在这个假设下提出两个基础原则.</p>
<ol>
<li>查询延迟在load时也得保持可预测性.</li>
</ol>
<p>如果系统同时接受两条query, 短一些query需要先结束.</p>
<ol start="2">
<li>查询延迟需要尽量低.</li>
</ol>
<p>如果数据库遵守这两条那么是可以做到可预测和高性能的. 不过公平调度只能保证1不能保证2. 因为短作业一般不会特别影响到长作业的延迟. 比如我们有9成的短作业他们耗时10ms，只有一成的长作业，他们耗时1s. 即使使用短作业优先的方式，对于长作业也只有10%的影响.</p>
<p>本文提出的自适应优先级策略就是为了透明地给短作业赋予优先级. 处理起来和多级反馈队列很像，一个查询的优先级取决于他到目前为止消耗的CPU资源. 因为作者将query包装成了一个RG, 所以查询的优先级其实也就是query的优先级. 可以按照如下公式处理:</p>
<p>$P_{i+1}&#x3D;\begin{cases}P_{i},i&lt;d_{start}\\max(P_{min},\lambda P_{i}),i\geq d_{start}\end{cases}$</p>
<p>有3个参数, $d_start$表示RG的优先级开始衰退的时间, 衰退的速度控制在$\lambda\in[0,1]$. 优先级最低到$p_min$.</p>
<p>和公平调度相比，这种调度策略能提供更大的相对性能差异. 但是为了实现短作业任务的高性能也是必须的. 尽管如此还是保证了原则(1). 同时到达的两条query的优先级退化速度是一致的也就是说短的一个会在同样的资源分配下先结束.</p>
<h3 id="自定义优先级"><a href="#自定义优先级" class="headerlink" title="自定义优先级"></a>自定义优先级</h3><p>当然也可以让用户自己定义优先级. 有两种简单的方式实现</p>
<ol>
<li>特别重要的query可以允许用户设置一个不同的静态初始优先级并且这个优先级是静态的不会衰退</li>
<li>也可以将优化级和用户绑定. 这样用户优先级可以影响他的所有query的衰退速度.</li>
</ol>
<h2 id="Self-tuning-Scheduling"><a href="#Self-tuning-Scheduling" class="headerlink" title="Self-tuning Scheduling"></a>Self-tuning Scheduling</h2><p>TODO</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/06/24/%E6%B5%85%E8%B0%88%E5%8D%8F%E7%A8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/06/24/%E6%B5%85%E8%B0%88%E5%8D%8F%E7%A8%8B/" class="post-title-link" itemprop="url">浅谈协程</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-06-24 22:14:29" itemprop="dateCreated datePublished" datetime="2023-06-24T22:14:29+08:00">2023-06-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-10-15 13:09:45" itemprop="dateModified" datetime="2023-10-15T13:09:45+08:00">2023-10-15</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>这篇博文主要是结合笔者以前在字节跳动实习时在内部做的一次分享以及近年来的一些新的感悟来谈一下协程的部分内容，这篇博文不会过多讨论协程如何进行调度以及如何进行任务的组合等部分，主要是围绕为何会有协程,协程的分类以及不同的实现，另外也简单聊一下使用协程的心得.</p>
<h3 id="为什么我们想要协程"><a href="#为什么我们想要协程" class="headerlink" title="为什么我们想要协程"></a>为什么我们想要协程</h3><p>亦可参考Google于13年的一次<a target="_blank" rel="noopener" href="https://dokumen.tips/documents/paul-turner-pjt-with-threads-turner-pjt-google-confidential-and-proprietary.html?page=17">分享</a></p>
<p>首先为什么会想要使用协程呢？先从网络编程中几种模式说起，这里我们基于asio的代码来讨论，先用最传统的阻塞式的网络编程模式实现echo server就如同如下代码</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">try</span></span><br><span class="line">  &#123;</span><br><span class="line">    boost::asio::io_context io_context;</span><br><span class="line">    <span class="function">tcp::acceptor <span class="title">acceptor</span><span class="params">(io_context, tcp::endpoint(tcp::v4(), <span class="number">8000</span>))</span></span>;</span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>)</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="function">tcp::socket <span class="title">socket</span><span class="params">(io_context)</span></span>;</span><br><span class="line">      acceptor.<span class="built_in">accept</span>(socket);</span><br><span class="line">      boost::system::error_code error;</span><br><span class="line">      <span class="keyword">while</span> (<span class="literal">true</span>)</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="type">char</span> data[<span class="number">1024</span>];</span><br><span class="line">        <span class="type">size_t</span> length = socket.<span class="built_in">read_some</span>(boost::asio::<span class="built_in">buffer</span>(data), error);</span><br><span class="line">        <span class="keyword">if</span> (error == boost::asio::error::eof)</span><br><span class="line">          <span class="keyword">break</span>; <span class="comment">// Connection closed cleanly by peer.</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (error)</span><br><span class="line">          <span class="keyword">throw</span> boost::system::<span class="built_in">system_error</span>(error); <span class="comment">// Some other error.</span></span><br><span class="line">        boost::asio::<span class="built_in">write</span>(socket, boost::asio::<span class="built_in">buffer</span>(data, length));</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">catch</span> (std::exception&amp; e)</span><br><span class="line">  &#123;</span><br><span class="line">    std::cerr &lt;&lt; <span class="string">&quot;Exception: &quot;</span> &lt;&lt; e.<span class="built_in">what</span>() &lt;&lt; std::endl;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>因为使用的是阻塞的模式，这段代码的吞吐量特别慢，因为每次只能处理一个连接的请求，并且一次连接的请求没能处理完完全不会去处理下一段。</p>
<p>有的人会想或许我们可以采取每一条连接都开启一个新线程进行处理的方式</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thread&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;asio.hpp&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> asio::ip;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">do_echo</span><span class="params">(tcp::socket socket)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">try</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">char</span> data[<span class="number">1024</span>];</span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            std::<span class="type">size_t</span> length = socket.<span class="built_in">read_some</span>(asio::<span class="built_in">buffer</span>(data));</span><br><span class="line">            asio::<span class="built_in">write</span>(socket, asio::<span class="built_in">buffer</span>(data, length));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">catch</span> (std::exception&amp; e)</span><br><span class="line">    &#123;</span><br><span class="line">        std::cerr &lt;&lt; <span class="string">&quot;Exception in thread: &quot;</span> &lt;&lt; e.<span class="built_in">what</span>() &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">do_accept</span><span class="params">(asio::ip::tcp::acceptor&amp; acceptor, asio::io_service&amp; io_service)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    acceptor.<span class="built_in">async_accept</span>(io_service,</span><br><span class="line">        [&amp;acceptor, &amp;io_service](std::error_code ec, tcp::socket socket)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (!ec)</span><br><span class="line">            &#123;</span><br><span class="line">                std::<span class="built_in">thread</span>(do_echo, std::<span class="built_in">move</span>(socket)).<span class="built_in">detach</span>();</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="built_in">do_accept</span>(acceptor, io_service);</span><br><span class="line">        &#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span>* argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">try</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (argc != <span class="number">2</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            std::cerr &lt;&lt; <span class="string">&quot;Usage: echo_server &lt;port&gt;\n&quot;</span>;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        asio::io_service io_service;</span><br><span class="line">        <span class="function">tcp::acceptor <span class="title">acceptor</span><span class="params">(io_service, tcp::endpoint(tcp::v4(), std::atoi(argv[<span class="number">1</span>])))</span></span>;</span><br><span class="line">        <span class="built_in">do_accept</span>(acceptor, io_service);</span><br><span class="line">        io_service.<span class="built_in">run</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">catch</span> (std::exception&amp; e)</span><br><span class="line">    &#123;</span><br><span class="line">        std::cerr &lt;&lt; <span class="string">&quot;Exception: &quot;</span> &lt;&lt; e.<span class="built_in">what</span>() &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上面这种形式在连接数较少时也是能work的，但是当连接数量达到几十万条甚至更多的时候呢？假设有10w个连接，Linux下每个线程的栈默认大小为8M，那么一下子就会消费80G的内存,再算上线程切换的开销，可以想象服务的负载会有多么大，这似乎并不是一条很靠谱的解决方案.<br>接下来我们试着用最简单的回调的方式进行异步化改造</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;boost/asio.hpp&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> boost::asio::ip::tcp;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">session</span><span class="params">(tcp::socket socket)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  std::array&lt;<span class="type">char</span>, 1024&gt; buffer;</span><br><span class="line">  boost::system::error_code error;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 异步读取来自客户端的数据</span></span><br><span class="line">  socket.<span class="built_in">async_read_some</span>(boost::asio::<span class="built_in">buffer</span>(buffer), [&amp;](boost::system::error_code ec, std::<span class="type">size_t</span> length)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">if</span> (!ec)</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="comment">// 将数据回显回客户端</span></span><br><span class="line">      boost::asio::<span class="built_in">async_write</span>(socket, boost::asio::<span class="built_in">buffer</span>(buffer, length),</span><br><span class="line">        [&amp;](boost::system::error_code ec, std::<span class="type">size_t</span> <span class="comment">/*length*/</span>)</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="keyword">if</span> (!ec)</span><br><span class="line">          &#123;</span><br><span class="line">            <span class="comment">// 继续异步读取来自客户端的数据</span></span><br><span class="line">            <span class="built_in">session</span>(std::<span class="built_in">move</span>(socket));</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">try</span></span><br><span class="line">  &#123;</span><br><span class="line">    boost::asio::io_context io_context;</span><br><span class="line">    <span class="function">tcp::acceptor <span class="title">acceptor</span><span class="params">(io_context, tcp::endpoint(tcp::v4(), <span class="number">8000</span>))</span></span>;</span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>)</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="function">tcp::socket <span class="title">socket</span><span class="params">(io_context)</span></span>;</span><br><span class="line">      acceptor.<span class="built_in">accept</span>(socket);</span><br><span class="line">      <span class="comment">// 启动异步会话</span></span><br><span class="line">      <span class="built_in">session</span>(std::<span class="built_in">move</span>(socket));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">catch</span> (std::exception&amp; e)</span><br><span class="line">  &#123;</span><br><span class="line">    std::cerr &lt;&lt; <span class="string">&quot;Exception: &quot;</span> &lt;&lt; e.<span class="built_in">what</span>() &lt;&lt; std::endl;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上面这段代码中所有的io操作都是异步的,即使只有一个线程的情况下也能提供很强的吞吐(参考nodejs)，因为其中所有的IO操作都是非阻塞的，加上使用了IO多路复用技术可以保证一个线程中处理多个request时不会出现某个request的io卡住导致所有request全部饿死的情况。但是可以看到这种方式的代码中无可避免的会使用回调(echo server这种比较简单的情况只有2层回调，但是如果我们是http服务器呢？读到数据后先进行encode&#x2F;decode,然后路由到对应的处理函数)，当回调层数越深的时候丢失的代码上下文就越多，在debug的时候就更费劲.<br>另外异步+回调更容易让程序员迷失在对象的生命周期之中，一种很常见的问题是，对象A在线程1里析构了，但是被线程2访问了，这就会导致heap-use-after-free的问题。有的人会argue到使用shared_ptr来解决问题，但是如果shared_ptr引用的原子变量的开销在很多时候也不可小觑，更不用提enable_shared_from被滥用的话带来的问题。</p>
<p>下面我们用asio的协程来编写刚刚的功能.</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">report_error</span><span class="params">(std::string_view component, sys::error_code ec)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  std::cerr &lt;&lt; component &lt;&lt; <span class="string">&quot; failure: &quot;</span></span><br><span class="line">            &lt;&lt; ec &lt;&lt; <span class="string">&quot; ()&quot;</span> &lt;&lt; ec.<span class="built_in">message</span>() &lt;&lt; <span class="string">&quot;)\n&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function">asio::awaitable&lt;<span class="type">void</span>&gt; <span class="title">session</span><span class="params">(tcp::socket socket)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">try</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="type">char</span> data[<span class="number">1024</span>];</span><br><span class="line">    <span class="keyword">for</span> (;;)</span><br><span class="line">    &#123;</span><br><span class="line">      std::<span class="type">size_t</span> n = <span class="keyword">co_await</span> socket.<span class="built_in">async_read_some</span>(asio::<span class="built_in">buffer</span>(data), asio::use_awaitable);</span><br><span class="line">      <span class="function"><span class="keyword">co_await</span> <span class="title">async_write</span><span class="params">(socket, asio::buffer(data, n), asio::use_awaitable)</span></span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">catch</span> (sys::system_error <span class="type">const</span>&amp; e)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">if</span> (e.<span class="built_in">code</span>() == asio::error::eof)</span><br><span class="line">      std::cerr &lt;&lt; <span class="string">&quot;Session done \n&quot;</span>;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">      <span class="built_in">report_error</span>(<span class="string">&quot;Session&quot;</span>, e.<span class="built_in">code</span>());</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function">asio::awaitable&lt;<span class="type">void</span>&gt; <span class="title">listener</span><span class="params">(asio::io_context&amp; context, <span class="type">unsigned</span> <span class="type">short</span> port)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="function">tcp::acceptor <span class="title">acceptor</span><span class="params">(context, &#123;tcp::v4(), port&#125;)</span></span>;</span><br><span class="line"> </span><br><span class="line">  <span class="keyword">try</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">for</span> (;;)</span><br><span class="line">    &#123;</span><br><span class="line">      tcp::socket socket = <span class="keyword">co_await</span> acceptor.<span class="built_in">async_accept</span>(asio::use_awaitable);</span><br><span class="line">      asio::<span class="built_in">co_spawn</span>(context, <span class="built_in">session</span>(std::<span class="built_in">move</span>(socket)), asio::detached);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">catch</span> (sys::system_error <span class="type">const</span>&amp; e)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="built_in">report_error</span>(<span class="string">&quot;Listener&quot;</span>, e.<span class="built_in">code</span>());</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">try</span></span><br><span class="line">  &#123;</span><br><span class="line">    asio::io_context context;</span><br><span class="line"> </span><br><span class="line">    <span class="function">asio::signal_set <span class="title">signals</span><span class="params">(context, SIGINT, SIGTERM)</span></span>;</span><br><span class="line">    signals.<span class="built_in">async_wait</span>([&amp;](<span class="keyword">auto</span>, <span class="keyword">auto</span>)&#123; context.<span class="built_in">stop</span>(); &#125;);</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">auto</span> listen = <span class="built_in">listener</span>(context, <span class="number">55555</span>);</span><br><span class="line">    asio::<span class="built_in">co_spawn</span>(context, std::<span class="built_in">move</span>(listen), asio::detached);</span><br><span class="line"> </span><br><span class="line">    context.<span class="built_in">run</span>();</span><br><span class="line">    std::cerr &lt;&lt; <span class="string">&quot;Server done \n&quot;</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">catch</span> (std::exception&amp; e)</span><br><span class="line">  &#123;</span><br><span class="line">    std::cerr &lt;&lt; <span class="string">&quot;Server failure: &quot;</span> &lt;&lt; e.<span class="built_in">what</span>() &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到在协程版本的代码中我们并不需要像异步版本的代码一样写很多的回调函数，更多的是<code>co_await expression</code>这样类似函数调用的写法，我们的代码不需要再非常的割裂，可以和同步编程时的代码似乎没有太大的差别，同时这样的代码也不会出现同步阻塞代码中处理一条请求时无法处理新来的请求的情况，程序的吞吐也能很可观。同时也不会出现per-thread-per-connection版本中的线程消耗问题.</p>
<p>下文中我们简单描述一下不同的协程的实现原理</p>
<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><h3 id="按照是否保存调用栈区分"><a href="#按照是否保存调用栈区分" class="headerlink" title="按照是否保存调用栈区分"></a>按照是否保存调用栈区分</h3><p>首先有栈无栈协程在执行的时候都是要使用到程序内存空间当中的栈的，而他们的名字之中的有栈无栈指的是是否保存自己的调用栈，有栈协程会将从协程起始点开始到挂起点为止的所有栈上的变量都保存到自己的栈之中,当发生协程切换的时候会替换挂起协程和恢复协程的栈,这样就可以在另一个协程的挂起点上恢复。这里我们先卖个关子不谈这有什么差异</p>
<p>现在我们设想一个场景，在某个协程C的上下文中调用函数F，这个协程能在什么地方挂起？<br>在有栈协程中，假设C调用到F的时候调用栈如下:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">|      Stack Frame f     |   &lt;- 在这里的任意时刻挂起</span><br><span class="line">+----------------------+</span><br><span class="line">|  Local Variables f    |</span><br><span class="line">|                      |</span><br><span class="line">|                      |</span><br><span class="line">|                      |</span><br><span class="line">|                      |</span><br><span class="line">+----------------------+</span><br><span class="line">|  Return Address f    |</span><br><span class="line">+----------------------+</span><br><span class="line">|       Ctx Of C       |</span><br><span class="line">+----------------------+</span><br></pre></td></tr></table></figure>

<p>有栈协程能够将C中jmp F到F执行的任意时刻的堆栈给保存下来，之后也可以切换回来. 这里用Linux kernel中的process&#x2F;thread调度做一个简单的类比，Linux中不管是process还是thread都是用task_struct保存其对应的属性的，内核在进行调度的时候也是将当前的process&#x2F;thread对应的task_struct切出并替换成另一个task_struct，这样就完成了切换。所以我们甚至可以说如果有syscall api能够让用户自己指定将当前process&#x2F;thread切换到pid所对应的process&#x2F;thread，那么内核其实也提供了手动实现的有栈协程的手段.(实际上Google还真想<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=KXuZi9aeGTw">这么</a>干)</p>
<p>接下来我们讨论无栈协程的实现。无栈协程并不会单独保存协程的整个stack frame,类比上面有栈协程的图来对比的话就是无栈协程只能在<strong>被标注可以挂起的地方</strong>挂起. 假设我们有这样一段代码</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Task&lt;<span class="type">int</span>&gt; <span class="title">coro</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> i = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">co_yield</span> i;</span><br><span class="line">  i++;</span><br><span class="line">  <span class="keyword">co_yield</span> i;</span><br><span class="line">  i++;</span><br><span class="line">  <span class="keyword">co_return</span> i;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这段代码中只有3个co_xxx的地方可以挂起，这段代码可能会被编译器修改成这样</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">CoroutineState</span> &#123;</span><br><span class="line">  <span class="type">int</span> i;</span><br><span class="line">  <span class="type">int</span> state;</span><br><span class="line">  <span class="built_in">CoroutineState</span>() : <span class="built_in">i</span>(<span class="number">0</span>), <span class="built_in">state</span>(<span class="number">0</span>) &#123;&#125;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">coro</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">switch</span> (state) &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="number">0</span>:</span><br><span class="line">        state = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">return</span> i;</span><br><span class="line">      <span class="keyword">case</span> <span class="number">1</span>:</span><br><span class="line">        i++;</span><br><span class="line">        state = <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">return</span> i;</span><br><span class="line">      <span class="keyword">case</span> <span class="number">2</span>:</span><br><span class="line">        i++;</span><br><span class="line">        <span class="keyword">return</span> i;</span><br><span class="line">      <span class="keyword">default</span>:</span><br><span class="line">        <span class="comment">// shoule never come here</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>可以看到整个函数被转换成了一个状态机类，在函数内部的局部变量会被捕获到这个类中作为成员变量，而不同的挂起点对应不同的状态。可以认为无栈协程会被状态成状态机代码来执行(熟悉Js的小伙伴会不会想到Promise呢).敏锐的小伙伴肯定也意识到了，编译器帮我们将无栈协程转换成了对应的状态机或者结构体(在rust中的future,JS中的promise)，那只要拿到这个对应的handler就能自己决定在哪儿resume(这也给众多的库作者提供了自己手写runtime scheduler的方式).</p>
<p>但是说了这么多无栈和有栈的区别能如何更具体的体现呢？我们按照一段伪代码来分析在无栈和有栈时的不同情况</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">function <span class="title">foo</span><span class="params">()</span>:</span></span><br><span class="line"><span class="function">    ...</span></span><br><span class="line"><span class="function">    return <span class="number">42</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">function coroFun():</span></span><br><span class="line"><span class="function">    yield <span class="number">100</span></span></span><br><span class="line"><span class="function">    i =</span> <span class="built_in">foo</span>()</span><br><span class="line">    yield <span class="number">101</span></span><br></pre></td></tr></table></figure>

<p>无栈协程无法在<code>foo()</code>上挂起,因为foo中没有挂起点,这意味着没有告诉编译器怎么将<code>foo()</code>转变成一个结构体保存其对应的堆栈上下文也不知道在什么地方挂起和回复. 但是有栈协程因为从协程起始点开始保存了所有的栈信息所以即使到了<code>foo()</code>函数中也能一并保存，可以随时挂起.这就是为什么无栈协程only the top-level coroutine may be suspended.</p>
<h3 id="协程的使用"><a href="#协程的使用" class="headerlink" title="协程的使用"></a>协程的使用</h3><ol>
<li><p>首先第一个问题，协程是适合IO密集型任务还是计算密集任务？答案是IO密集型任务，协程最直观的好处在于他的切换代价非常低，所以对于IO密集型任务可以在IO发生阻塞时(所以一般需要结合非阻塞IO使用，当返回EWOULDBLOCK的时候就可以出让本协程了)切换到另一个协程，这样代价相比线程IO切换会低上很多。</p>
</li>
<li><p>那如果有了协程我的并行度会有提升吗？并行度的上限理论上还是和CPU core数量有关，同一时间能并行执行的任务并不会因为协程数量更多切换代价更低而提升。协程的好处是在避免因为过多的回调引起程序的非结构化的基础上还能提供有效的异步编程手段以提升程序的吞吐(参考单线程的NodeJS).</p>
</li>
<li><p>协程使用中应该使用什么同步原语？如果还是使用pthread_xxx同步原语的话同步的粒度是thread级别的，不管是有栈协程还是无栈协程对于操作系统来说都是运行在用户态的函数，比如一旦使用pthread_lock上锁那整个线程都将阻塞自然而然也就没有了切换协程的能力。这也是为什么在不同的协程实现中都会带上一套自己的同步原语(比如bmutex之于bthread, tokio::sync::Mutex之于rust). 之后的博文也会介绍如何实现不同的协程如何实现自己的同步原语. 当然，在库级别的协程的同步原语在多个库混杂时也会造成一些问题，比如我在bthread里面如果使用了folly::fiber的同步原语会发生什么？</p>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/06/17/%E8%AF%91From-Eager-Futures-Promises-to-Lazy-Continuations/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/06/17/%E8%AF%91From-Eager-Futures-Promises-to-Lazy-Continuations/" class="post-title-link" itemprop="url">译From Eager  Futures/Promises  to Lazy Continuations</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-06-17 23:23:03" itemprop="dateCreated datePublished" datetime="2023-06-17T23:23:03+08:00">2023-06-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-06-18 14:31:28" itemprop="dateModified" datetime="2023-06-18T14:31:28+08:00">2023-06-18</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>译者一直对有关coroutine和execution的概念非常迷恋，近来希望将对这部分内容的学习心得简单分享一下提升下自己的理解，预计会有5 6篇博文产出，先以这篇CppCon的翻译起个头</p>
<p>下文会从pdf的第一章开始翻译</p>
<h2 id="motivating-futures-x2F-promises-actors"><a href="#motivating-futures-x2F-promises-actors" class="headerlink" title="motivating futures&#x2F;promises + actors"></a>motivating futures&#x2F;promises + actors</h2><p>当工程师试图打造一款高性能且正确的分布式系统时会遇到许多关键挑战。概括下来有两条</p>
<ol>
<li>在代码中不得不有等待的条件</li>
<li>在代码中有state</li>
</ol>
<h3 id="如何解决等待的问题"><a href="#如何解决等待的问题" class="headerlink" title="如何解决等待的问题"></a>如何解决等待的问题</h3><p>以下面的代码为例</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">std::string text=<span class="string">&quot;...&quot;</span>;</span><br><span class="line">text = <span class="built_in">SpellCehck</span>(text);</span><br><span class="line">text = <span class="built_in">GrammerCheck</span>(text);</span><br></pre></td></tr></table></figure>

<p>上面的代码可通过函数的组合修改成一行<code>GrammerCheck(SpellCehck(&quot;...&quot;))</code>. 不过接下来我们还是分开分析，先分析SpellCheck函数的实现</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">std::string <span class="title">SpellCheck</span><span class="params">(std::string text)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> body = http::<span class="built_in">UrlEncode</span>(&#123;<span class="string">&quot;text&quot;</span>, text&#125;);</span><br><span class="line">  <span class="keyword">auto</span> response = http::<span class="built_in">Post</span>(<span class="string">&quot;https://www.online-spellcheck.com&quot;</span>, body);</span><br><span class="line">  <span class="keyword">return</span> response.body;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>无论这段代码之中的<code>Http::Post</code>方法是阻塞的还是非阻塞都不会改变一件事实：你的代码不得不在这里等待<br>可能的解决方案如下：</p>
<ol>
<li>就死等. 这个方案肯定是不会采纳的</li>
<li>使用线程. 成本高昂同时对正确性无益</li>
<li>使用coroutine. 作者当时是09年 还没有好用的C++ coroutine</li>
<li>使用不同的语言比如erlang 或者 把erlang带进C++之中</li>
<li>使用回调函数，之后会讨论这个</li>
<li>使用future&#x2F;promise</li>
</ol>
<p>接下来我们讨论future&#x2F;promise。<br>future&#x2F;promise就像buffered channel一样</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Promise&lt;std::string&gt; promise;</span><br><span class="line">---------------thread x-------------</span><br><span class="line">Channel::Reader&lt;std::string&gt; reader = channel.<span class="built_in">Reader</span>();</span><br><span class="line">reader.<span class="built_in">Read</span>(); <span class="comment">// Blocks!</span></span><br><span class="line">---------------thread y-------------</span><br><span class="line">Channel::Writer&lt;std::string&gt; writer = channel.<span class="built_in">Writer</span>();</span><br><span class="line">writer.<span class="built_in">Write</span>(<span class="string">&quot;...&quot;</span>); <span class="comment">// Non-blocking!</span></span><br><span class="line">writer.<span class="built_in">Close</span>();</span><br></pre></td></tr></table></figure>

<p>改为future代码如下</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Promise&lt;std::string&gt; promise;</span><br><span class="line">---------------thread x-------------</span><br><span class="line">Future&lt;std::string&gt; future = promise.<span class="built_in">Future</span>();</span><br><span class="line">future.<span class="built_in">Get</span>(); <span class="comment">// Blocks!</span></span><br><span class="line">---------------thread y-------------</span><br><span class="line">promise.<span class="built_in">Set</span>(<span class="string">&quot;...&quot;</span>); <span class="comment">// Non-blocking!</span></span><br></pre></td></tr></table></figure>

<p>接下来我们用future来修改SpellCheck函数</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 这里我们异步地请求Post方法，并通过future拿到对应的返回值</span></span><br><span class="line"><span class="function">Future&lt;std::string&gt; <span class="title">SpellCheck</span><span class="params">(std::string text)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> body = http::<span class="built_in">UrlEncode</span>(&#123;<span class="string">&quot;text&quot;</span>, text&#125;);</span><br><span class="line">  Promise&lt;std::string&gt; promise;</span><br><span class="line">  <span class="keyword">auto</span> future = promise.<span class="built_in">Future</span>();</span><br><span class="line">  http::<span class="built_in">AsyncPost</span>(</span><br><span class="line">      <span class="string">&quot;https://www.online-spellcheck.com&quot;</span> ,</span><br><span class="line">      body,</span><br><span class="line">      [promise = std::<span class="built_in">move</span>(promise)]( <span class="keyword">auto</span>&amp;&amp; response) &#123;</span><br><span class="line">        <span class="keyword">if</span> (response.code != <span class="number">200</span>) promise.<span class="built_in">Fail</span>(response.code); </span><br><span class="line">        <span class="keyword">else</span> promise.<span class="built_in">Set</span>(response.body);</span><br><span class="line">      &#125;);</span><br><span class="line">  <span class="keyword">return</span> future;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>假如现在我们的SpellCheck和GrammarCheck两个函数都试用了future&#x2F;promise的方法改造，那么我们会碰到接下来的问题</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">std::string text = <span class="string">&quot;...&quot;</span>; </span><br><span class="line">text = <span class="built_in">SpellCheck</span>(text). <span class="built_in">Get</span>(); <span class="comment">// Blocks!</span></span><br><span class="line">text = <span class="built_in">GrammarCheck</span>(text). <span class="built_in">Get</span>(); <span class="comment">// Blocks!</span></span><br></pre></td></tr></table></figure>

<p>可以看到这两个方法的Get都会是阻塞的，那不相当于我们的代码又变成串行阻塞的了吗？这里的函数逻辑是在完成spellcheck后再调用grammarcheck，也就是说这里的Control Flow应该是<code>SpellCheck -&gt; GrammarCheck</code>那么这里如果可以让两个future拥有future a异步执行完了之后(then)执行b的语义似乎能避免对应的阻塞，假设C++的future能提供类似JavaScript的<code>.then</code>接口继续讨论这个问题.那么对应代码或许可以这样修改</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 这里将SpellCheck和GrammerCheck组合到一个函数SpellAndGrammarCheck之中</span></span><br><span class="line"><span class="function">Future&lt;std::string&gt; <span class="title">SpellAndGrammarCheck</span> <span class="params">(std::string text)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">SpellCheck</span>(text)</span><br><span class="line">      .<span class="built_in">Then</span>([](<span class="keyword">auto</span>&amp;&amp; text) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">GrammarCheck</span>(text);<span class="comment">// Can be a Future&lt;T&gt; or T.</span></span><br><span class="line">      &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>到这里我们似乎解决了等待的问题.</p>
<h3 id="如何解决状态的问题"><a href="#如何解决状态的问题" class="headerlink" title="如何解决状态的问题"></a>如何解决状态的问题</h3><p>使用future&#x2F;promises执行代码的一些性质</p>
<ul>
<li>因为代码中从不block所以可以只有一个线程便执行(类型JavaScript的模型，只有基于libuv提供的单线程event loop)</li>
<li>然后代码并不一定能原子地执行，因为当代码中出现必须等待别的代码时就出现了交互(在不得不等待时会有别的代码被执行就是问题的关键)</li>
<li>许多人称这种情况为”concurrency” vs parallelism因为这种模式给了你并发执行的错觉然而你并没有同时在执行</li>
<li>但是你依旧得忍受并发执行所带来的同步问题</li>
<li>也可以基于多线程执行代码</li>
</ul>
<p>可能的解决方案如下：</p>
<ul>
<li>1963年提出了mutexes和semaphore</li>
<li>1973年提出了actors</li>
<li>1974年提出了monitors</li>
<li>1978年提出了communicating sequential processes</li>
<li>1987年提出了statecharts</li>
</ul>
<p>其中mutexes，semaphores和monitors都是基于threads的解决方案<br>而actors，csp，statecharts是没有线程的解决方案</p>
<p>没有线程会是什么情况？<br>没有线程的抽象包含了执行模型&#x2F;语义和状态的同步<br>actors包括了执行，同步，状态</p>
<p>包括得更多 -&gt; 更高级的抽象能带来</p>
<ul>
<li>更容易理解</li>
<li>更容易在更多的硬件和平台运行</li>
<li>更容易优化</li>
</ul>
<p>actors的性质</p>
<ul>
<li>本地可修改状态</li>
<li>消息队列</li>
<li>一次接受并处理一条消息</li>
<li>actors之间发送消息是非阻塞的</li>
<li>不论是local还是distributed模式都是同样的编程模型</li>
</ul>
<p>下面我们看一段在C++中的actor模型的代码</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">MyActor</span> : <span class="keyword">public</span> Actor &#123;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Receive</span><span class="params">(ActorId sender, Message message, <span class="type">void</span>* arguments)</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">    <span class="keyword">switch</span> (message) &#123;</span><br><span class="line">      <span class="keyword">case</span> MESSAGE_FOO_REQUEST:</span><br><span class="line">        <span class="keyword">auto</span>* request = (FooRequest*) arguments;</span><br><span class="line">        ...</span><br><span class="line">        <span class="built_in">Send</span>(sender, MESSAGE_FOO_RESPONSE, response);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">case</span> MESSAGE_BAR_REQUEST:</span><br><span class="line">      ...</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>只需要实现不同的request，actor在接受到 message后就能派发到对应的actor上去。<br><img src="/%E8%AF%91From-Eager-Futures-Promises-to-Lazy-Continuations/actors%E4%BA%A4%E4%BA%92%E5%9B%BE.png" alt="actors (visualized)"></p>
<p>如果对所有的方法上锁（类似java的synchronized）能不能做到同样的效果呢？<br><img src="/%E8%AF%91From-Eager-Futures-Promises-to-Lazy-Continuations/threads%E4%BA%A4%E4%BA%92%E5%9B%BE.png" alt="threads (visualized)"></p>
<p>actor的性能如何？<br>对于数据经常需要被共享或者在执行资源间移动的并发程序没啥影响</p>
<p>但是对于分布式和网络程序，数据经常只在别的机器上被共享，并且在任意的core之间交换数据会带来性能下降</p>
<p>似乎通过actor我们解决了state的问题</p>
<h2 id="libprocess"><a href="#libprocess" class="headerlink" title="libprocess"></a>libprocess</h2><p>作者在2009年的时候</p>
<ul>
<li>在UCB 构建分布式系统Apache Mesos</li>
<li>使用了C++来避免如Java的gc语言会带来的运行时不确定性问题</li>
<li>希望使用actors</li>
</ul>
<p>于是在打造libprocess的时候他们想到了将futures&#x2F;promises和actors结合！</p>
<h3 id="为什么actor需要future-x2F-promises"><a href="#为什么actor需要future-x2F-promises" class="headerlink" title="为什么actor需要future&#x2F;promises"></a>为什么actor需要future&#x2F;promises</h3><p>回首上面的actor代码会发现很难描述清楚actor之间的执行流</p>
<ul>
<li>在actor 模型上收发信息就如同编写汇编语言一样（译者注：编写难度和体验）尽管他们确实解决了state的问题</li>
<li>message的处理就如同goto一样！而goto是非结构化的，是不被提倡的</li>
</ul>
<p>抛弃goto这个玩意，我们想要的是</p>
<ul>
<li>非阻塞的函数调用(返回future)</li>
<li>函数的可组合性(Then)</li>
</ul>
<p>就像如下的代码</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">MyActor actor;</span><br><span class="line"><span class="keyword">auto</span> future = actor.<span class="built_in">Foo</span>(...)</span><br><span class="line">  .<span class="built_in">Then</span>([](<span class="keyword">auto</span>&amp;&amp; response) &#123;</span><br><span class="line">    <span class="keyword">return</span> ...;</span><br><span class="line">  &#125;);</span><br></pre></td></tr></table></figure>

<p>libprocess actor的伪代码如下</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">MyActor</span> : <span class="keyword">public</span> Actor &#123;</span><br><span class="line">  <span class="function">Future&lt;FooResponse&gt; <span class="title">Foo</span><span class="params">(FooRequest request)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Execute the “message” on the actor ‘self()’.                                                                                                                </span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">On</span>(<span class="built_in">self</span>(), [<span class="keyword">this</span>, request]() &#123;</span><br><span class="line">      FooResponse response;</span><br><span class="line">      ...</span><br><span class="line">      <span class="keyword">return</span> response;</span><br><span class="line">    &#125;);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>注意这里On(self(), closure)的语义是在self()也就是这个actor实例本身这个执行资源上执行closure中的内容</p>
<p>自然的也可以在函数中通过then组合调用别的逻辑</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">MyActor</span> : <span class="keyword">public</span> Actor &#123;</span><br><span class="line">  <span class="function">Future&lt;FooResponse&gt; <span class="title">Foo</span><span class="params">(FooRequest request)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Execute the “message” on the actor ‘self()’.                                                                                                                </span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">On</span>(<span class="built_in">self</span>(), [<span class="keyword">this</span>, request]() &#123;</span><br><span class="line">      ...</span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">SomeOtherFunctionReturningAFuture</span>()</span><br><span class="line">        .<span class="built_in">Then</span>([](<span class="keyword">auto</span>&amp;&amp; value) &#123;</span><br><span class="line">           ...</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="why-futures-x2F-promises-need-actors"><a href="#why-futures-x2F-promises-need-actors" class="headerlink" title="why futures&#x2F;promises need actors"></a>why futures&#x2F;promises need actors</h3><p>观察一下下面这段代码</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">MyObject</span> &#123;</span><br><span class="line">  <span class="function">Future&lt;<span class="type">void</span>&gt; <span class="title">SomeMember</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">SomeFunction</span>()</span><br><span class="line">      .<span class="built_in">Then</span>([](<span class="keyword">auto</span>&amp;&amp; value) &#123;</span><br><span class="line">        <span class="comment">// Where should this lambda run?????                                                                                                                   </span></span><br><span class="line">        ...</span><br><span class="line">      &#125;);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p><code>Then</code>之中的函数逻辑应该运行在什么之上呢？一个简单的想法是直接使用<code>SomeFunction</code>返回的future所关联的promise所在的执行资源之上</p>
<p>完善一下上面的代码可能会是这样</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">MyObject</span> &#123;</span><br><span class="line">  <span class="function">Future&lt;<span class="type">void</span>&gt; <span class="title">SomeMember</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">SomeFunction</span>()</span><br><span class="line">      .<span class="built_in">Then</span>([<span class="keyword">this</span>](<span class="keyword">auto</span>&amp;&amp; value) &#123;</span><br><span class="line">        <span class="comment">// Where should this lambda run?????                                                                                                                    </span></span><br><span class="line">        std::unique_lock&lt;std::mutex&gt; <span class="built_in">lock</span>(mutex_);</span><br><span class="line">        i += value;</span><br><span class="line">      &#125;);</span><br><span class="line">  &#125;</span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="type">int</span> i_;</span><br><span class="line">  std::mutex mutex_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>这可能会带来一个问题：在SomeFunction对应的promise的执行逻辑在调用<code>promise.Set()</code>的时候可能是阻塞的(可以理解成执行promise的逻辑和执行Then的逻辑可能会并行，这里就有锁会带来的同步代价)<br>或许可以使用asyncmutex试图解决这个问题</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">MyObject</span> &#123;</span><br><span class="line">  <span class="function">Future&lt;<span class="type">void</span>&gt; <span class="title">SomeMember</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">SomeFunction</span>()</span><br><span class="line">      .<span class="built_in">Then</span>([<span class="keyword">this</span>](<span class="keyword">auto</span>&amp;&amp; value) &#123;</span><br><span class="line">        <span class="comment">// Where should this lambda run?????                                                                                                                    </span></span><br><span class="line">        <span class="keyword">return</span> mutex_.<span class="built_in">Acquire</span>()</span><br><span class="line">          .<span class="built_in">Then</span>([<span class="keyword">this</span>]() &#123;</span><br><span class="line">            i += value;</span><br><span class="line">            mutex_.<span class="built_in">Release</span>();</span><br><span class="line">          &#125;);</span><br><span class="line">      &#125;);</span><br><span class="line">  &#125;</span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="type">int</span> i_;</span><br><span class="line">  AsyncMutex mutex_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>这里调用<code>Release()</code>将要&#x2F;必须执行一个不会block的waiter，这也可能带来不确定的执行。</p>
<p>如果能够保证<code>Then</code>的内容严格在actor执行完<code>SomeFunction()</code>之后执行就能够避免上文中非确定性执行带来的同步问题</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">MyObject</span> : <span class="keyword">public</span> Actor &#123;</span><br><span class="line">  <span class="function">Future&lt;<span class="type">void</span>&gt; <span class="title">SomeMember</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">SomeFunction</span>()</span><br><span class="line">      .<span class="built_in">Then</span>(<span class="built_in">DeferOn</span>(<span class="built_in">self</span>(), [<span class="keyword">this</span>](<span class="keyword">auto</span>&amp;&amp; value) &#123;  <span class="comment">// Then之中的内容之后会在同一个actor的执行资源上执行</span></span><br><span class="line">        i_ += value;</span><br><span class="line">      &#125;));</span><br><span class="line">  &#125;</span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="type">int</span> i_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<ul>
<li>上面的方式中actor提供了执行<code>Then</code>(continuation)的executor资源</li>
<li>设置promise非常快是非阻塞的(DeferOn保证了在set之后才会执行Then之中的逻辑)</li>
<li>无需同步</li>
</ul>
<h2 id="revisiting-the-problem"><a href="#revisiting-the-problem" class="headerlink" title="revisiting the problem"></a>revisiting the problem</h2><p>重新看一下SpellAndGrammerCheck函数</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">std::string <span class="title">SpellAndGrammarCheck</span><span class="params">(std::string text)</span> </span>&#123; </span><br><span class="line">  text = <span class="built_in">SpellCheck</span>(text);</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">GrammarCheck</span>(text);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这段代码是顺序的，非并行的，即使并发执行也没有状态需要同步<br>修改成Future和Then的方式</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Future&lt;std::string&gt; <span class="title">SpellAndGrammarCheck</span><span class="params">(std::string text)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">SpellCheck</span>(text)</span><br><span class="line">      .<span class="built_in">Then</span>([](<span class="keyword">auto</span>&amp;&amp; text) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">GrammarCheck</span>(text);</span><br><span class="line">      &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这之中会申请锁并且需要动态分配内存</p>
<h3 id="是什么需要申请锁以及动态分配内存"><a href="#是什么需要申请锁以及动态分配内存" class="headerlink" title="是什么需要申请锁以及动态分配内存"></a>是什么需要申请锁以及动态分配内存</h3><p>我们先展开SpellCheck的逻辑</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Future&lt;std::string&gt; <span class="title">SpellAndGrammarCheck</span> <span class="params">(std::string text)</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">auto</span> future = promise.<span class="built_in">future</span>();</span><br><span class="line">  http::<span class="built_in">AsyncPost</span>( <span class="comment">// Non-blocking! Returns immediately!</span></span><br><span class="line">      ...,</span><br><span class="line">      [promise = std::<span class="built_in">move</span>(promise)]( <span class="keyword">auto</span>&amp;&amp; response) &#123;</span><br><span class="line">        promise.<span class="built_in">Set</span>(response.body);</span><br><span class="line">      &#125;);</span><br><span class="line">  <span class="keyword">return</span> future</span><br><span class="line">      .<span class="built_in">Then</span>([](<span class="keyword">auto</span>&amp;&amp; text) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">GrammarCheck</span>(text);</span><br><span class="line">      &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上面的代码中在<code>promise.Set(response.body)</code>与continuation通过<code>.Then()</code>组合之间存在race, 这两个动作可能在同时发生，于此我们需要锁来同步. 另外promise也可能在continuation被组合起来以前设置，所以需要动态内存分配.</p>
<p>有什么办法避免锁以及这一次动态内存分配吗？</p>
<h2 id="evolution-of-libprocess"><a href="#evolution-of-libprocess" class="headerlink" title="evolution of libprocess"></a>evolution of libprocess</h2><h3 id="避免锁开销"><a href="#避免锁开销" class="headerlink" title="避免锁开销"></a>避免锁开销</h3><p>上面的逻辑中SpellCheck的future的组装(将GrammarCheck的逻辑组合在一起)和promise的set操作之间是可能并行的，所以需要锁来同步，但如果将代码的逻辑做一下简单的修改，修改成SpellCheck中AsyncPost的逻辑执行完之后执行一个回调函数就可以避免锁的同步(也就是保证了GrammerCheck的逻辑一定在SpellCheck之后)</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// f的逻辑其实就是GrammerCheck</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">SpellCheck</span><span class="params">(std::string text, std::function&lt;<span class="type">void</span>(std::string)&gt; f)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> body = http::<span class="built_in">UrlEncode</span>(&#123;<span class="string">&quot;text&quot;</span>, text&#125;);</span><br><span class="line">  </span><br><span class="line">  http::<span class="built_in">AsyncPost</span>(</span><br><span class="line">      <span class="string">&quot;https://www.online-spellcheck.com&quot;</span> ,</span><br><span class="line">      body,</span><br><span class="line">      [f = std::<span class="built_in">move</span>(f)](<span class="keyword">auto</span>&amp;&amp; response) &#123;</span><br><span class="line">        <span class="built_in">f</span>(response.body); <span class="comment">// Invoke continuation without locks!</span></span><br><span class="line">      &#125;);</span><br><span class="line">  <span class="keyword">return</span> future;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>也可以修改成模板函数</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> K&gt;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">SpellCheck</span><span class="params">(std::string text, K k)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> body = http::<span class="built_in">UrlEncode</span>(&#123;<span class="string">&quot;text&quot;</span>, text&#125;);</span><br><span class="line">  http::<span class="built_in">AsyncPost</span>(</span><br><span class="line">      <span class="string">&quot;https://www.online-spellcheck.com&quot;</span> ,</span><br><span class="line">      body,</span><br><span class="line">      [k = std::<span class="built_in">move</span>(k)](<span class="keyword">auto</span>&amp;&amp; response) &#123;</span><br><span class="line">        <span class="keyword">if</span> (response.code != <span class="number">200</span>)  k.<span class="built_in">Fail</span>(response.code); </span><br><span class="line">        <span class="keyword">else</span> k.<span class="built_in">Success</span>(response.body);</span><br><span class="line">      &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>译者注：作者在演讲里表示在他读大学的时候他们都用K来表示continuation，所以这里模板里他也用的是K而不是C</p>
<h3 id="避免动态内存分配"><a href="#避免动态内存分配" class="headerlink" title="避免动态内存分配"></a>避免动态内存分配</h3><p>以上面的模板函数为例,到底是在什么地方分配了内存呢？这里需要进入Http::AsyncPost的实现之中</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">namespace</span> http &#123;</span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> K&gt;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Post</span><span class="params">(std::string url, std::string body, K k)</span> </span>&#123;</span><br><span class="line">  <span class="type">void</span>* data = <span class="keyword">new</span> <span class="built_in">K</span>(std::<span class="built_in">move</span>(k));</span><br><span class="line">  ...</span><br><span class="line">  <span class="built_in">http_post</span>(url, body, data, +[](<span class="type">long</span> code, <span class="type">const</span> <span class="type">char</span>* body, <span class="type">void</span>* data) &#123;</span><br><span class="line">    K* k = <span class="built_in">reinterpret_cast</span>&lt;K*&gt;(data);</span><br><span class="line">    k-&gt;<span class="built_in">Success</span>(http::Response&#123;code, body&#125;);</span><br><span class="line">    <span class="keyword">delete</span> k;</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="comment">// namespace http</span></span><br></pre></td></tr></table></figure>

<p>在Post方法中还是分配了内存.</p>
<p>💡 如果将continuation K作为函数返回的结果中的一部分是不是就避免了分配？</p>
<p>接受一个continuation作为参数并返回一个continuation作为结果(返回值中组合&#x2F;包括了作为参数传递的continuation)</p>
<p>修改一下上面的Post方法的实现，与其在函数的栈上分配一个堆上的void*，不如在函数中定义一个仅存在于该函数的struct并返回一个该struct的值</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> K&gt;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Post</span><span class="params">(std::string url, std::string body, K k)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">Continuation</span> &#123;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">Start</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="type">void</span>* data = &amp;k;</span><br><span class="line">      <span class="built_in">http_post</span>(url, body, data, +[]( <span class="type">long</span> code, <span class="type">const</span> <span class="type">char</span>* body, <span class="type">void</span>* data) </span><br><span class="line">      &#123;</span><br><span class="line">        K* k = <span class="built_in">reinterpret_cast</span>&lt;K*&gt;(data);</span><br><span class="line">        k-&gt;<span class="built_in">Success</span>( http::Response&#123;code, body&#125;);</span><br><span class="line">      &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">    std::string url, body;</span><br><span class="line">    K k;</span><br><span class="line">  &#125;;</span><br><span class="line">  <span class="keyword">return</span> Continuation&#123;std::<span class="built_in">move</span>(url), std::<span class="built_in">move</span>(body), std::<span class="built_in">move</span>(k)&#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到这段代码讲传递进入的url,body,k都传递进了struct Continuation之中，之后这三个值的生命周期将同返回的Continuation value绑定，在value析构时一同回收，同时这里的内存分配也只有一个栈上的值类型Continuation的内存分配.</p>
<h3 id="lazy-continuation"><a href="#lazy-continuation" class="headerlink" title="lazy continuation"></a>lazy continuation</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> k = http::<span class="built_in">Post</span>(url, body, <span class="comment">/* k&#x27; */</span>);</span><br><span class="line">k.<span class="built_in">Start</span>();</span><br></pre></td></tr></table></figure>

<ul>
<li>返回值类型是”computational graph”</li>
<li>这个graph是lazy的,当我们拿到这个graph时什么都不会发生(tradeoff for dynamic allocation) 并且如果我们想执行他的逻辑就必须显式调用start</li>
<li>graph可以分配在栈上或者堆上</li>
<li>在完成以前内存必须有效</li>
</ul>
<h2 id="eventuals"><a href="#eventuals" class="headerlink" title="eventuals"></a>eventuals</h2><p>作者将lazy continuation称为eventuals.</p>
<p>这一章的内容主要是介绍了eventuals并且通过eventuals将上文中传递continuation的代码风格进行了修正(传递continuation看着比较难看不符合人体工程学),译文会忽略这部分推导,感兴趣的读者可以访问<a target="_blank" rel="noopener" href="https://github.com/3rdparty/eventuals">eventuals</a>查看这个项目的信息.</p>
<h2 id="scheduling"><a href="#scheduling" class="headerlink" title="scheduling"></a>scheduling</h2><p>本章节主要是探讨continuation应该在什么地方运行？回望下面这段代码</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">auto</span> <span class="title">Post</span><span class="params">(std::string url, std::string body)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">Eventual</span>&lt;http::Response&gt;([url, body]( <span class="keyword">auto</span>&amp; k) &#123;</span><br><span class="line">      <span class="keyword">using</span> K = std::<span class="type">decay_t</span>&lt;<span class="keyword">decltype</span>(k)&gt;;</span><br><span class="line">      <span class="type">void</span>* data = &amp;k;</span><br><span class="line">      <span class="built_in">http_post</span>(url, body, data, +[]( <span class="type">long</span> code, <span class="type">const</span> <span class="type">char</span>* body, <span class="type">void</span>* data) </span><br><span class="line">      &#123;</span><br><span class="line">        K* k = <span class="built_in">reinterpret_cast</span>&lt;K*&gt;(data);</span><br><span class="line">        k-&gt;<span class="built_in">Success</span>(http::Response&#123;code, body&#125;);</span><br><span class="line">      &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;);</span><br></pre></td></tr></table></figure>

<p>如果continuation是在event loop中被调用的,我们不希望continuation继续在event loop中继续运行(会阻塞其他的IO任务,IO线程池不应该执行太复杂的continuation任务)<br>同理,如果continuation是在actor中被调用的我们也不希望继续在actor的执行资源上运行，因为这样会阻塞别的message的处理</p>
<p>回首看一下motivating exemple的代码</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">std::string <span class="title">SpellCheck</span><span class="params">(std::string text)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> body = http::<span class="built_in">UrlEncode</span>(&#123;<span class="string">&quot;text&quot;</span>, text&#125;);</span><br><span class="line">  <span class="keyword">auto</span> response = http::<span class="built_in">Post</span>(<span class="string">&quot;https://www.online-spellcheck.com&quot;</span>, body);</span><br><span class="line">  <span class="keyword">return</span> response.body;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>得益于函数的抽象，我们可以分开考虑函数的接口以及实现.在这里不需要考虑http::Post到底是如何实现的.</p>
<ul>
<li>我们不关心是否在多线程上实现</li>
<li>我们不关心是否在GPU上实现</li>
<li>我们不关心是否在FPGA上实现</li>
</ul>
<p>然而，如果执行完http::Post方法并将控制流返回时我们发现现在正在</p>
<ul>
<li>于我们开始执行时不同的线程上执行时，我们会很惊讶</li>
<li>一块GPU的执行逻辑上，而我们是在CPU上开始执行的，我们会很惊讶</li>
</ul>
<p>所以我们到底应该让continuation在什么地方执行呢？<br><strong>使用在你不得不等待以前正在使用的执行资源</strong></p>
<p>否则(译者注：这里作者意思大概就是否则我们每一次都应该检查接下来的函数调用的文档&#x2F;实现去查看对应的函数会不会在eventloop上执行，如果是的话就需要自己通过ThreadPool::Schedule等方法重新调度),需要将代码进行类似的修改.</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">auto</span> <span class="title">SpellAndGrammarCheck</span> <span class="params">(std::string text)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> ThreadPool::<span class="built_in">Schedule</span>([text]() &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">SpellCheck</span>(text)</span><br><span class="line">        <span class="comment">// Rescheduling on thread pool because we looked at  </span></span><br><span class="line">        <span class="comment">// documentation of &#x27;SpellCheck()&#x27; and it continues on the</span></span><br><span class="line">        <span class="comment">// event loop which we don&#x27;t want to be on.</span></span><br><span class="line">        | ThreadPool::<span class="built_in">Schedule</span>([text]() &#123;</span><br><span class="line">             <span class="keyword">return</span> <span class="built_in">Then</span>([](<span class="keyword">auto</span>&amp;&amp; text) &#123;</span><br><span class="line">               <span class="keyword">return</span> <span class="built_in">GrammarCheck</span>(text);</span><br><span class="line">             &#125;);</span><br><span class="line">           &#125;);</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>类似的内容可以查看std::execution的提案(译者后续的博文也会介绍这个提案).</p>
<p>另外也介绍了在PLDI也有类似的工作</p>
<p>“Composing Sorfware Efficiently with Lithe”(PLDI 2010)</p>
<ul>
<li>允许许多同时的scheduler负责计算图的子树</li>
<li>所有的计算都拥有一个调度context</li>
<li>对于冲洗提交任务给拥有context的接口提供了正式的接口</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/06/17/post-title-with-whitespace/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/06/17/post-title-with-whitespace/" class="post-title-link" itemprop="url">post title with whitespace</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-06-17 22:34:38" itemprop="dateCreated datePublished" datetime="2023-06-17T22:34:38+08:00">2023-06-17</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/06/17/hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/06/17/hello-world/" class="post-title-link" itemprop="url">Hello World</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-06-17 22:28:29" itemprop="dateCreated datePublished" datetime="2023-06-17T22:28:29+08:00">2023-06-17</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">John Doe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">5</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
